{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh-_lrIWLbTL",
        "outputId": "97a873d6-8073-4694-e625-da19593fd307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "GPU Available: True\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import time as time_module\n",
        "import gc\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "from collections import defaultdict\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.test.is_gpu_available() if hasattr(tf.test, 'is_gpu_available') else tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2328-UvD9gzi",
        "outputId": "70248b3a-d6e1-4564-ebc4-ce82c88dd761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Memory monitoring setup complete\n",
            "Memory usage initial: 986.3 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "986.3359375"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Cell 2: Install dependencies and setup memory monitoring\n",
        "!pip install psutil\n",
        "\n",
        "import psutil\n",
        "\n",
        "def get_memory_usage():\n",
        "    \"\"\"Monitor memory usage in MB\"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss / 1024 / 1024\n",
        "\n",
        "def print_memory_status(stage=\"\"):\n",
        "    \"\"\"Print memory status dengan garbage collection\"\"\"\n",
        "    gc.collect()  # Force garbage collection\n",
        "    memory_mb = get_memory_usage()\n",
        "    print(f\"Memory usage {stage}: {memory_mb:.1f} MB\")\n",
        "    return memory_mb\n",
        "\n",
        "def memory_cleanup():\n",
        "    \"\"\"Aggressive memory cleanup\"\"\"\n",
        "    gc.collect()\n",
        "    if hasattr(gc, 'set_threshold'):\n",
        "        gc.set_threshold(700, 10, 10)  # More aggressive GC\n",
        "\n",
        "print(\"Memory monitoring setup complete\")\n",
        "print_memory_status(\"initial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBOpNukqLe8h",
        "outputId": "9321a067-9195-41a1-ff6c-574a9a6ec6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Set paths and checkpoint configuration\n",
        "root = '/content/drive/MyDrive/TA/DIEN/DIEN-tf2/new/dataset'\n",
        "\n",
        "# Setup checkpoint system\n",
        "checkpoint_root = '/content/drive/MyDrive/TA/TAOBAO/checkpoints'\n",
        "os.makedirs(checkpoint_root, exist_ok=True)\n",
        "\n",
        "# Checkpoint paths\n",
        "preprocessing_checkpoint = os.path.join(checkpoint_root, 'preprocessing.pkl')\n",
        "dataset_checkpoint = os.path.join(checkpoint_root, 'dataset.npz')\n",
        "metadata_checkpoint = os.path.join(checkpoint_root, 'metadata.pkl')\n",
        "results_checkpoint = os.path.join(checkpoint_root, 'results.pkl')\n",
        "\n",
        "# Model save directory\n",
        "save_path = '/content/drive/MyDrive/TA/TAOBAO/models'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "print(\"Paths configured successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itnKfSa5Lg_0",
        "outputId": "b8b13ea3-07c9-4ce1-b21f-7d0d57f12943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting with fresh results dictionary\n"
          ]
        }
      ],
      "source": [
        "# Checkpoint flags\n",
        "preprocessing_done = False\n",
        "dataset_ready = False\n",
        "models_trained = {'Basic': False, 'DeepFM': False, 'DIN': False}\n",
        "\n",
        "# Check if previous results exist\n",
        "if os.path.exists(results_checkpoint):\n",
        "    with open(results_checkpoint, 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "        print(f\"Loaded existing results containing {list(results.keys())} models\")\n",
        "        for model_name in results:\n",
        "            if model_name in models_trained:\n",
        "                models_trained[model_name] = True\n",
        "else:\n",
        "    results = {}\n",
        "    print(\"Starting with fresh results dictionary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrZvNJIDDpER",
        "outputId": "23393656-52a7-4a75-c1fa-708e52cb3e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Safe memory reduction function loaded\n"
          ]
        }
      ],
      "source": [
        "# QUICK FIX: Add this cell before Cell 4 to prevent categorical errors\n",
        "def safe_reduce_mem_usage(df):\n",
        "    \"\"\"Safe memory reduction that handles categorical columns properly\"\"\"\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        # Skip datetime and categorical columns\n",
        "        if (pd.api.types.is_datetime64_any_dtype(col_type) or\n",
        "            pd.api.types.is_categorical_dtype(col_type)):\n",
        "            continue\n",
        "\n",
        "        # Handle object/string columns\n",
        "        if col_type == object:\n",
        "            try:\n",
        "                num_unique_values = len(df[col].unique())\n",
        "                num_total_values = len(df[col])\n",
        "\n",
        "                # Only convert to category if it makes sense\n",
        "                if num_unique_values / num_total_values < 0.3:  # More conservative threshold\n",
        "                    df[col] = df[col].astype('category')\n",
        "            except:\n",
        "                pass  # Skip if conversion fails\n",
        "            continue\n",
        "\n",
        "        # Handle numeric columns only\n",
        "        if pd.api.types.is_numeric_dtype(col_type):\n",
        "            try:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "\n",
        "                if pd.isna(c_min) or pd.isna(c_max):\n",
        "                    continue\n",
        "\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    if c_min >= -128 and c_max <= 127:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min >= -32768 and c_max <= 32767:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min >= -2147483648 and c_max <= 2147483647:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                elif 'float' in str(col_type):\n",
        "                    if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Skipping {col}: {e}\")\n",
        "                continue\n",
        "\n",
        "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    print(f'✅ Memory: {start_mem:.1f} MB → {end_mem:.1f} MB ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
        "    return df\n",
        "\n",
        "# Replace the function in Cell 4\n",
        "reduce_mem_usage_aggressive = safe_reduce_mem_usage\n",
        "\n",
        "print(\"Safe memory reduction function loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG26FUHC9gzj",
        "outputId": "e5743ea6-9889-40f5-d9ea-d6dc117cfe6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPLETELY FIXED Data loading functions ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: FIXED Memory-optimized data loading functions - COMPLETE REPLACEMENT\n",
        "def reduce_mem_usage_aggressive(df):\n",
        "    \"\"\"Aggressive memory reduction dengan categorical optimization - COMPLETELY FIXED\"\"\"\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        # Skip datetime columns\n",
        "        if pd.api.types.is_datetime64_any_dtype(col_type):\n",
        "            continue\n",
        "\n",
        "        # Handle object/string columns dengan categorical\n",
        "        if col_type == object:\n",
        "            try:\n",
        "                num_unique_values = len(df[col].unique())\n",
        "                num_total_values = len(df[col])\n",
        "\n",
        "                # Convert to category jika rasio unique < 50%\n",
        "                if num_unique_values / num_total_values < 0.5:\n",
        "                    df[col] = df[col].astype('category')\n",
        "            except:\n",
        "                pass\n",
        "            continue\n",
        "\n",
        "        # Handle categorical columns - SKIP MIN/MAX operations\n",
        "        if pd.api.types.is_categorical_dtype(col_type):\n",
        "            continue\n",
        "\n",
        "        # Handle numeric columns - AVOID float16 COMPLETELY for ID columns\n",
        "        try:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            # Check for NaN values\n",
        "            if pd.isna(c_min) or pd.isna(c_max):\n",
        "                continue\n",
        "\n",
        "            # IDENTIFY ID columns that will be used as embedding dimensions\n",
        "            is_id_column = any(keyword in col.lower() for keyword in\n",
        "                              ['id', 'user', 'item', 'cat', 'brand', 'group', 'adgroup'])\n",
        "\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min >= -128 and c_max <= 127:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min >= -32768 and c_max <= 32767:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min >= -2147483648 and c_max <= 2147483647:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "            elif 'float' in str(col_type):\n",
        "                # CRITICAL FIX: For ID columns, NEVER use float16\n",
        "                if is_id_column:\n",
        "                    # For ID columns, always use float32 or higher\n",
        "                    if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    # If value too large for float32, keep as original\n",
        "                else:\n",
        "                    # For non-ID columns, still avoid float16 to be safe\n",
        "                    if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "\n",
        "        except (TypeError, ValueError, OverflowError) as e:\n",
        "            print(f\"⚠️ Skipping column {col} due to error: {e}\")\n",
        "            continue\n",
        "\n",
        "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    print(f'Memory usage decreased from {start_mem:.2f} MB to {end_mem:.2f} MB ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
        "    return df\n",
        "\n",
        "def load_data_streaming(file_path, chunksize=50000, usecols=None, **kwargs):\n",
        "    \"\"\"Load data dengan streaming untuk dataset besar - ENHANCED ERROR HANDLING\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Loading {file_path} with streaming (chunksize={chunksize:,})\")\n",
        "    print_memory_status(\"before loading\")\n",
        "\n",
        "    chunks = []\n",
        "    total_rows = 0\n",
        "\n",
        "    try:\n",
        "        for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize,\n",
        "                                            usecols=usecols, **kwargs)):\n",
        "            # Apply SAFE memory reduction\n",
        "            try:\n",
        "                chunk = reduce_mem_usage_aggressive(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Memory reduction warning for chunk {i+1}: {e}\")\n",
        "                # Continue without memory reduction if it fails\n",
        "\n",
        "            chunks.append(chunk)\n",
        "            total_rows += len(chunk)\n",
        "\n",
        "            # Memory monitoring setiap 20 chunks\n",
        "            if (i + 1) % 20 == 0:\n",
        "                print(f\"Loaded {i+1} chunks ({total_rows:,} rows)\")\n",
        "                print_memory_status(f\"chunk {i+1}\")\n",
        "\n",
        "        print(f\"Concatenating {len(chunks)} chunks...\")\n",
        "        df = pd.concat(chunks, ignore_index=True)\n",
        "        del chunks\n",
        "        memory_cleanup()\n",
        "\n",
        "        print(f\"Total rows loaded: {len(df):,}\")\n",
        "        print_memory_status(\"after loading\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"COMPLETELY FIXED Data loading functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1_4ZF1QMI4R",
        "outputId": "a4655f7e-7cdd-4e9c-df09-37d61f242eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint functions ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Checkpoint management functions\n",
        "def save_dataset_checkpoint(train_x, train_y, test_x, test_y):\n",
        "    \"\"\"Save dataset dengan kompresi optimal\"\"\"\n",
        "    print(\"Saving dataset checkpoint...\")\n",
        "    print_memory_status(\"before saving\")\n",
        "\n",
        "    # Create save dict with essential features\n",
        "    save_dict = {\n",
        "        'train_user': train_x['user'],\n",
        "        'train_item': train_x['item'],\n",
        "        'train_cat': train_x['cat'],\n",
        "        'train_price': train_x['price'],\n",
        "        'train_hist_items': train_x['hist_items'],\n",
        "        'train_y': train_y,\n",
        "        'test_user': test_x['user'],\n",
        "        'test_item': test_x['item'],\n",
        "        'test_cat': test_x['cat'],\n",
        "        'test_price': test_x['price'],\n",
        "        'test_hist_items': test_x['hist_items'],\n",
        "        'test_y': test_y\n",
        "    }\n",
        "\n",
        "    # Add history features if available\n",
        "    for key in ['hist_cats', 'hist_behaviors']:\n",
        "        if key in train_x:\n",
        "            save_dict[f'train_{key}'] = train_x[key]\n",
        "            save_dict[f'test_{key}'] = test_x[key]\n",
        "\n",
        "    # 🔧 FIXED: Add ALL enhanced features including missing ones\n",
        "    all_enhanced_features = [\n",
        "        # Basic features (sudah ada)\n",
        "        'gender', 'age_level', 'shopping_level', 'brand', 'hour', 'is_weekend',\n",
        "        # 🎯 MISSING CYCLICAL FEATURES (yang hilang!)\n",
        "        'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
        "        # 🎯 MISSING ADVANCED TEMPORAL (yang hilang!)\n",
        "        'day_of_week', 'time_segment', 'is_holiday'\n",
        "    ]\n",
        "\n",
        "    saved_count = 0\n",
        "    missing_count = 0\n",
        "\n",
        "    for key in all_enhanced_features:\n",
        "        if key in train_x:\n",
        "            save_dict[f'train_{key}'] = train_x[key]\n",
        "            save_dict[f'test_{key}'] = test_x[key]\n",
        "            saved_count += 1\n",
        "            print(f\"✅ Saved enhanced feature: {key}\")\n",
        "        else:\n",
        "            missing_count += 1\n",
        "            print(f\"⚠️ Missing enhanced feature: {key}\")\n",
        "\n",
        "    np.savez_compressed(dataset_checkpoint, **save_dict)\n",
        "\n",
        "    # Calculate and print file size\n",
        "    file_size = os.path.getsize(dataset_checkpoint) / (1024 * 1024)  # MB\n",
        "    print(f\"Dataset checkpoint saved: {file_size:.1f} MB\")\n",
        "    print(f\"✅ Enhanced features saved: {saved_count}/{len(all_enhanced_features)}\")\n",
        "    if missing_count > 0:\n",
        "        print(f\"⚠️ Missing features: {missing_count}\")\n",
        "    print_memory_status(\"after saving\")\n",
        "\n",
        "def save_metadata_checkpoint(n_users, n_items, n_cats, hist_len, additional_dims=None):\n",
        "    \"\"\"Save metadata checkpoint\"\"\"\n",
        "    metadata = {\n",
        "        'n_users': n_users,\n",
        "        'n_items': n_items,\n",
        "        'n_cats': n_cats,\n",
        "        'hist_len': hist_len\n",
        "    }\n",
        "\n",
        "    if additional_dims:\n",
        "        metadata['additional_dims'] = additional_dims\n",
        "\n",
        "    with open(metadata_checkpoint, 'wb') as f:\n",
        "        pickle.dump(metadata, f)\n",
        "    print(\"Metadata checkpoint saved\")\n",
        "\n",
        "def load_dataset_from_checkpoint():\n",
        "    \"\"\"Load dataset from checkpoint\"\"\"\n",
        "    print(\"Loading dataset from checkpoint...\")\n",
        "    data = np.load(dataset_checkpoint, allow_pickle=True)\n",
        "\n",
        "    # Basic features\n",
        "    train_x = {\n",
        "        'user': data['train_user'],\n",
        "        'item': data['train_item'],\n",
        "        'cat': data['train_cat'],\n",
        "        'price': data['train_price'],\n",
        "        'hist_items': data['train_hist_items']\n",
        "    }\n",
        "\n",
        "    test_x = {\n",
        "        'user': data['test_user'],\n",
        "        'item': data['test_item'],\n",
        "        'cat': data['test_cat'],\n",
        "        'price': data['test_price'],\n",
        "        'hist_items': data['test_hist_items']\n",
        "    }\n",
        "\n",
        "    # Load history features if available\n",
        "    for feature in ['hist_cats', 'hist_behaviors']:\n",
        "        key_train = f'train_{feature}'\n",
        "        key_test = f'test_{feature}'\n",
        "        if key_train in data:\n",
        "            train_x[feature] = data[key_train]\n",
        "            test_x[feature] = data[key_test]\n",
        "\n",
        "    # 🔧 FIXED: Load ALL enhanced features including missing ones\n",
        "    all_enhanced_features = [\n",
        "        # Basic features\n",
        "        'gender', 'age_level', 'shopping_level', 'brand', 'hour', 'is_weekend',\n",
        "        # 🎯 CYCLICAL FEATURES\n",
        "        'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
        "        # 🎯 ADVANCED TEMPORAL FEATURES\n",
        "        'day_of_week', 'time_segment', 'is_holiday'\n",
        "    ]\n",
        "\n",
        "    loaded_count = 0\n",
        "    missing_count = 0\n",
        "\n",
        "    for feature in all_enhanced_features:\n",
        "        key_train = f'train_{feature}'\n",
        "        key_test = f'test_{feature}'\n",
        "        if key_train in data:\n",
        "            train_x[feature] = data[key_train]\n",
        "            test_x[feature] = data[key_test]\n",
        "            loaded_count += 1\n",
        "            print(f\"✅ Loaded enhanced feature: {feature}\")\n",
        "        else:\n",
        "            missing_count += 1\n",
        "            print(f\"⚠️ Missing enhanced feature: {feature}\")\n",
        "\n",
        "    train_y = data['train_y']\n",
        "    test_y = data['test_y']\n",
        "\n",
        "    print(f\"✅ Enhanced features loaded: {loaded_count}/{len(all_enhanced_features)}\")\n",
        "    if missing_count > 0:\n",
        "        print(f\"⚠️ Missing features: {missing_count} (will need regeneration)\")\n",
        "\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "def load_metadata_from_checkpoint():\n",
        "    \"\"\"Load metadata from checkpoint\"\"\"\n",
        "    with open(metadata_checkpoint, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "print(\"Checkpoint functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpazSfHd8RCG",
        "outputId": "42cf24ec-8243-4eea-f120-6bed8ab4404f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Data processing functions ready - Expected +5-8% AUC boost\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: REPLACE - Enhanced Data processing functions with Advanced Temporal Features\n",
        "def add_temporal_features(df):\n",
        "    \"\"\"Enhanced temporal features untuk better context modeling\"\"\"\n",
        "    if 'time_stamp' in df.columns:\n",
        "        # Convert timestamp efficiently\n",
        "        df['datetime'] = pd.to_datetime(df['time_stamp'], unit='s')\n",
        "\n",
        "        # Extract basic time features untuk cyclical conversion\n",
        "        df['hour'] = df['datetime'].dt.hour.astype(np.int8)\n",
        "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype(np.int8)\n",
        "\n",
        "        # 🎯 PRIORITAS: Cyclical encoding untuk continuous temporal patterns\n",
        "        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24).astype(np.float32)\n",
        "        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24).astype(np.float32)\n",
        "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7).astype(np.float32)\n",
        "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7).astype(np.float32)\n",
        "\n",
        "        # Keep existing features\n",
        "        df['is_weekend'] = (df['datetime'].dt.dayofweek >= 5).astype(np.int8)\n",
        "        df['time_segment'] = pd.cut(df['hour'],\n",
        "                                  bins=[0, 6, 12, 18, 24],\n",
        "                                  labels=[0, 1, 2, 3],\n",
        "                                  include_lowest=True).astype(np.int8)\n",
        "        df['is_holiday'] = ((df['datetime'].dt.day == 1) |\n",
        "                           (df['datetime'].dt.day == 15)).astype(np.int8)\n",
        "\n",
        "        # Drop intermediate columns untuk menghemat memori\n",
        "        df.drop(['datetime', 'hour', 'day_of_week'], axis=1, inplace=True)\n",
        "\n",
        "        print(\"✅ Enhanced temporal features created:\")\n",
        "        print(\"   - Cyclical hour/day encoding (hour_sin, hour_cos, day_sin, day_cos)\")\n",
        "        print(\"   - Time segments (morning/afternoon/evening/night)\")\n",
        "        print(\"   - Holiday detection\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_data_in_chunks(raw_sample, other_dataframes, chunk_size=500000):\n",
        "    \"\"\"Process merge operations dalam chunks untuk menghemat memori\"\"\"\n",
        "    print(f\"Processing {len(raw_sample):,} rows in chunks of {chunk_size:,}\")\n",
        "    print_memory_status(\"start chunked processing\")\n",
        "\n",
        "    # Split raw_sample into chunks\n",
        "    n_chunks = (len(raw_sample) + chunk_size - 1) // chunk_size\n",
        "    processed_chunks = []\n",
        "\n",
        "    for i in range(n_chunks):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = min((i + 1) * chunk_size, len(raw_sample))\n",
        "\n",
        "        print(f\"Processing chunk {i+1}/{n_chunks} (rows {start_idx:,}-{end_idx:,})\")\n",
        "\n",
        "        # Get chunk\n",
        "        chunk = raw_sample.iloc[start_idx:end_idx].copy()\n",
        "\n",
        "        # Merge with other dataframes\n",
        "        for name, df in other_dataframes.items():\n",
        "            if df is not None:\n",
        "                # Determine merge key\n",
        "                if name == 'ad_feature':\n",
        "                    merge_key = 'adgroup_id'\n",
        "                elif name == 'user_profile':\n",
        "                    merge_key = 'userid'\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                chunk = chunk.merge(df, on=merge_key, how='left')\n",
        "                print(f\"  Merged with {name}\")\n",
        "\n",
        "        # Add enhanced temporal features\n",
        "        chunk = add_temporal_features(chunk)\n",
        "\n",
        "        # Memory optimization\n",
        "        chunk = reduce_mem_usage_aggressive(chunk)\n",
        "        processed_chunks.append(chunk)\n",
        "\n",
        "        # Cleanup\n",
        "        del chunk\n",
        "        memory_cleanup()\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print_memory_status(f\"after chunk {i+1}\")\n",
        "\n",
        "    # Combine all chunks\n",
        "    print(\"Combining all processed chunks...\")\n",
        "    final_data = pd.concat(processed_chunks, ignore_index=True)\n",
        "    del processed_chunks\n",
        "    memory_cleanup()\n",
        "\n",
        "    print_memory_status(\"chunked processing complete\")\n",
        "    return final_data\n",
        "\n",
        "def process_user_behavior_ultra_efficient(user_behavior, target_size=10000000):\n",
        "    \"\"\"Process user behavior dengan ALL AVAILABLE FOR RARE BEHAVIORS strategy\"\"\"\n",
        "    print(f\"Processing user behavior: {len(user_behavior):,} → {target_size:,} records\")\n",
        "    print_memory_status(\"start behavior processing\")\n",
        "\n",
        "    # Check available behavior types\n",
        "    behavior_counts = user_behavior['behavior'].value_counts()\n",
        "    print(f\"\\nOriginal behavior distribution:\")\n",
        "    for behavior, count in behavior_counts.items():\n",
        "        print(f\"  {behavior}: {count:,} ({count/len(user_behavior)*100:.1f}%)\")\n",
        "\n",
        "    # RARE BEHAVIORS FIRST strategy: Take ALL available for buy & fav\n",
        "    rare_behaviors = ['buy', 'fav']  # Behaviors to take ALL available data\n",
        "    common_behaviors = ['pv', 'cart']  # Behaviors to distribute remaining capacity\n",
        "\n",
        "    print(f\"\\n🎯 ALL AVAILABLE FOR RARE BEHAVIORS strategy:\")\n",
        "    print(f\"  Rare behaviors (take ALL): {rare_behaviors}\")\n",
        "    print(f\"  Common behaviors (distribute remaining): {common_behaviors}\")\n",
        "\n",
        "    # Step 1: Take ALL available data for rare behaviors\n",
        "    sampled_behaviors = []\n",
        "    total_rare_samples = 0\n",
        "\n",
        "    print(f\"\\n📊 Step 1: Taking ALL available data for rare behaviors:\")\n",
        "    for behavior_type in rare_behaviors:\n",
        "        if behavior_type in behavior_counts.index:\n",
        "            behavior_data = user_behavior[user_behavior['behavior'] == behavior_type]\n",
        "            available_samples = len(behavior_data)\n",
        "\n",
        "            # Take ALL available data\n",
        "            sample = behavior_data.copy()\n",
        "            sampled_behaviors.append(sample)\n",
        "            total_rare_samples += len(sample)\n",
        "\n",
        "            print(f\"  🔥 {behavior_type}: took ALL {len(sample):,} available samples\")\n",
        "\n",
        "            del behavior_data\n",
        "            memory_cleanup()\n",
        "        else:\n",
        "            print(f\"  ⚠️  {behavior_type}: not found in data\")\n",
        "\n",
        "    # Step 2: Calculate remaining capacity for common behaviors\n",
        "    remaining_capacity = target_size - total_rare_samples\n",
        "    n_common_behaviors = len([b for b in common_behaviors if b in behavior_counts.index])\n",
        "\n",
        "    if remaining_capacity > 0 and n_common_behaviors > 0:\n",
        "        samples_per_common = remaining_capacity // n_common_behaviors\n",
        "\n",
        "        print(f\"\\n📊 Step 2: Distributing remaining capacity to common behaviors:\")\n",
        "        print(f\"  Total capacity used by rare behaviors: {total_rare_samples:,}\")\n",
        "        print(f\"  Remaining capacity: {remaining_capacity:,}\")\n",
        "        print(f\"  Samples per common behavior: {samples_per_common:,}\")\n",
        "\n",
        "        for behavior_type in common_behaviors:\n",
        "            if behavior_type in behavior_counts.index:\n",
        "                behavior_data = user_behavior[user_behavior['behavior'] == behavior_type]\n",
        "                available_samples = len(behavior_data)\n",
        "\n",
        "                # Take minimum of available samples and allocated capacity\n",
        "                n_samples = min(samples_per_common, available_samples)\n",
        "\n",
        "                if n_samples > 0:\n",
        "                    if available_samples > n_samples:\n",
        "                        # Random sampling\n",
        "                        sample = behavior_data.sample(n=n_samples, random_state=42)\n",
        "                        sampling_type = \"random sampling\"\n",
        "                    else:\n",
        "                        # Take all available\n",
        "                        sample = behavior_data.copy()\n",
        "                        sampling_type = \"took all available\"\n",
        "\n",
        "                    sampled_behaviors.append(sample)\n",
        "                    print(f\"  ✅ {behavior_type}: sampled {len(sample):,} from {available_samples:,} available ({sampling_type})\")\n",
        "                else:\n",
        "                    print(f\"  ❌ {behavior_type}: no capacity remaining\")\n",
        "\n",
        "                del behavior_data\n",
        "                memory_cleanup()\n",
        "            else:\n",
        "                print(f\"  ⚠️  {behavior_type}: not found in data\")\n",
        "    else:\n",
        "        print(f\"\\n⚠️  No remaining capacity for common behaviors!\")\n",
        "\n",
        "    # Combine all samples\n",
        "    user_behavior_sampled = pd.concat(sampled_behaviors, ignore_index=True)\n",
        "    del sampled_behaviors\n",
        "    memory_cleanup()\n",
        "\n",
        "    # Shuffle untuk menghindari bias urutan\n",
        "    user_behavior_sampled = user_behavior_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Check final distribution\n",
        "    final_counts = user_behavior_sampled['behavior'].value_counts()\n",
        "    total_sampled = len(user_behavior_sampled)\n",
        "\n",
        "    print(f\"\\n✅ FINAL DISTRIBUTION (Rare Behaviors Prioritized):\")\n",
        "    print(f\"   Total sampled: {total_sampled:,} records\")\n",
        "\n",
        "    # Show rare behaviors first\n",
        "    for behavior in rare_behaviors:\n",
        "        if behavior in final_counts.index:\n",
        "            count = final_counts[behavior]\n",
        "            percentage = count/total_sampled*100\n",
        "            print(f\"   {behavior}: {count:,} ({percentage:.1f}%) ← ALL AVAILABLE\")\n",
        "\n",
        "    # Then show common behaviors\n",
        "    for behavior in common_behaviors:\n",
        "        if behavior in final_counts.index:\n",
        "            count = final_counts[behavior]\n",
        "            percentage = count/total_sampled*100\n",
        "            available = behavior_counts.get(behavior, 0)\n",
        "            coverage = count/available*100 if available > 0 else 0\n",
        "            print(f\"   {behavior}: {count:,} ({percentage:.1f}%) ← {coverage:.1f}% of available\")\n",
        "\n",
        "    # Calculate priority score (higher = better for rare behaviors)\n",
        "    rare_coverage = sum([final_counts.get(b, 0) for b in rare_behaviors]) / total_sampled * 100\n",
        "    print(f\"\\n📈 Rare Behaviors Coverage: {rare_coverage:.1f}% of total samples\")\n",
        "\n",
        "    if rare_coverage >= 20:\n",
        "        print(\"   🎉 Excellent rare behavior representation!\")\n",
        "    elif rare_coverage >= 10:\n",
        "        print(\"   ✅ Good rare behavior representation!\")\n",
        "    else:\n",
        "        print(\"   ⚠️  Consider increasing target size for better rare behavior coverage\")\n",
        "\n",
        "    # Optimize data types\n",
        "    user_behavior_sampled = reduce_mem_usage_aggressive(user_behavior_sampled)\n",
        "\n",
        "    print_memory_status(\"behavior processing complete\")\n",
        "    return user_behavior_sampled\n",
        "\n",
        "print(\"Enhanced Data processing functions ready - Expected +5-8% AUC boost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8VH_9uT8RCG",
        "outputId": "e6ecf44c-97dd-465f-8640-a40a8fa2a4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History creation functions ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: History creation functions\n",
        "def create_histories_memory_efficient(data, user_behavior=None, max_hist_len=50):\n",
        "    \"\"\"Create histories dengan memory optimization maksimal\"\"\"\n",
        "    print(\"Creating histories with memory optimization...\")\n",
        "    print_memory_status(\"start history creation\")\n",
        "\n",
        "    user_histories = defaultdict(list)\n",
        "    user_category_histories = defaultdict(list)\n",
        "    user_behavior_histories = defaultdict(list)\n",
        "\n",
        "    # Process main data dalam chunks kecil\n",
        "    unique_users = data['userid'].unique()\n",
        "    user_chunk_size = 2000  # Process 2K users at a time\n",
        "    user_chunks = [unique_users[i:i+user_chunk_size]\n",
        "                   for i in range(0, len(unique_users), user_chunk_size)]\n",
        "\n",
        "    print(f\"Processing {len(unique_users):,} users in {len(user_chunks)} chunks\")\n",
        "\n",
        "    for chunk_idx, user_chunk in enumerate(user_chunks):\n",
        "        chunk_data = data[data['userid'].isin(user_chunk)]\n",
        "\n",
        "        # Group by user dan ambil history\n",
        "        for uid, group in chunk_data.groupby('userid'):\n",
        "            if 'time_stamp' in group.columns:\n",
        "                sorted_group = group.sort_values('time_stamp')\n",
        "            else:\n",
        "                sorted_group = group\n",
        "\n",
        "            # Ambil hanya yang terakhir dengan dtype optimal\n",
        "            items = sorted_group['adgroup_id'].values[-max_hist_len:].astype(np.int32)\n",
        "            categories = sorted_group['cate_id'].values[-max_hist_len:].astype(np.int32)\n",
        "\n",
        "            user_histories[uid] = items\n",
        "            user_category_histories[uid] = categories\n",
        "            user_behavior_histories[uid] = ['click'] * len(items)\n",
        "\n",
        "        del chunk_data\n",
        "\n",
        "        if (chunk_idx + 1) % 10 == 0:\n",
        "            print(f\"Processed user chunk {chunk_idx+1}/{len(user_chunks)}\")\n",
        "            memory_cleanup()\n",
        "\n",
        "    # Integrate behavior data jika ada\n",
        "    if user_behavior is not None:\n",
        "        print(\"Integrating behavior data...\")\n",
        "\n",
        "        # Process behavior dalam chunks\n",
        "        behavior_chunk_size = 100000\n",
        "        behavior_chunks = [user_behavior[i:i+behavior_chunk_size]\n",
        "                          for i in range(0, len(user_behavior), behavior_chunk_size)]\n",
        "\n",
        "        for chunk_idx, behavior_chunk in enumerate(behavior_chunks):\n",
        "            for uid, group in behavior_chunk.groupby('userid'):\n",
        "                if uid in user_histories:  # Only process users we care about\n",
        "                    sorted_group = group.sort_values('timestamp')\n",
        "\n",
        "                    # Combine dengan existing history\n",
        "                    items = sorted_group['itemid'].values[-max_hist_len:].astype(np.int32)\n",
        "                    categories = sorted_group['categoryid'].values[-max_hist_len:].astype(np.int32)\n",
        "                    behaviors = sorted_group['behavior'].values[-max_hist_len:]\n",
        "\n",
        "                    # Update histories\n",
        "                    user_histories[uid] = np.concatenate([user_histories[uid], items])[-max_hist_len:]\n",
        "                    user_category_histories[uid] = np.concatenate([user_category_histories[uid], categories])[-max_hist_len:]\n",
        "                    user_behavior_histories[uid] = (user_behavior_histories[uid] + list(behaviors))[-max_hist_len:]\n",
        "\n",
        "            if (chunk_idx + 1) % 5 == 0:\n",
        "                print(f\"Processed behavior chunk {chunk_idx+1}/{len(behavior_chunks)}\")\n",
        "                memory_cleanup()\n",
        "\n",
        "    print_memory_status(\"history creation complete\")\n",
        "    return user_histories, user_category_histories, user_behavior_histories\n",
        "\n",
        "def create_padded_sequences_efficient(data, histories, hist_len=40, batch_size=100000):\n",
        "    \"\"\"Create padded sequences dengan memory optimization\"\"\"\n",
        "    print(f\"Creating padded sequences for {len(data):,} samples\")\n",
        "    print_memory_status(\"start padding\")\n",
        "\n",
        "    user_histories, user_category_histories, user_behavior_histories = histories\n",
        "\n",
        "    # Determine optimal dtypes\n",
        "    max_item_id = data['adgroup_id'].max()\n",
        "    max_cat_id = data['cate_id'].max()\n",
        "\n",
        "    item_dtype = np.int16 if max_item_id < 32767 else np.int32\n",
        "    cat_dtype = np.int16 if max_cat_id < 32767 else np.int32\n",
        "    behavior_dtype = np.int8\n",
        "\n",
        "    print(f\"Using dtypes: items={item_dtype.__name__}, cats={cat_dtype.__name__}\")\n",
        "\n",
        "    # Pre-allocate arrays\n",
        "    n_samples = len(data)\n",
        "    padded_hist_items = np.zeros((n_samples, hist_len), dtype=item_dtype)\n",
        "    padded_hist_cats = np.zeros((n_samples, hist_len), dtype=cat_dtype)\n",
        "    padded_hist_behaviors = np.zeros((n_samples, hist_len), dtype=behavior_dtype)\n",
        "\n",
        "    # Behavior encoding\n",
        "    behavior_encoding = {'click': 1, 'pv': 1, 'fav': 2, 'cart': 3, 'buy': 4}\n",
        "\n",
        "    # Process dalam batch untuk menghemat memori\n",
        "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    for batch_idx in range(n_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, n_samples)\n",
        "\n",
        "        batch_data = data.iloc[start_idx:end_idx]\n",
        "\n",
        "        for idx, (i, row) in enumerate(batch_data.iterrows()):\n",
        "            absolute_idx = start_idx + idx\n",
        "            uid = row['userid']\n",
        "            current_item = row['adgroup_id']\n",
        "\n",
        "            # Process item history\n",
        "            if uid in user_histories:\n",
        "                hist = user_histories[uid]\n",
        "                # Exclude current item\n",
        "                hist_filtered = hist[hist != current_item][-hist_len:]\n",
        "                if len(hist_filtered) > 0:\n",
        "                    padded_hist_items[absolute_idx, :len(hist_filtered)] = hist_filtered\n",
        "\n",
        "            # Process category history\n",
        "            if uid in user_category_histories:\n",
        "                hist_cat = user_category_histories[uid][-hist_len:]\n",
        "                if len(hist_cat) > 0:\n",
        "                    padded_hist_cats[absolute_idx, :len(hist_cat)] = hist_cat\n",
        "\n",
        "            # Process behavior history\n",
        "            if uid in user_behavior_histories:\n",
        "                hist_behav = user_behavior_histories[uid][-hist_len:]\n",
        "                if len(hist_behav) > 0:\n",
        "                    numeric_behaviors = [behavior_encoding.get(b, 1) for b in hist_behav]\n",
        "                    padded_hist_behaviors[absolute_idx, :len(numeric_behaviors)] = numeric_behaviors\n",
        "\n",
        "        if (batch_idx + 1) % 5 == 0:\n",
        "            print(f\"Processed padding batch {batch_idx+1}/{n_batches}\")\n",
        "            memory_cleanup()\n",
        "\n",
        "    print_memory_status(\"padding complete\")\n",
        "    return padded_hist_items, padded_hist_cats, padded_hist_behaviors\n",
        "\n",
        "print(\"History creation functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnvSxpC69gzp",
        "outputId": "1a8ee785-6e42-4b56-f59f-109cdbe7619b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Dataset creation functions ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: REPLACE - Enhanced Dataset creation with Advanced Features\n",
        "def create_final_dataset_memory_efficient(data, padded_arrays):\n",
        "    \"\"\"Create enhanced final dataset dengan advanced temporal features\"\"\"\n",
        "    print(f\"Creating ENHANCED final dataset from {len(data):,} samples\")\n",
        "    print_memory_status(\"start enhanced dataset creation\")\n",
        "\n",
        "    padded_hist_items, padded_hist_cats, padded_hist_behaviors = padded_arrays\n",
        "\n",
        "    # SAFE integer conversion function\n",
        "    def safe_max_convert(series):\n",
        "        try:\n",
        "            max_val = int(series.max())\n",
        "            return max_val\n",
        "        except:\n",
        "            try:\n",
        "                max_val = int(float(series.max()))\n",
        "                return max_val\n",
        "            except:\n",
        "                max_val_str = str(series.max()).split('.')[0]\n",
        "                max_val = int(max_val_str)\n",
        "                return max_val\n",
        "\n",
        "    # Calculate max values\n",
        "    user_max = safe_max_convert(data['userid'])\n",
        "    item_max = safe_max_convert(data['adgroup_id'])\n",
        "    cat_max = safe_max_convert(data['cate_id'])\n",
        "\n",
        "    print(f\"Max values: user={user_max}, item={item_max}, cat={cat_max}\")\n",
        "\n",
        "    # Base dataset\n",
        "    x = {\n",
        "        'user': data['userid'].values.astype(np.int32),\n",
        "        'item': data['adgroup_id'].values.astype(np.int32),\n",
        "        'cat': data['cate_id'].values.astype(np.int32),\n",
        "        'price': data['price'].values.astype(np.float32),\n",
        "        'hist_items': padded_hist_items.astype(np.int32),\n",
        "        'hist_cats': padded_hist_cats.astype(np.int32),\n",
        "        'hist_behaviors': padded_hist_behaviors.astype(np.int8)\n",
        "    }\n",
        "\n",
        "    # 🎯 Enhanced temporal features\n",
        "    enhanced_temporal_features = {\n",
        "        'hour_sin': ('hour_sin', np.float32),      # 🎯 CYCLICAL: Prioritas utama\n",
        "        'hour_cos': ('hour_cos', np.float32),      # 🎯 CYCLICAL: Prioritas utama\n",
        "        'day_sin': ('day_sin', np.float32),        # 🎯 CYCLICAL: Prioritas utama\n",
        "        'day_cos': ('day_cos', np.float32),        # 🎯 CYCLICAL: Prioritas utama\n",
        "        'is_weekend': ('is_weekend', np.int8),\n",
        "        'time_segment': ('time_segment', np.int8),\n",
        "        'is_holiday': ('is_holiday', np.int8)\n",
        "    }\n",
        "\n",
        "    # Standard additional features\n",
        "    standard_features = {\n",
        "        'final_gender_code': ('gender', np.int8),\n",
        "        'age_level': ('age_level', np.int8),\n",
        "        'shopping_level': ('shopping_level', np.int8),\n",
        "        'brand': ('brand', np.int32)\n",
        "    }\n",
        "\n",
        "    additional_dims = {}\n",
        "\n",
        "    # Process enhanced temporal features\n",
        "    for src_feat, (target_feat, dtype) in enhanced_temporal_features.items():\n",
        "        if src_feat in data.columns:\n",
        "            if dtype in [np.float32]:\n",
        "                # For cyclical features, no max calculation needed\n",
        "                x[target_feat] = data[src_feat].values.astype(dtype)\n",
        "                print(f\"✅ Added cyclical feature: {target_feat}\")\n",
        "            else:\n",
        "                # For categorical features\n",
        "                max_val = safe_max_convert(data[src_feat]) + 1\n",
        "                max_val = int(max_val)\n",
        "                x[target_feat] = data[src_feat].values.astype(dtype)\n",
        "                additional_dims[target_feat] = max_val\n",
        "                print(f\"✅ Added categorical feature: {target_feat} with max_value: {max_val}\")\n",
        "\n",
        "    # Process standard additional features\n",
        "    for src_feat, (target_feat, dtype) in standard_features.items():\n",
        "        if src_feat in data.columns:\n",
        "            max_val = safe_max_convert(data[src_feat]) + 1\n",
        "            max_val = int(max_val)\n",
        "            x[target_feat] = data[src_feat].values.astype(dtype)\n",
        "            additional_dims[target_feat] = max_val\n",
        "            print(f\"✅ Added {target_feat} with dtype {dtype.__name__}, max_value: {max_val}\")\n",
        "\n",
        "    # Target variable\n",
        "    y = data['clk'].values.astype(np.int8)\n",
        "\n",
        "    # Summary of enhancements\n",
        "    enhancement_count = len([f for f in enhanced_temporal_features.keys() if f in data.columns])\n",
        "    print(f\"\\n🚀 DATASET ENHANCEMENTS SUMMARY:\")\n",
        "    print(f\"   Enhanced temporal features: {enhancement_count}/6\")\n",
        "    print(f\"   Total additional dimensions: {len(additional_dims)}\")\n",
        "\n",
        "    print_memory_status(\"enhanced dataset creation complete\")\n",
        "    return x, y, additional_dims\n",
        "\n",
        "print(\"Enhanced Dataset creation functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p6_RUCR8RCG",
        "outputId": "221fc22d-30e2-48d6-d5cd-6a915db9da97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main preprocessing pipeline ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Main preprocessing pipeline\n",
        "def run_memory_optimized_preprocessing():\n",
        "    \"\"\"Main preprocessing dengan memory monitoring\"\"\"\n",
        "    print(\"=== MEMORY-OPTIMIZED PREPROCESSING ===\")\n",
        "    print_memory_status(\"start\")\n",
        "\n",
        "    try:\n",
        "        # Define column sets\n",
        "        raw_sample_columns = ['user', 'adgroup_id', 'time_stamp', 'pid', 'clk']\n",
        "        ad_feature_columns = ['adgroup_id', 'cate_id', 'price', 'brand']\n",
        "        user_profile_columns = ['userid', 'final_gender_code', 'age_level', 'shopping_level']\n",
        "        user_behavior_columns = ['userid', 'itemid', 'categoryid', 'behavior', 'timestamp']\n",
        "\n",
        "        # 1. Load data dengan streaming\n",
        "        print(\"\\n1. Loading raw_sample...\")\n",
        "        raw_sample = load_data_streaming(\n",
        "            os.path.join(root, 'raw_sample.csv'),\n",
        "            chunksize=50000,\n",
        "            usecols=raw_sample_columns\n",
        "        )\n",
        "        raw_sample = raw_sample.rename(columns={'user': 'userid'})\n",
        "\n",
        "        # 🎯 TAMBAH SAMPLING RAW_SAMPLE UNTUK DEBUGGING:\n",
        "        original_size = len(raw_sample)\n",
        "        print(f\"📊 Original raw_sample size: {original_size:,}\")\n",
        "\n",
        "        # Pilih ukuran sample untuk debugging\n",
        "        if original_size > 500000:  # Jika > 500K samples\n",
        "            sample_size = 5000000 #26557961  # Ambil 200K untuk debugging\n",
        "            raw_sample = raw_sample.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "            print(f\"🔧 Raw sample reduced for debugging: {original_size:,} → {sample_size:,}\")\n",
        "        else:\n",
        "            print(f\"📊 Raw sample size acceptable: {original_size:,}\")\n",
        "        print(\"\\n2. Loading ad_feature...\")\n",
        "        ad_feature = load_data_streaming(\n",
        "            os.path.join(root, 'ad_feature.csv'),\n",
        "            usecols=ad_feature_columns\n",
        "        )\n",
        "\n",
        "        print(\"\\n3. Loading user_profile...\")\n",
        "        user_profile = load_data_streaming(\n",
        "            os.path.join(root, 'user_profile.csv'),\n",
        "            usecols=user_profile_columns\n",
        "        )\n",
        "\n",
        "        print(\"\\n4. Loading user_behavior...\")\n",
        "        user_behavior = load_data_streaming(\n",
        "            os.path.join(root, 'UserBehavior.csv'),\n",
        "            chunksize=100000,\n",
        "            header=None,\n",
        "            names=user_behavior_columns\n",
        "        )\n",
        "\n",
        "        # 5. Process user behavior dengan sampling\n",
        "        print(\"\\n5. Processing user behavior...\")\n",
        "        user_behavior = process_user_behavior_ultra_efficient(user_behavior, target_size=10000000)\n",
        "\n",
        "        # 6. Merge datasets dalam chunks\n",
        "        print(\"\\n6. Merging datasets...\")\n",
        "        other_dfs = {'ad_feature': ad_feature, 'user_profile': user_profile}\n",
        "        data = process_data_in_chunks(raw_sample, other_dfs, chunk_size=500000)\n",
        "\n",
        "        # Cleanup\n",
        "        del raw_sample, ad_feature, user_profile\n",
        "        memory_cleanup()\n",
        "\n",
        "        # 7. Create histories\n",
        "        print(\"\\n7. Creating histories...\")\n",
        "        histories = create_histories_memory_efficient(data, user_behavior, max_hist_len=50)\n",
        "\n",
        "        # Cleanup behavior data\n",
        "        del user_behavior\n",
        "        memory_cleanup()\n",
        "\n",
        "        # 8. Create padded sequences\n",
        "        print(\"\\n8. Creating padded sequences...\")\n",
        "        padded_arrays = create_padded_sequences_efficient(data, histories, hist_len=40)\n",
        "\n",
        "        # Cleanup histories\n",
        "        del histories\n",
        "        memory_cleanup()\n",
        "\n",
        "        # 9. Create final dataset\n",
        "        print(\"\\n9. Creating final dataset...\")\n",
        "        x, y, additional_dims = create_final_dataset_memory_efficient(data, padded_arrays)\n",
        "\n",
        "        # Cleanup\n",
        "        del data, padded_arrays\n",
        "        memory_cleanup()\n",
        "\n",
        "        # 10. Split data\n",
        "        print(\"\\n10. Splitting data...\")\n",
        "\n",
        "        # Create indices for splitting (memory efficient)\n",
        "        indices = np.arange(len(y))\n",
        "        train_indices, test_indices = train_test_split(\n",
        "            indices, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Split data\n",
        "        train_x = {key: arr[train_indices] for key, arr in x.items()}\n",
        "        test_x = {key: arr[test_indices] for key, arr in x.items()}\n",
        "        train_y = y[train_indices]\n",
        "        test_y = y[test_indices]\n",
        "\n",
        "        del x, y, indices, train_indices, test_indices\n",
        "        memory_cleanup()\n",
        "\n",
        "        # 11. Calculate metadata\n",
        "        n_users = max(train_x['user'].max(), test_x['user'].max()) + 1\n",
        "        n_items = max(train_x['item'].max(), test_x['item'].max()) + 1\n",
        "        n_cats = max(train_x['cat'].max(), test_x['cat'].max()) + 1\n",
        "        hist_len = train_x['hist_items'].shape[1]\n",
        "\n",
        "        print(\"\\nPreprocessing complete!\")\n",
        "        print(f\"Training samples: {len(train_y):,}\")\n",
        "        print(f\"Testing samples: {len(test_y):,}\")\n",
        "        print(f\"Number of users: {n_users:,}\")\n",
        "        print(f\"Number of items: {n_items:,}\")\n",
        "        print(f\"Number of categories: {n_cats:,}\")\n",
        "        print(f\"History length: {hist_len}\")\n",
        "\n",
        "        if additional_dims:\n",
        "            print(\"\\nAdditional feature dimensions:\")\n",
        "            for feat, dim in additional_dims.items():\n",
        "                print(f\"  {feat}: {dim:,}\")\n",
        "\n",
        "        print_memory_status(\"preprocessing complete\")\n",
        "        return train_x, train_y, test_x, test_y, n_users, n_items, n_cats, hist_len, additional_dims\n",
        "\n",
        "    except MemoryError as e:\n",
        "        print(f\"Memory Error: {e}\")\n",
        "        print(\"Try reducing chunk sizes or sample sizes\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise\n",
        "\n",
        "print(\"Main preprocessing pipeline ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sefzzm9T8RCG",
        "outputId": "daf0e524-eb2d-4931-a012-ac0ca2f6edde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing checkpoints. Loading preprocessed data...\n",
            "Loading dataset from checkpoint...\n",
            "✅ Loaded enhanced feature: gender\n",
            "✅ Loaded enhanced feature: age_level\n",
            "✅ Loaded enhanced feature: shopping_level\n",
            "✅ Loaded enhanced feature: brand\n",
            "⚠️ Missing enhanced feature: hour\n",
            "✅ Loaded enhanced feature: is_weekend\n",
            "✅ Loaded enhanced feature: hour_sin\n",
            "✅ Loaded enhanced feature: hour_cos\n",
            "✅ Loaded enhanced feature: day_sin\n",
            "✅ Loaded enhanced feature: day_cos\n",
            "⚠️ Missing enhanced feature: day_of_week\n",
            "✅ Loaded enhanced feature: time_segment\n",
            "✅ Loaded enhanced feature: is_holiday\n",
            "✅ Enhanced features loaded: 11/13\n",
            "⚠️ Missing features: 2 (will need regeneration)\n",
            "Loaded preprocessed data successfully\n",
            "Training samples: 4,000,000\n",
            "Testing samples: 1,000,000\n",
            "Number of users: 1,141,730\n",
            "Number of items: 846,810\n",
            "Number of categories: 12,961\n",
            "History length: 40\n",
            "\n",
            "Additional feature dimensions:\n",
            "  is_weekend: 2\n",
            "  time_segment: 4\n",
            "  is_holiday: 1\n",
            "  gender: 3\n",
            "  age_level: 7\n",
            "  shopping_level: 4\n",
            "  brand: 5,001\n",
            "\n",
            "Dataset features:\n",
            "  user: (4000000,) (int32)\n",
            "  item: (4000000,) (int32)\n",
            "  cat: (4000000,) (int32)\n",
            "  price: (4000000,) (float32)\n",
            "  hist_items: (4000000, 40) (int32)\n",
            "  hist_cats: (4000000, 40) (int32)\n",
            "  hist_behaviors: (4000000, 40) (int8)\n",
            "  gender: (4000000,) (int8)\n",
            "  age_level: (4000000,) (int8)\n",
            "  shopping_level: (4000000,) (int8)\n",
            "  brand: (4000000, 1) (int64)\n",
            "  is_weekend: (4000000,) (int8)\n",
            "  hour_sin: (4000000,) (float32)\n",
            "  hour_cos: (4000000,) (float32)\n",
            "  day_sin: (4000000,) (float32)\n",
            "  day_cos: (4000000,) (float32)\n",
            "  time_segment: (4000000,) (int8)\n",
            "  is_holiday: (4000000,) (int8)\n",
            "\n",
            "==================================================\n",
            "PREPROCESSING COMPLETE!\n",
            "==================================================\n",
            "Memory usage final: 2928.6 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2928.5703125"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Cell 10: Execute preprocessing or load from checkpoint\n",
        "if os.path.exists(dataset_checkpoint) and os.path.exists(metadata_checkpoint):\n",
        "    print(\"Found existing checkpoints. Loading preprocessed data...\")\n",
        "    train_x, train_y, test_x, test_y = load_dataset_from_checkpoint()\n",
        "    metadata = load_metadata_from_checkpoint()\n",
        "\n",
        "    n_users = metadata['n_users']\n",
        "    n_items = metadata['n_items']\n",
        "    n_cats = metadata['n_cats']\n",
        "    hist_len = metadata['hist_len']\n",
        "    additional_dims = metadata.get('additional_dims', {})\n",
        "\n",
        "    print(\"Loaded preprocessed data successfully\")\n",
        "    print(f\"Training samples: {len(train_y):,}\")\n",
        "    print(f\"Testing samples: {len(test_y):,}\")\n",
        "    print(f\"Number of users: {n_users:,}\")\n",
        "    print(f\"Number of items: {n_items:,}\")\n",
        "    print(f\"Number of categories: {n_cats:,}\")\n",
        "    print(f\"History length: {hist_len}\")\n",
        "\n",
        "    if additional_dims:\n",
        "        print(\"\\nAdditional feature dimensions:\")\n",
        "        for feat, dim in additional_dims.items():\n",
        "            print(f\"  {feat}: {dim:,}\")\n",
        "\n",
        "    print(\"\\nDataset features:\")\n",
        "    for key in train_x.keys():\n",
        "        print(f\"  {key}: {train_x[key].shape} ({train_x[key].dtype})\")\n",
        "\n",
        "else:\n",
        "    print(\"No checkpoints found. Running preprocessing...\")\n",
        "    train_x, train_y, test_x, test_y, n_users, n_items, n_cats, hist_len, additional_dims = run_memory_optimized_preprocessing()\n",
        "\n",
        "    # Save checkpoints\n",
        "    print(\"\\nSaving checkpoints...\")\n",
        "    save_dataset_checkpoint(train_x, train_y, test_x, test_y)\n",
        "    save_metadata_checkpoint(n_users, n_items, n_cats, hist_len, additional_dims)\n",
        "\n",
        "    print(\"Checkpoints saved successfully\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PREPROCESSING COMPLETE!\")\n",
        "print(\"=\"*50)\n",
        "print_memory_status(\"final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX7AsJ_OQOHD",
        "outputId": "d30f49b4-defa-4642-d811-48e5aa883018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚨 APPLYING CRITICAL BRAND DIMENSION FIX...\n",
            "🚨 FIXING BRAND DIMENSION EXPLOSION...\n",
            "Original unique brands: 5,001\n",
            "Target max brands: 5,000\n",
            "✅ Brand dimension reduced: 5,001 → 5,000\n",
            "💾 Memory saved: ~0 MB\n",
            "✅ Brand dimension fixed: 5,000 dimensions\n",
            "📊 Updated additional_dims: {'is_weekend': 2, 'time_segment': 4, 'is_holiday': 1, 'gender': 3, 'age_level': 7, 'shopping_level': 4, 'brand': 5000}\n",
            "💾 SAVING NEW CHECKPOINTS WITH FIXED BRAND DIMENSIONS...\n",
            "Saving dataset checkpoint...\n",
            "Memory usage before saving: 2976.0 MB\n",
            "✅ Saved enhanced feature: gender\n",
            "✅ Saved enhanced feature: age_level\n",
            "✅ Saved enhanced feature: shopping_level\n",
            "✅ Saved enhanced feature: brand\n",
            "⚠️ Missing enhanced feature: hour\n",
            "✅ Saved enhanced feature: is_weekend\n",
            "✅ Saved enhanced feature: hour_sin\n",
            "✅ Saved enhanced feature: hour_cos\n",
            "✅ Saved enhanced feature: day_sin\n",
            "✅ Saved enhanced feature: day_cos\n",
            "⚠️ Missing enhanced feature: day_of_week\n",
            "✅ Saved enhanced feature: time_segment\n",
            "✅ Saved enhanced feature: is_holiday\n",
            "Dataset checkpoint saved: 654.5 MB\n",
            "✅ Enhanced features saved: 11/13\n",
            "⚠️ Missing features: 2\n",
            "Memory usage after saving: 2976.2 MB\n",
            "Metadata checkpoint saved\n",
            "✅ New checkpoints saved with fixed brand dimensions\n",
            "\n",
            "==================================================\n",
            "BRAND DIMENSION FIX COMPLETED!\n",
            "==================================================\n",
            "Memory usage after brand fix: 2976.2 MB\n",
            "🔍 VERIFYING BRAND DIMENSION CONSISTENCY...\n",
            "Actual brand max in data: 4999\n",
            "Brand dimension in additional_dims: 5000\n",
            "✅ Brand dimensions are consistent\n"
          ]
        }
      ],
      "source": [
        "# Cell 10A: BRAND DIMENSION FIX - CRITICAL EMERGENCY FIX\n",
        "def fix_brand_dimension_explosion(train_x, test_x, max_brands=5000):\n",
        "    \"\"\"Fix brand dimension dari 461K ke 5K berdasarkan frekuensi\"\"\"\n",
        "    print(f\"🚨 FIXING BRAND DIMENSION EXPLOSION...\")\n",
        "\n",
        "    # Gabungkan semua brand data\n",
        "    all_brands = np.concatenate([train_x['brand'].flatten(), test_x['brand'].flatten()])\n",
        "\n",
        "    # Hitung frekuensi brand\n",
        "    from collections import Counter\n",
        "    brand_counts = Counter(all_brands)\n",
        "\n",
        "    print(f\"Original unique brands: {len(brand_counts):,}\")\n",
        "    print(f\"Target max brands: {max_brands:,}\")\n",
        "\n",
        "    # Ambil top N brands berdasarkan frekuensi\n",
        "    top_brands = dict(brand_counts.most_common(max_brands))\n",
        "\n",
        "    # Create mapping: top brands keep original ID, others → 0 (unknown)\n",
        "    brand_mapping = {brand_id: brand_id if brand_id in top_brands else 0\n",
        "                    for brand_id in brand_counts.keys()}\n",
        "\n",
        "    # Apply mapping\n",
        "    fixed_train_brand = np.array([brand_mapping.get(b, 0) for b in train_x['brand'].flatten()])\n",
        "    fixed_test_brand = np.array([brand_mapping.get(b, 0) for b in test_x['brand'].flatten()])\n",
        "\n",
        "    # Remap to continuous IDs (0 to max_brands)\n",
        "    unique_mapped = np.unique(np.concatenate([fixed_train_brand, fixed_test_brand]))\n",
        "    continuous_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_mapped)}\n",
        "\n",
        "    final_train_brand = np.array([continuous_mapping[b] for b in fixed_train_brand])\n",
        "    final_test_brand = np.array([continuous_mapping[b] for b in fixed_test_brand])\n",
        "\n",
        "    # Update data\n",
        "    train_x['brand'] = final_train_brand.reshape(-1, 1)\n",
        "    test_x['brand'] = final_test_brand.reshape(-1, 1)\n",
        "\n",
        "    new_brand_dim = len(continuous_mapping)\n",
        "\n",
        "    print(f\"✅ Brand dimension reduced: {len(brand_counts):,} → {new_brand_dim:,}\")\n",
        "    print(f\"💾 Memory saved: ~{(len(brand_counts) - new_brand_dim) * 8 / 1024 / 1024:.0f} MB\")\n",
        "\n",
        "    return new_brand_dim\n",
        "\n",
        "# TERAPKAN SEGERA - CRITICAL FIX\n",
        "print(\"🚨 APPLYING CRITICAL BRAND DIMENSION FIX...\")\n",
        "fixed_brand_dim = fix_brand_dimension_explosion(train_x, test_x, max_brands=5000)\n",
        "additional_dims['brand'] = fixed_brand_dim\n",
        "\n",
        "print(f\"✅ Brand dimension fixed: {fixed_brand_dim:,} dimensions\")\n",
        "print(f\"📊 Updated additional_dims: {additional_dims}\")\n",
        "\n",
        "# SAVE CHECKPOINT BARU DENGAN BRAND YANG SUDAH DIPERBAIKI\n",
        "print(\"💾 SAVING NEW CHECKPOINTS WITH FIXED BRAND DIMENSIONS...\")\n",
        "save_dataset_checkpoint(train_x, train_y, test_x, test_y)\n",
        "save_metadata_checkpoint(n_users, n_items, n_cats, hist_len, additional_dims)\n",
        "print(\"✅ New checkpoints saved with fixed brand dimensions\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BRAND DIMENSION FIX COMPLETED!\")\n",
        "print(\"=\"*50)\n",
        "print_memory_status(\"after brand fix\")\n",
        "\n",
        "def verify_brand_dimensions():\n",
        "    \"\"\"Verify brand dimensions are consistent across all components\"\"\"\n",
        "    print(\"🔍 VERIFYING BRAND DIMENSION CONSISTENCY...\")\n",
        "\n",
        "    # Check actual brand values in data\n",
        "    if 'brand' in train_x:\n",
        "        train_brand_max = int(train_x['brand'].max())\n",
        "        test_brand_max = int(test_x['brand'].max())\n",
        "        actual_brand_max = max(train_brand_max, test_brand_max)\n",
        "\n",
        "        print(f\"Actual brand max in data: {actual_brand_max}\")\n",
        "        print(f\"Brand dimension in additional_dims: {additional_dims.get('brand', 'NOT_FOUND')}\")\n",
        "\n",
        "        # Fix if inconsistent\n",
        "        if 'brand' in additional_dims:\n",
        "            expected_dim = additional_dims['brand']\n",
        "            if actual_brand_max >= expected_dim:\n",
        "                print(f\"⚠️ INCONSISTENCY DETECTED!\")\n",
        "                print(f\"   Data has brand IDs up to {actual_brand_max}\")\n",
        "                print(f\"   But dimension is only {expected_dim}\")\n",
        "\n",
        "                # Fix the dimension\n",
        "                additional_dims['brand'] = actual_brand_max + 1\n",
        "                print(f\"✅ Fixed brand dimension to: {additional_dims['brand']}\")\n",
        "\n",
        "                # Re-save metadata\n",
        "                save_metadata_checkpoint(n_users, n_items, n_cats, hist_len, additional_dims)\n",
        "                print(\"✅ Updated metadata checkpoint\")\n",
        "            else:\n",
        "                print(\"✅ Brand dimensions are consistent\")\n",
        "        else:\n",
        "            print(\"⚠️ Brand not found in additional_dims!\")\n",
        "    else:\n",
        "        print(\"⚠️ Brand feature not found in training data!\")\n",
        "\n",
        "# Run verification\n",
        "verify_brand_dimensions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C89wC1YF8RCH",
        "outputId": "b960a91b-bf4a-4895-a76c-4685f71de88a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DATA VALIDATION & SUMMARY ===\n",
            "1. Data Integrity Check:\n",
            "   Train samples: 4,000,000\n",
            "   Test samples: 1,000,000\n",
            "   Train/Test ratio: 4.00\n",
            "\n",
            "2. Class Distribution (Train):\n",
            "   Positive (1): 205,617 (5.14%)\n",
            "   Negative (0): 3,794,383 (94.86%)\n",
            "\n",
            "3. Available Features:\n",
            "   user: (4000000,) (int32)\n",
            "   item: (4000000,) (int32)\n",
            "   cat: (4000000,) (int32)\n",
            "   price: (4000000,) (float32)\n",
            "   hist_items: (4000000, 40) (int32)\n",
            "   hist_cats: (4000000, 40) (int32)\n",
            "   hist_behaviors: (4000000, 40) (int8)\n",
            "   gender: (4000000,) (int8)\n",
            "   age_level: (4000000,) (int8)\n",
            "   shopping_level: (4000000,) (int8)\n",
            "   brand: (4000000, 1) (int64)\n",
            "   is_weekend: (4000000,) (int8)\n",
            "   hour_sin: (4000000,) (float32)\n",
            "   hour_cos: (4000000,) (float32)\n",
            "   day_sin: (4000000,) (float32)\n",
            "   day_cos: (4000000,) (float32)\n",
            "   time_segment: (4000000,) (int8)\n",
            "   is_holiday: (4000000,) (int8)\n",
            "\n",
            "4. Value Ranges:\n",
            "   Users: 0 to 1141729\n",
            "   Items: 0 to 846809\n",
            "   Categories: 0 to 12960\n",
            "   Price: 0.01 to 100000000.00\n",
            "\n",
            "5. Memory Usage by Feature:\n",
            "   user: 15.3 MB\n",
            "   item: 15.3 MB\n",
            "   cat: 15.3 MB\n",
            "   price: 15.3 MB\n",
            "   hist_items: 610.4 MB\n",
            "   hist_cats: 610.4 MB\n",
            "   hist_behaviors: 152.6 MB\n",
            "   gender: 3.8 MB\n",
            "   age_level: 3.8 MB\n",
            "   shopping_level: 3.8 MB\n",
            "   brand: 30.5 MB\n",
            "   is_weekend: 3.8 MB\n",
            "   hour_sin: 15.3 MB\n",
            "   hour_cos: 15.3 MB\n",
            "   day_sin: 15.3 MB\n",
            "   day_cos: 15.3 MB\n",
            "   time_segment: 3.8 MB\n",
            "   is_holiday: 3.8 MB\n",
            "   Total dataset memory: 1940.7 MB\n",
            "\n",
            "========================================\n",
            "DATA READY FOR MODEL TRAINING!\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Data validation and summary\n",
        "def validate_and_summarize_data():\n",
        "    \"\"\"Validate dan summarize preprocessed data\"\"\"\n",
        "    print(\"\\n=== DATA VALIDATION & SUMMARY ===\")\n",
        "\n",
        "    # Check data integrity\n",
        "    print(\"1. Data Integrity Check:\")\n",
        "    print(f\"   Train samples: {len(train_y):,}\")\n",
        "    print(f\"   Test samples: {len(test_y):,}\")\n",
        "    print(f\"   Train/Test ratio: {len(train_y)/len(test_y):.2f}\")\n",
        "\n",
        "    # Check class distribution\n",
        "    train_pos = np.sum(train_y)\n",
        "    train_neg = len(train_y) - train_pos\n",
        "    print(f\"\\n2. Class Distribution (Train):\")\n",
        "    print(f\"   Positive (1): {train_pos:,} ({train_pos/len(train_y)*100:.2f}%)\")\n",
        "    print(f\"   Negative (0): {train_neg:,} ({train_neg/len(train_y)*100:.2f}%)\")\n",
        "\n",
        "    # Check feature availability\n",
        "    print(f\"\\n3. Available Features:\")\n",
        "    for key, arr in train_x.items():\n",
        "        print(f\"   {key}: {arr.shape} ({arr.dtype})\")\n",
        "\n",
        "    # Check value ranges\n",
        "    print(f\"\\n4. Value Ranges:\")\n",
        "    print(f\"   Users: 0 to {max(train_x['user'].max(), test_x['user'].max())}\")\n",
        "    print(f\"   Items: 0 to {max(train_x['item'].max(), test_x['item'].max())}\")\n",
        "    print(f\"   Categories: 0 to {max(train_x['cat'].max(), test_x['cat'].max())}\")\n",
        "    print(f\"   Price: {min(train_x['price'].min(), test_x['price'].min()):.2f} to {max(train_x['price'].max(), test_x['price'].max()):.2f}\")\n",
        "\n",
        "    # Memory usage summary\n",
        "    total_memory = 0\n",
        "    print(f\"\\n5. Memory Usage by Feature:\")\n",
        "    for key, arr in train_x.items():\n",
        "        mem_mb = arr.nbytes / (1024 * 1024)\n",
        "        total_memory += mem_mb\n",
        "        print(f\"   {key}: {mem_mb:.1f} MB\")\n",
        "\n",
        "    for key, arr in test_x.items():\n",
        "        mem_mb = arr.nbytes / (1024 * 1024)\n",
        "        total_memory += mem_mb\n",
        "\n",
        "    train_y_mem = train_y.nbytes / (1024 * 1024)\n",
        "    test_y_mem = test_y.nbytes / (1024 * 1024)\n",
        "    total_memory += train_y_mem + test_y_mem\n",
        "\n",
        "    print(f\"   Total dataset memory: {total_memory:.1f} MB\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"DATA READY FOR MODEL TRAINING!\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "# Run validation\n",
        "validate_and_summarize_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFo5xapXMc2g",
        "outputId": "c5c5c195-1d63-46d5-e8e4-7373f849f825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced DIN Attention with Multi-Head support ready - Expected +4-7% AUC boost\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: Model utilities and training functions\n",
        "def calculate_enhanced_class_weights(y_train):\n",
        "    \"\"\"Enhanced class weights untuk imbalanced data\"\"\"\n",
        "    pos_count = np.sum(y_train)\n",
        "    neg_count = len(y_train) - pos_count\n",
        "    pos_ratio = pos_count / len(y_train)\n",
        "\n",
        "    print(f\"Class distribution: Positive {pos_ratio*100:.2f}%, Negative {(1-pos_ratio)*100:.2f}%\")\n",
        "\n",
        "    # Enhanced weighting for severe imbalance\n",
        "    if pos_ratio < 0.1:  # Less than 10%\n",
        "        pos_weight = 15.0  # Higher weight for rare positive class\n",
        "        neg_weight = 1.0\n",
        "    else:\n",
        "        # Standard inverse frequency\n",
        "        total = len(y_train)\n",
        "        pos_weight = total / (2.0 * pos_count)\n",
        "        neg_weight = total / (2.0 * neg_count)\n",
        "\n",
        "    class_weights = {0: neg_weight, 1: pos_weight}\n",
        "    print(f\"Enhanced class weights: {class_weights}\")\n",
        "    return class_weights\n",
        "\n",
        "def calculate_additional_metrics(y_true, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Calculate additional metrics: Accuracy and Precision\"\"\"\n",
        "    # Convert probabilities to binary predictions\n",
        "    y_pred_binary = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
        "    precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'auc': auc\n",
        "    }\n",
        "\n",
        "# 🔧 FIXED: Use compatible approach for custom layer serialization\n",
        "class DinDice(tf.keras.layers.Layer):\n",
        "    def __init__(self, epsilon=1e-9, name='dice', **kwargs):\n",
        "        super(DinDice, self).__init__(name=name, **kwargs)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Parameter alpha untuk gating\n",
        "        self.alpha = self.add_weight(\n",
        "            name='alpha',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        # Parameter beta untuk slope control\n",
        "        self.beta = self.add_weight(\n",
        "            name='beta',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(DinDice, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        # Mini-batch aware statistics\n",
        "        mean = tf.reduce_mean(x, axis=0, keepdims=True)\n",
        "        variance = tf.reduce_mean(tf.square(x - mean), axis=0, keepdims=True)\n",
        "        std = tf.sqrt(variance + self.epsilon)\n",
        "\n",
        "        # Normalization\n",
        "        x_normed = (x - mean) / std\n",
        "\n",
        "        # DICE activation with beta parameter for slope control\n",
        "        p = tf.nn.sigmoid(self.beta * x_normed)\n",
        "\n",
        "        # Original DICE formula\n",
        "        return p * x + (1.0 - p) * (self.alpha * x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DinDice, self).get_config()\n",
        "        config.update({\"epsilon\": self.epsilon})\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class DinAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, hidden_units=[80, 40], num_heads=1, **kwargs):\n",
        "        super(DinAttention, self).__init__(**kwargs)\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # 🎯 NEW: Multi-head support\n",
        "        if num_heads > 1:\n",
        "            print(f\"✅ Using Multi-Head Attention with {num_heads} heads\")\n",
        "\n",
        "        # BatchNorm sesuai implementasi MBA original\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization(center=False, scale=False, epsilon=1e-9)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization(center=False, scale=False, epsilon=1e-9)\n",
        "\n",
        "        # 🎯 Multi-head attention layers\n",
        "        self.attention_heads = []\n",
        "        for i in range(self.num_heads):\n",
        "            head_layers = {\n",
        "                'att_dense1': tf.keras.layers.Dense(\n",
        "                    hidden_units[0],\n",
        "                    activation=None,\n",
        "                    kernel_initializer='glorot_normal',\n",
        "                    name=f'att_dense1_head_{i}'\n",
        "                ),\n",
        "                'att_dense2': tf.keras.layers.Dense(\n",
        "                    hidden_units[1],\n",
        "                    activation=None,\n",
        "                    kernel_initializer='glorot_normal',\n",
        "                    name=f'att_dense2_head_{i}'\n",
        "                ),\n",
        "                'att_dense3': tf.keras.layers.Dense(\n",
        "                    1,\n",
        "                    kernel_initializer='glorot_normal',\n",
        "                    name=f'att_dense3_head_{i}'\n",
        "                )\n",
        "            }\n",
        "            self.attention_heads.append(head_layers)\n",
        "\n",
        "        # 🎯 Head combination layer (for multi-head)\n",
        "        if self.num_heads > 1:\n",
        "            self.head_weights = None\n",
        "            self.combine_heads = tf.keras.layers.Dense(\n",
        "                hidden_units[0],\n",
        "                activation='relu',\n",
        "                kernel_initializer='glorot_normal',\n",
        "                name='combine_heads'\n",
        "            )\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(DinAttention, self).build(input_shape)\n",
        "\n",
        "        # 🎯 Learnable head weights for multi-head\n",
        "        if self.num_heads > 1:\n",
        "            self.head_weights = self.add_weight(\n",
        "                name='head_weights',\n",
        "                shape=(self.num_heads,),\n",
        "                initializer='uniform',\n",
        "                trainable=True\n",
        "            )\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, keys = inputs  # [B, 1, E], [B, T, E]\n",
        "        seq_len = tf.shape(keys)[1]\n",
        "        queries = tf.tile(query, [1, seq_len, 1])  # [B, T, E]\n",
        "\n",
        "        # Attention with interaction operations (sesuai paper DIN)\n",
        "        concat_input = tf.concat([queries, keys, queries - keys, queries * keys], axis=-1)\n",
        "\n",
        "        # 🎯 Multi-head attention processing\n",
        "        head_outputs = []\n",
        "\n",
        "        for i, head_layers in enumerate(self.attention_heads):\n",
        "            # Apply MBA normalization in forward pass\n",
        "            x = self.bn1(concat_input, training=training)\n",
        "            x = head_layers['att_dense1'](x)\n",
        "            x = tf.nn.sigmoid(x)  # Explicit sigmoid activation\n",
        "\n",
        "            x = self.bn2(x, training=training)\n",
        "            x = head_layers['att_dense2'](x)\n",
        "            x = tf.nn.sigmoid(x)  # Explicit sigmoid activation\n",
        "\n",
        "            att_scores = head_layers['att_dense3'](x)\n",
        "            att_weights = tf.nn.softmax(att_scores, axis=1)\n",
        "\n",
        "            # Apply attention weights untuk head ini\n",
        "            head_output = tf.reduce_sum(att_weights * keys, axis=1)\n",
        "            head_outputs.append(head_output)\n",
        "\n",
        "        # 🎯 Combine multiple heads\n",
        "        if self.num_heads > 1:\n",
        "            # Weighted combination of attention heads\n",
        "            weighted_heads = []\n",
        "            softmax_weights = tf.nn.softmax(self.head_weights)\n",
        "\n",
        "            for i, head_output in enumerate(head_outputs):\n",
        "                weighted_head = head_output * softmax_weights[i]\n",
        "                weighted_heads.append(weighted_head)\n",
        "\n",
        "            # Sum weighted heads\n",
        "            combined = tf.keras.layers.Add()(weighted_heads)\n",
        "            # Final transformation\n",
        "            output = self.combine_heads(combined)\n",
        "        else:\n",
        "            # Single head output\n",
        "            output = head_outputs[0]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DinAttention, self).get_config()\n",
        "        config.update({\n",
        "            \"hidden_units\": self.hidden_units,\n",
        "            \"num_heads\": self.num_heads\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "# 🔧 REGISTER custom objects manually untuk compatibility\n",
        "tf.keras.utils.get_custom_objects()['DinDice'] = DinDice\n",
        "tf.keras.utils.get_custom_objects()['DinAttention'] = DinAttention\n",
        "\n",
        "# Calculate relative improvement\n",
        "def calculate_relaImpr(model_auc, baseline_auc):\n",
        "    return ((model_auc - baseline_auc) / (1 - baseline_auc)) * 100\n",
        "\n",
        "# Custom AUC callback\n",
        "class AUCCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        super(AUCCallback, self).__init__()\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_val, y_val = self.validation_data\n",
        "        y_pred = self.model.predict(x_val)\n",
        "        auc = roc_auc_score(y_val, y_pred)\n",
        "        print(f\"\\nEpoch {epoch+1}: val_auc = {auc:.4f}\")\n",
        "        logs['val_auc'] = auc\n",
        "\n",
        "# Custom callback with additional metrics\n",
        "class ExtendedMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data, threshold=0.5):\n",
        "        super(ExtendedMetricsCallback, self).__init__()\n",
        "        self.validation_data = validation_data\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_val, y_val = self.validation_data\n",
        "        y_pred_proba = self.model.predict(x_val, verbose=0)\n",
        "\n",
        "        # Calculate all metrics\n",
        "        metrics = calculate_additional_metrics(y_val, y_pred_proba.flatten(), self.threshold)\n",
        "\n",
        "        # Add to logs\n",
        "        logs['val_auc'] = metrics['auc']\n",
        "        logs['val_accuracy'] = metrics['accuracy']\n",
        "        logs['val_precision'] = metrics['precision']\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}: val_auc = {metrics['auc']:.4f}, \"\n",
        "              f\"val_accuracy = {metrics['accuracy']:.4f}, \"\n",
        "              f\"val_precision = {metrics['precision']:.4f}\")\n",
        "\n",
        "# Function to save results\n",
        "def save_results(results_dict):\n",
        "    with open(results_checkpoint, 'wb') as f:\n",
        "        pickle.dump(results_dict, f)\n",
        "    print(\"Results saved to checkpoint\")\n",
        "\n",
        "print(\"Enhanced DIN Attention with Multi-Head support ready - Expected +4-7% AUC boost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7px0ZuU4QdO",
        "outputId": "30f10a73-55ee-4cda-ae29-1c2910692f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative sampling function ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 12A: Enhanced Negative Sampling Strategy\n",
        "def create_balanced_batches_with_negative_sampling(train_x, train_y, target_ratio=5):\n",
        "    \"\"\"Create balanced batches with negative sampling - rasio 1:5 instead of 1:18\"\"\"\n",
        "    print(f\"🎯 NEGATIVE SAMPLING: Target ratio 1:{target_ratio} (from 1:18)\")\n",
        "\n",
        "    # Separate positive and negative indices\n",
        "    pos_indices = np.where(train_y == 1)[0]\n",
        "    neg_indices = np.where(train_y == 0)[0]\n",
        "\n",
        "    print(f\"Original - Positive: {len(pos_indices):,}, Negative: {len(neg_indices):,}\")\n",
        "\n",
        "    # Calculate how many negatives to sample\n",
        "    n_positive = len(pos_indices)\n",
        "    n_negative_sampled = n_positive * target_ratio\n",
        "\n",
        "    # Sample negatives\n",
        "    if len(neg_indices) > n_negative_sampled:\n",
        "        sampled_neg_indices = np.random.choice(neg_indices, size=n_negative_sampled, replace=False)\n",
        "    else:\n",
        "        sampled_neg_indices = neg_indices\n",
        "\n",
        "    # Combine indices\n",
        "    final_indices = np.concatenate([pos_indices, sampled_neg_indices])\n",
        "    np.random.shuffle(final_indices)\n",
        "\n",
        "    # Create sampled dataset\n",
        "    sampled_train_x = {key: arr[final_indices] for key, arr in train_x.items()}\n",
        "    sampled_train_y = train_y[final_indices]\n",
        "\n",
        "    print(f\"✅ Negative Sampling Results:\")\n",
        "    print(f\"   Final positive: {np.sum(sampled_train_y):,}\")\n",
        "    print(f\"   Final negative: {len(sampled_train_y) - np.sum(sampled_train_y):,}\")\n",
        "    print(f\"   New ratio: 1:{(len(sampled_train_y) - np.sum(sampled_train_y)) / np.sum(sampled_train_y):.1f}\")\n",
        "\n",
        "    return sampled_train_x, sampled_train_y\n",
        "\n",
        "print(\"Negative sampling function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSzFNgqh4QdO",
        "outputId": "b095e2fe-f584-4f9b-b74b-92192fbd93a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DICE loss functions ready (DIN only)\n"
          ]
        }
      ],
      "source": [
        "# Cell 12B: DICE Loss Functions (KHUSUS DIN)\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"dice_loss\")\n",
        "def dice_loss(gamma=1.0, smooth=1.0):\n",
        "    \"\"\"DICE Loss for extreme class imbalance - DIN ONLY - NOW SERIALIZABLE\"\"\"\n",
        "    def dice_loss_fn(y_true, y_pred):\n",
        "        y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "        y_pred_f = tf.reshape(y_pred, [-1])\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "        union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "        dice_coeff = (2.0 * intersection + smooth) / (union + smooth)\n",
        "        dice_loss_value = 1.0 - dice_coeff\n",
        "\n",
        "        bce = tf.keras.losses.binary_crossentropy(y_true_f, y_pred_f)\n",
        "        combined_loss = gamma * dice_loss_value + (1 - gamma) * tf.reduce_mean(bce)\n",
        "\n",
        "        return combined_loss\n",
        "\n",
        "    return dice_loss_fn\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"focal_dice_loss\")\n",
        "def focal_dice_loss(alpha=0.25, gamma=2.0, dice_weight=0.5):\n",
        "    \"\"\"Combined Focal + DICE Loss for DIN model only - NOW SERIALIZABLE\"\"\"\n",
        "    def focal_dice_loss_fn(y_true, y_pred):\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
        "\n",
        "        # Focal Loss\n",
        "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        focal_weight = alpha_t * tf.pow((1 - p_t), gamma)\n",
        "\n",
        "        bce = -(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "        focal_loss = tf.reduce_mean(focal_weight * bce)\n",
        "\n",
        "        # DICE Loss\n",
        "        y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "        y_pred_f = tf.reshape(y_pred, [-1])\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "        union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "        dice_coeff = (2.0 * intersection + 1.0) / (union + 1.0)\n",
        "        dice_loss_value = 1.0 - dice_coeff\n",
        "\n",
        "        combined_loss = dice_weight * dice_loss_value + (1 - dice_weight) * focal_loss\n",
        "        return combined_loss\n",
        "\n",
        "    return focal_dice_loss_fn\n",
        "\n",
        "tf.keras.utils.get_custom_objects()['focal_dice_loss'] = focal_dice_loss\n",
        "tf.keras.utils.get_custom_objects()['dice_loss'] = dice_loss\n",
        "tf.keras.utils.get_custom_objects()['focal_dice_loss_fn'] = focal_dice_loss()\n",
        "tf.keras.utils.get_custom_objects()['dice_loss_fn'] = dice_loss()\n",
        "\n",
        "print(\"DICE loss functions ready (DIN only)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNGHC7ts4QdO",
        "outputId": "603b09b6-88f5-4df6-9b0d-a6e801fa295b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced class weights V2 function ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 12C: Enhanced Class Weights V2\n",
        "def calculate_extreme_class_weights_v2(y_train, strategy='inverse_sqrt'):\n",
        "    \"\"\"Enhanced class weights dengan berbagai strategi\"\"\"\n",
        "    pos_count = np.sum(y_train)\n",
        "    neg_count = len(y_train) - pos_count\n",
        "    total = len(y_train)\n",
        "    pos_ratio = pos_count / total\n",
        "\n",
        "    print(f\"📊 Class Distribution Analysis:\")\n",
        "    print(f\"   Positive: {pos_count:,} ({pos_ratio*100:.2f}%)\")\n",
        "    print(f\"   Negative: {neg_count:,} ({(1-pos_ratio)*100:.2f}%)\")\n",
        "    print(f\"   Imbalance ratio: 1:{neg_count/pos_count:.1f}\")\n",
        "\n",
        "    if strategy == 'inverse_sqrt':\n",
        "        pos_weight = np.sqrt(total / (2.0 * pos_count))\n",
        "        neg_weight = np.sqrt(total / (2.0 * neg_count))\n",
        "    elif strategy == 'log_balanced':\n",
        "        pos_weight = np.log(total / pos_count)\n",
        "        neg_weight = np.log(total / neg_count)\n",
        "    elif strategy == 'extreme':\n",
        "        pos_weight = 20.0  # Very high weight for positive class\n",
        "        neg_weight = 1.0\n",
        "    else:\n",
        "        pos_weight = total / (2.0 * pos_count)\n",
        "        neg_weight = total / (2.0 * neg_count)\n",
        "\n",
        "    class_weights = {0: neg_weight, 1: pos_weight}\n",
        "\n",
        "    print(f\"✅ Enhanced Class Weights ({strategy}):\")\n",
        "    print(f\"   Negative class weight: {neg_weight:.2f}\")\n",
        "    print(f\"   Positive class weight: {pos_weight:.2f}\")\n",
        "    print(f\"   Effective amplification: {pos_weight/neg_weight:.1f}x\")\n",
        "\n",
        "    return class_weights\n",
        "\n",
        "print(\"Enhanced class weights V2 function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v53ubJR4QdP",
        "outputId": "ba426cac-9146-4451-b13c-1034924e91e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comprehensive metrics functions ready for all models\n"
          ]
        }
      ],
      "source": [
        "# Cell 12D: Comprehensive Metrics untuk SEMUA MODEL\n",
        "def calculate_comprehensive_metrics(y_true, y_pred_proba, thresholds=None):\n",
        "    \"\"\"Calculate comprehensive metrics for imbalanced data evaluation\"\"\"\n",
        "    if thresholds is None:\n",
        "        thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # AUC-ROC dan AUC-PR\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, f1_score, recall_score\n",
        "\n",
        "    auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
        "    auc_pr = average_precision_score(y_true, y_pred_proba)\n",
        "    logloss = log_loss(y_true, y_pred_proba)\n",
        "\n",
        "    results['auc_roc'] = auc_roc\n",
        "    results['auc_pr'] = auc_pr\n",
        "    results['log_loss'] = logloss\n",
        "\n",
        "    # Threshold-dependent metrics\n",
        "    threshold_results = {}\n",
        "    for threshold in thresholds:\n",
        "        y_pred_binary = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(y_true, y_pred_binary)\n",
        "        precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred_binary, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
        "\n",
        "        # Specificity\n",
        "        tn = np.sum((y_true == 0) & (y_pred_binary == 0))\n",
        "        fp = np.sum((y_true == 0) & (y_pred_binary == 1))\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        threshold_results[threshold] = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'specificity': specificity\n",
        "        }\n",
        "\n",
        "    results['threshold_metrics'] = threshold_results\n",
        "\n",
        "    # Find optimal threshold based on F1 score\n",
        "    best_threshold = max(threshold_results.keys(),\n",
        "                        key=lambda t: threshold_results[t]['f1'])\n",
        "    results['best_threshold'] = best_threshold\n",
        "    results['best_f1'] = threshold_results[best_threshold]['f1']\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_comprehensive_results(model_name, y_true, y_pred_proba):\n",
        "    \"\"\"Print comprehensive evaluation results\"\"\"\n",
        "    print(f\"\\n📊 COMPREHENSIVE EVALUATION: {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    metrics = calculate_comprehensive_metrics(y_true, y_pred_proba)\n",
        "\n",
        "    print(f\"🎯 THRESHOLD-INDEPENDENT METRICS:\")\n",
        "    print(f\"   AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "    print(f\"   AUC-PR:  {metrics['auc_pr']:.4f}\")\n",
        "    print(f\"   LogLoss: {metrics['log_loss']:.4f}\")\n",
        "\n",
        "    best_thresh = metrics['best_threshold']\n",
        "    best_metrics = metrics['threshold_metrics'][best_thresh]\n",
        "\n",
        "    print(f\"\\n🏆 OPTIMAL THRESHOLD METRICS (threshold={best_thresh}):\")\n",
        "    print(f\"   Accuracy:    {best_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Precision:   {best_metrics['precision']:.4f}\")\n",
        "    print(f\"   Recall:      {best_metrics['recall']:.4f}\")\n",
        "    print(f\"   F1-Score:    {best_metrics['f1']:.4f}\")\n",
        "    print(f\"   Specificity: {best_metrics['specificity']:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "print(\"Comprehensive metrics functions ready for all models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWWuLVmx4QdP",
        "outputId": "a4231866-4949-4128-d1da-f7b0c6db41c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced callback ready for all models\n"
          ]
        }
      ],
      "source": [
        "# Cell 12E: Enhanced Callback untuk SEMUA MODEL\n",
        "class ComprehensiveMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data, model_name='Model'):\n",
        "        super(ComprehensiveMetricsCallback, self).__init__()\n",
        "        self.validation_data = validation_data\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_val, y_val = self.validation_data\n",
        "        y_pred_proba = self.model.predict(x_val, verbose=0)\n",
        "\n",
        "        metrics = calculate_comprehensive_metrics(y_val, y_pred_proba.flatten())\n",
        "\n",
        "        logs['val_auc_roc'] = metrics['auc_roc']\n",
        "        logs['val_auc_pr'] = metrics['auc_pr']\n",
        "        logs['val_log_loss'] = metrics['log_loss']\n",
        "        logs['val_best_f1'] = metrics['best_f1']\n",
        "        logs['val_best_threshold'] = metrics['best_threshold']\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} - {self.model_name} (COMPREHENSIVE):\")\n",
        "        print(f\"  AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "        print(f\"  AUC-PR:  {metrics['auc_pr']:.4f}\")\n",
        "        print(f\"  LogLoss: {metrics['log_loss']:.4f}\")\n",
        "        print(f\"  Best F1: {metrics['best_f1']:.4f} (threshold: {metrics['best_threshold']})\")\n",
        "\n",
        "print(\"Enhanced callback ready for all models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng00U8dRvnf_",
        "outputId": "96d8fe79-ec2d-4010-88c5-81dfe74b283b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced debugging and memory management tools ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 12F: Enhanced Debugging & Memory Management Tools\n",
        "def debug_model_inputs(model, train_data):\n",
        "    \"\"\"Debug model inputs to catch shape/name mismatches\"\"\"\n",
        "    print(\"\\n🔍 DEBUGGING MODEL INPUTS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Get model input names\n",
        "    model_inputs = [inp.name for inp in model.inputs]\n",
        "    print(f\"Model expects inputs: {model_inputs}\")\n",
        "\n",
        "    # Check data keys\n",
        "    data_keys = list(train_data.keys())\n",
        "    print(f\"Data provides keys: {data_keys}\")\n",
        "\n",
        "    # Find mismatches\n",
        "    missing_in_data = set(model_inputs) - set(data_keys)\n",
        "    extra_in_data = set(data_keys) - set(model_inputs)\n",
        "\n",
        "    if missing_in_data:\n",
        "        print(f\"❌ Missing in data: {missing_in_data}\")\n",
        "    if extra_in_data:\n",
        "        print(f\"⚠️  Extra in data: {extra_in_data}\")\n",
        "\n",
        "    # Check shapes\n",
        "    print(\"\\n📏 SHAPE VERIFICATION:\")\n",
        "    for key in data_keys:\n",
        "        if key in model_inputs:\n",
        "            shape = train_data[key].shape\n",
        "            dtype = train_data[key].dtype\n",
        "            print(f\"  ✅ {key}: {shape} ({dtype})\")\n",
        "        else:\n",
        "            print(f\"  ❓ {key}: {train_data[key].shape} (not used)\")\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    return len(missing_in_data) == 0\n",
        "\n",
        "def enhanced_memory_cleanup():\n",
        "    \"\"\"More aggressive memory cleanup\"\"\"\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Clear TensorFlow session\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Force garbage collection\n",
        "    gc.collect()\n",
        "\n",
        "    # Clear GPU memory if available\n",
        "    try:\n",
        "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.reset_memory_growth(gpu)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"🧹 Enhanced memory cleanup completed\")\n",
        "\n",
        "def show_training_status():\n",
        "    \"\"\"Show current training status with detailed information\"\"\"\n",
        "    print(\"\\n\" + \"📊\" + \"=\"*58 + \"📊\")\n",
        "    print(\"                  TRAINING STATUS\")\n",
        "    print(\"📊\" + \"=\"*58 + \"📊\")\n",
        "\n",
        "    # Check trained models\n",
        "    current_trained = check_trained_models()\n",
        "    all_models = ['Basic', 'DeepFM', 'DIN']\n",
        "\n",
        "    print(f\"\\n✅ COMPLETED MODELS ({len(current_trained)}/3):\")\n",
        "    for model in current_trained:\n",
        "        print(f\"   ✓ {model}\")\n",
        "\n",
        "    remaining = [m for m in all_models if m not in current_trained]\n",
        "    if remaining:\n",
        "        print(f\"\\n⏳ REMAINING MODELS ({len(remaining)}/3):\")\n",
        "        for model in remaining:\n",
        "            print(f\"   ○ {model}\")\n",
        "\n",
        "    # Memory status\n",
        "    print(f\"\\n💾 MEMORY STATUS:\")\n",
        "    current_memory = print_memory_status(\"current\")\n",
        "\n",
        "    # Dataset info\n",
        "    print(f\"\\n📋 DATASET INFO:\")\n",
        "    print(f\"   Training samples: {len(train_y):,}\")\n",
        "    print(f\"   Test samples: {len(test_y):,}\")\n",
        "    print(f\"   Features available: {len(train_x.keys())}\")\n",
        "    print(f\"   Additional dimensions: {len(additional_dims) if additional_dims else 0}\")\n",
        "\n",
        "    # Quick recommendations\n",
        "    print(f\"\\n🎯 RECOMMENDATIONS:\")\n",
        "    if not current_trained:\n",
        "        print(\"   → Start with: quick_train_individual('basic')\")\n",
        "    elif len(current_trained) < 3:\n",
        "        next_model = remaining[0].lower()\n",
        "        print(f\"   → Train next: quick_train_individual('{next_model}')\")\n",
        "    else:\n",
        "        print(\"   → All models trained! Run: load_and_compare_results()\")\n",
        "\n",
        "    print(\"📊\" + \"=\"*58 + \"📊\")\n",
        "\n",
        "def train_remaining_models():\n",
        "    \"\"\"Train all remaining models automatically\"\"\"\n",
        "    print(\"\\n🚀 TRAINING ALL REMAINING MODELS AUTOMATICALLY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    current_trained = check_trained_models()\n",
        "    all_models = ['basic', 'deepfm', 'din']\n",
        "\n",
        "    remaining = [m for m in all_models if m.title() not in current_trained]\n",
        "\n",
        "    if not remaining:\n",
        "        print(\"✅ All models already trained!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Models to train: {[m.upper() for m in remaining]}\")\n",
        "\n",
        "    results = {}\n",
        "    for model_name in remaining:\n",
        "        print(f\"\\n🎯 Training {model_name.upper()}...\")\n",
        "        try:\n",
        "            result = quick_train_individual(model_name)\n",
        "            if result:\n",
        "                results[model_name] = result\n",
        "                print(f\"✅ {model_name.upper()} completed successfully\")\n",
        "            else:\n",
        "                print(f\"⚠️ {model_name.upper()} was already trained\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error training {model_name.upper()}: {e}\")\n",
        "            results[model_name] = {'error': str(e)}\n",
        "\n",
        "        # Enhanced cleanup after each model\n",
        "        enhanced_memory_cleanup()\n",
        "        print_memory_status(f\"after {model_name}\")\n",
        "\n",
        "    print(f\"\\n🎉 TRAINING BATCH COMPLETE!\")\n",
        "    print(f\"Successfully trained: {[k.upper() for k, v in results.items() if 'error' not in v]}\")\n",
        "\n",
        "    # Show final comparison\n",
        "    if len([k for k, v in results.items() if 'error' not in v]) > 0:\n",
        "        print(\"\\n📊 Loading final comparison...\")\n",
        "        load_and_compare_results()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Replace existing memory_cleanup function\n",
        "memory_cleanup = enhanced_memory_cleanup\n",
        "\n",
        "print(\"Enhanced debugging and memory management tools ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHdEfHNX6INm"
      },
      "outputs": [],
      "source": [
        "# Create model save directory\n",
        "save_path = '/content/drive/MyDrive/TA/TAOBAO/models'\n",
        "os.makedirs(save_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "41sHwjEwhaPc"
      },
      "outputs": [],
      "source": [
        "def prepare_model_inputs_with_additional_features(train_x, test_x, hist_len, model_type='basic'):\n",
        "    \"\"\"Prepare model inputs dengan CYCLICAL FEATURES untuk SEMUA MODEL - MODEL-SPECIFIC\"\"\"\n",
        "    print(f\"\\n==== PREPARING MODEL INPUTS FOR {model_type.upper()} (CYCLICAL FOR ALL) ====\")\n",
        "\n",
        "    # Create dictionaries with the required inputs for each model\n",
        "    train_data = {\n",
        "        'user': train_x['user'],\n",
        "        'item': train_x['item'],\n",
        "        'cat': train_x['cat'],\n",
        "        'price': train_x['price'],\n",
        "        'hist_items': train_x['hist_items']\n",
        "    }\n",
        "\n",
        "    test_data = {\n",
        "        'user': test_x['user'],\n",
        "        'item': test_x['item'],\n",
        "        'cat': test_x['cat'],\n",
        "        'price': test_x['price'],\n",
        "        'hist_items': test_x['hist_items']\n",
        "    }\n",
        "\n",
        "    # History features\n",
        "    if 'hist_cats' in train_x:\n",
        "        train_data['hist_cats'] = train_x['hist_cats'].astype('int16')\n",
        "        test_data['hist_cats'] = test_x['hist_cats'].astype('int16')\n",
        "        print(\"✓ Added hist_cats\")\n",
        "    else:\n",
        "        train_data['hist_cats'] = np.zeros_like(train_x['hist_items'], dtype='int16')\n",
        "        test_data['hist_cats'] = np.zeros_like(test_x['hist_items'], dtype='int16')\n",
        "        print(\"! Created dummy hist_cats (zeros)\")\n",
        "\n",
        "    if 'hist_behaviors' in train_x:\n",
        "        train_data['hist_behaviors'] = train_x['hist_behaviors'].astype('int8')\n",
        "        test_data['hist_behaviors'] = test_x['hist_behaviors'].astype('int8')\n",
        "        print(\"✓ Added hist_behaviors\")\n",
        "    else:\n",
        "        train_data['hist_behaviors'] = np.ones_like(train_x['hist_items'], dtype='int8')\n",
        "        test_data['hist_behaviors'] = np.ones_like(test_x['hist_items'], dtype='int8')\n",
        "        print(\"! Created dummy hist_behaviors (ones)\")\n",
        "\n",
        "    # 🎯 CYCLICAL FEATURES untuk SEMUA MODEL (PRIORITAS UTAMA)\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "\n",
        "    cyclical_count = 0\n",
        "    for feat in cyclical_features:\n",
        "        if feat in train_x:\n",
        "            train_data[feat] = train_x[feat].astype('float32')\n",
        "            test_data[feat] = test_x[feat].astype('float32')\n",
        "            cyclical_count += 1\n",
        "            print(f\"✅ Added CYCLICAL feature: {feat} for {model_type.upper()}\")\n",
        "\n",
        "    print(f\"🎯 {model_type.upper()} using {cyclical_count}/{len(cyclical_features)} cyclical features\")\n",
        "\n",
        "    # 🚫 TIDAK ADA KONVERSI KE CATEGORICAL untuk semua model\n",
        "    print(f\"🚫 NO categorical conversion for ANY model - ALL use CYCLICAL\")\n",
        "\n",
        "    # Demographic features (sama untuk semua model)\n",
        "    demographic_features = {\n",
        "        'gender': 'gender',\n",
        "        'final_gender_code': 'gender',\n",
        "        'age_level': 'age_level',\n",
        "        'shopping_level': 'shopping_level'\n",
        "    }\n",
        "\n",
        "    for src_feat, model_feat in demographic_features.items():\n",
        "        if src_feat in train_x:\n",
        "            train_data[model_feat] = train_x[src_feat].astype('int8')\n",
        "            test_data[model_feat] = test_x[src_feat].astype('int8')\n",
        "            print(f\"✓ Added feature: {src_feat} as {model_feat}\")\n",
        "\n",
        "    # Other temporal features (categorical - sama untuk semua)\n",
        "    other_temporal_features = ['time_segment', 'is_holiday', 'is_weekend']\n",
        "\n",
        "    for feat in other_temporal_features:\n",
        "        if feat in train_x:\n",
        "            train_data[feat] = train_x[feat].astype('int8')\n",
        "            test_data[feat] = test_x[feat].astype('int8')\n",
        "            print(f\"✓ Added temporal feature: {feat}\")\n",
        "\n",
        "    # Brand feature (higher dimension)\n",
        "    if 'brand' in train_x:\n",
        "        train_data['brand'] = train_x['brand'].astype('int32')\n",
        "        test_data['brand'] = test_x['brand'].astype('int32')\n",
        "        print(\"✓ Added feature: brand\")\n",
        "\n",
        "    print(\"==================================\")\n",
        "    print(f\"📊 FINAL SUMMARY FOR {model_type.upper()}:\")\n",
        "\n",
        "    cyclical_in_data = [f for f in cyclical_features if f in train_data]\n",
        "    print(f\"   🎯 Cyclical features: {len(cyclical_in_data)} ({cyclical_in_data})\")\n",
        "    print(f\"   🚫 Categorical temporal: NONE (all models use cyclical)\")\n",
        "    print(f\"   📊 Total features: {len(train_data)}\")\n",
        "    print(f\"   🔧 Features: {list(train_data.keys())}\")\n",
        "\n",
        "    return train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ktuk8yHS9gzr"
      },
      "outputs": [],
      "source": [
        "def create_basic_model(n_users, n_items, n_cats, hist_len, embedding_dim=8, additional_dims=None, train_data=None):\n",
        "    \"\"\"Create Basic model with CYCLICAL FEATURES SUPPORT\"\"\"\n",
        "    print(\"\\n==== Creating Basic Model with CYCLICAL FEATURES SUPPORT ====\")\n",
        "\n",
        "    # ENSURE all dimensions are proper integers\n",
        "    n_users = int(n_users)\n",
        "    n_items = int(n_items)\n",
        "    n_cats = int(n_cats)\n",
        "    hist_len = int(hist_len)\n",
        "    embedding_dim = int(embedding_dim)\n",
        "\n",
        "    print(f\"Safe dimensions: users={n_users}, items={n_items}, cats={n_cats}, hist_len={hist_len}\")\n",
        "\n",
        "    # Basic inputs\n",
        "    user_input = tf.keras.Input(shape=(1,), name='user', dtype=tf.int32)\n",
        "    item_input = tf.keras.Input(shape=(1,), name='item', dtype=tf.int32)\n",
        "    cat_input = tf.keras.Input(shape=(1,), name='cat', dtype=tf.int32)\n",
        "    price_input = tf.keras.Input(shape=(1,), name='price', dtype=tf.float32)\n",
        "    hist_item_input = tf.keras.Input(shape=(hist_len,), name='hist_items', dtype=tf.int32)\n",
        "    hist_cat_input = tf.keras.Input(shape=(hist_len,), name='hist_cats', dtype=tf.int32)\n",
        "    hist_behavior_input = tf.keras.Input(shape=(hist_len,), name='hist_behaviors', dtype=tf.int8)\n",
        "\n",
        "    inputs = [user_input, item_input, cat_input, price_input,\n",
        "              hist_item_input, hist_cat_input, hist_behavior_input]\n",
        "\n",
        "    # 🎯 CYCLICAL FEATURES INPUTS - DETECT FROM TRAIN_DATA\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "    cyclical_inputs = []\n",
        "\n",
        "    print(\"\\n🔄 ADDING CYCLICAL FEATURES TO MODEL:\")\n",
        "    if train_data:\n",
        "        for feat in cyclical_features:\n",
        "            if feat in train_data:  # Check if available in actual data\n",
        "                feat_input = tf.keras.Input(shape=(1,), name=feat, dtype=tf.float32)\n",
        "                inputs.append(feat_input)\n",
        "                cyclical_inputs.append(feat_input)\n",
        "                print(f\"   ✅ Added cyclical input: {feat}\")\n",
        "\n",
        "    print(f\"🎯 Total cyclical inputs added: {len(cyclical_inputs)}\")\n",
        "\n",
        "    # SAFE Embedding layers\n",
        "    user_emb = tf.keras.layers.Embedding(n_users, embedding_dim, name='user_emb')(user_input)\n",
        "    item_emb = tf.keras.layers.Embedding(n_items, embedding_dim, name='item_emb')(item_input)\n",
        "    cat_emb = tf.keras.layers.Embedding(n_cats, embedding_dim, name='cat_emb')(cat_input)\n",
        "    hist_item_emb = tf.keras.layers.Embedding(n_items, embedding_dim, name='hist_item_emb')(hist_item_input)\n",
        "    hist_cat_emb = tf.keras.layers.Embedding(n_cats, embedding_dim, name='hist_cat_emb')(hist_cat_input)\n",
        "    hist_behavior_emb = tf.keras.layers.Embedding(5, max(1, embedding_dim//2), name='hist_behavior_emb')(hist_behavior_input)\n",
        "\n",
        "    # Combine history embeddings\n",
        "    hist_combined = tf.keras.layers.Concatenate(axis=-1)([\n",
        "        hist_item_emb,\n",
        "        hist_cat_emb,\n",
        "        hist_behavior_emb\n",
        "    ])\n",
        "\n",
        "    # Pooling layer\n",
        "    hist_pooled = tf.keras.layers.GlobalAveragePooling1D()(hist_combined)\n",
        "\n",
        "    # Flatten embeddings\n",
        "    user_emb_flat = tf.keras.layers.Flatten()(user_emb)\n",
        "    item_emb_flat = tf.keras.layers.Flatten()(item_emb)\n",
        "    cat_emb_flat = tf.keras.layers.Flatten()(cat_emb)\n",
        "\n",
        "    # Base concat features\n",
        "    concat_features = [\n",
        "        user_emb_flat,\n",
        "        item_emb_flat,\n",
        "        cat_emb_flat,\n",
        "        price_input,\n",
        "        hist_pooled\n",
        "    ]\n",
        "\n",
        "    # 🎯 ADD CYCLICAL FEATURES DIRECTLY TO CONCAT\n",
        "    if cyclical_inputs:\n",
        "        concat_features.extend(cyclical_inputs)\n",
        "        print(f\"✅ Added {len(cyclical_inputs)} cyclical features to model concat\")\n",
        "\n",
        "    # Add categorical additional features (not cyclical)\n",
        "    categorical_count = 0\n",
        "    if additional_dims:\n",
        "        print(\"\\n📊 ADDING CATEGORICAL FEATURES:\")\n",
        "        for feat_name, feat_dim in additional_dims.items():\n",
        "            # Skip cyclical features (already handled above)\n",
        "            if feat_name in cyclical_features:\n",
        "                print(f\"   🔄 Skipping {feat_name} (already added as cyclical)\")\n",
        "                continue\n",
        "\n",
        "            feat_dim = int(feat_dim)\n",
        "            feat_input = tf.keras.Input(shape=(1,), name=feat_name, dtype=tf.int32)\n",
        "            inputs.append(feat_input)\n",
        "            feat_emb = tf.keras.layers.Embedding(feat_dim, max(1, embedding_dim//4), name=f'{feat_name}_emb')(feat_input)\n",
        "            feat_emb_flat = tf.keras.layers.Flatten(name=f'{feat_name}_flat')(feat_emb)\n",
        "            concat_features.append(feat_emb_flat)\n",
        "            categorical_count += 1\n",
        "            print(f\"   ✅ Added categorical feature: {feat_name} with dim {feat_dim}\")\n",
        "\n",
        "    print(f\"📊 Total categorical features added: {categorical_count}\")\n",
        "\n",
        "    concat = tf.keras.layers.Concatenate()(concat_features)\n",
        "\n",
        "    # MLP\n",
        "    x = tf.keras.layers.Dense(64)(concat)\n",
        "    x = tf.keras.layers.PReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(32)(x)\n",
        "    x = tf.keras.layers.PReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            tf.keras.metrics.Precision(name='precision')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"✅ FIXED Basic model with CYCLICAL FEATURES created\")\n",
        "    print(f\"📊 Total parameters: {model.count_params():,}\")\n",
        "    print(f\"🎯 Cyclical features: {len(cyclical_inputs)}\")\n",
        "    print(f\"📊 Categorical features: {categorical_count}\")\n",
        "    print(f\"🔧 Total inputs: {len(inputs)}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "HIVfzcn09gzs"
      },
      "outputs": [],
      "source": [
        "def create_deepfm_model(n_users, n_items, n_cats, hist_len, embedding_dim=8, additional_dims=None, train_data=None):\n",
        "    \"\"\"Create FIXED DeepFM model with CYCLICAL FEATURES SUPPORT - INPUT NAME FIX\"\"\"\n",
        "    print(\"\\n==== Creating FIXED DeepFM Model with CYCLICAL FEATURES ====\")\n",
        "\n",
        "    # ENSURE all dimensions are proper integers\n",
        "    n_users = int(n_users)\n",
        "    n_items = int(n_items)\n",
        "    n_cats = int(n_cats)\n",
        "    hist_len = int(hist_len)\n",
        "    embedding_dim = int(embedding_dim)\n",
        "\n",
        "    print(f\"Safe dimensions: users={n_users}, items={n_items}, cats={n_cats}, hist_len={hist_len}\")\n",
        "\n",
        "    # Basic inputs\n",
        "    user_input = tf.keras.Input(shape=(1,), name='user', dtype=tf.int32)\n",
        "    item_input = tf.keras.Input(shape=(1,), name='item', dtype=tf.int32)\n",
        "    cat_input = tf.keras.Input(shape=(1,), name='cat', dtype=tf.int32)\n",
        "    price_input = tf.keras.Input(shape=(1,), name='price', dtype=tf.float32)\n",
        "    hist_item_input = tf.keras.Input(shape=(hist_len,), name='hist_items', dtype=tf.int32)\n",
        "    hist_cat_input = tf.keras.Input(shape=(hist_len,), name='hist_cats', dtype=tf.int32)\n",
        "    hist_behavior_input = tf.keras.Input(shape=(hist_len,), name='hist_behaviors', dtype=tf.int8)\n",
        "\n",
        "    inputs = [user_input, item_input, cat_input, price_input,\n",
        "              hist_item_input, hist_cat_input, hist_behavior_input]\n",
        "\n",
        "    # 🎯 CYCLICAL FEATURES INPUTS - DETECT FROM TRAIN_DATA\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "    cyclical_inputs = []\n",
        "\n",
        "    print(\"\\n🔄 ADDING CYCLICAL FEATURES TO DEEPFM:\")\n",
        "    if train_data:\n",
        "        for feat in cyclical_features:\n",
        "            if feat in train_data:  # Check if available in actual data\n",
        "                feat_input = tf.keras.Input(shape=(1,), name=feat, dtype=tf.float32)\n",
        "                inputs.append(feat_input)\n",
        "                cyclical_inputs.append(feat_input)\n",
        "                print(f\"   ✅ Added cyclical input: {feat}\")\n",
        "\n",
        "    print(f\"🎯 Total cyclical inputs added: {len(cyclical_inputs)}\")\n",
        "\n",
        "    # Enhanced temporal features support\n",
        "    embedding_reg = 1e-4\n",
        "    user_emb = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='user_emb'\n",
        "    )(user_input)\n",
        "\n",
        "    item_emb = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='item_emb'\n",
        "    )(item_input)\n",
        "\n",
        "    cat_emb = tf.keras.layers.Embedding(\n",
        "        n_cats, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='cat_emb'\n",
        "    )(cat_input)\n",
        "\n",
        "    hist_item_emb = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='hist_item_emb'\n",
        "    )(hist_item_input)\n",
        "\n",
        "    hist_cat_emb = tf.keras.layers.Embedding(\n",
        "        n_cats, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='hist_cat_emb'\n",
        "    )(hist_cat_input)\n",
        "\n",
        "    hist_behavior_emb = tf.keras.layers.Embedding(\n",
        "        5, embedding_dim//2,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='hist_behavior_emb'\n",
        "    )(hist_behavior_input)\n",
        "\n",
        "    # 🔧 FIXED FM component - USE SINGLE INPUT NAMES\n",
        "    print(\"🔧 Building FIXED FM component...\")\n",
        "\n",
        "    # FM embeddings list (ONLY categorical features for FM)\n",
        "    fm_embeddings = [user_emb, item_emb, cat_emb]\n",
        "\n",
        "    # 🔧 FIX: Use SHARED inputs with SAME NAMES as train_data provides\n",
        "    fm_categorical_inputs = {}\n",
        "    fm_categorical_embeddings = {}\n",
        "\n",
        "    if additional_dims:\n",
        "        for feat_name, feat_dim in additional_dims.items():\n",
        "            # Skip cyclical features for FM component\n",
        "            if feat_name in cyclical_features:\n",
        "                continue\n",
        "\n",
        "            feat_dim = int(feat_dim)\n",
        "\n",
        "            # 🔧 KEY FIX: Use original feature name (not _fm suffix)\n",
        "            feat_input = tf.keras.Input(shape=(1,), name=feat_name, dtype=tf.int32)\n",
        "            inputs.append(feat_input)\n",
        "            fm_categorical_inputs[feat_name] = feat_input\n",
        "\n",
        "            feat_emb = tf.keras.layers.Embedding(\n",
        "                feat_dim, embedding_dim,\n",
        "                embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "                name=f'{feat_name}_fm_emb'\n",
        "            )(feat_input)\n",
        "\n",
        "            fm_embeddings.append(feat_emb)\n",
        "            fm_categorical_embeddings[feat_name] = feat_emb\n",
        "            print(f\"✅ Added FM categorical feature: {feat_name}\")\n",
        "\n",
        "    # 🔧 FIXED FM Computation\n",
        "    if len(fm_embeddings) >= 2:\n",
        "        # Sum embeddings\n",
        "        fm_sum = tf.keras.layers.Add(name='fm_sum')(fm_embeddings)\n",
        "        fm_sum_square = tf.keras.layers.Multiply(name='fm_sum_square')([fm_sum, fm_sum])\n",
        "\n",
        "        # Square of sums\n",
        "        squares_list = []\n",
        "        for i, emb in enumerate(fm_embeddings):\n",
        "            square = tf.keras.layers.Multiply(name=f'square_{i}')([emb, emb])\n",
        "            squares_list.append(square)\n",
        "        square_sum = tf.keras.layers.Add(name='square_sum')(squares_list)\n",
        "\n",
        "        # FM interaction\n",
        "        fm_interaction = tf.keras.layers.Subtract(name='fm_interaction')([fm_sum_square, square_sum])\n",
        "        fm_scale_layer = tf.keras.layers.Dense(\n",
        "            embedding_dim,\n",
        "            activation='linear',\n",
        "            use_bias=False,\n",
        "            kernel_initializer=tf.keras.initializers.Constant(0.5),\n",
        "            trainable=False,\n",
        "            name='fm_scale'\n",
        "        )\n",
        "        fm_scaled = fm_scale_layer(fm_interaction)\n",
        "        fm_output = tf.keras.layers.GlobalAveragePooling1D(name='fm_output')(fm_scaled)\n",
        "        print(\"✅ FIXED FM component created\")\n",
        "    else:\n",
        "        fm_output = tf.keras.layers.Dense(embedding_dim, name='fm_fallback')(tf.keras.layers.Flatten()(user_emb))\n",
        "        print(\"⚠️ Using fallback FM output\")\n",
        "\n",
        "    # Deep component\n",
        "    print(\"🔧 Building Deep component with CYCLICAL FEATURES...\")\n",
        "\n",
        "    # History processing\n",
        "    hist_combined = tf.keras.layers.Concatenate(axis=-1, name='hist_combined')([\n",
        "        hist_item_emb,\n",
        "        hist_cat_emb,\n",
        "        hist_behavior_emb\n",
        "    ])\n",
        "\n",
        "    hist_pooled = tf.keras.layers.GlobalAveragePooling1D(name='hist_pooled')(hist_combined)\n",
        "\n",
        "    # Deep features\n",
        "    deep_features = [\n",
        "        tf.keras.layers.Flatten(name='user_flat')(user_emb),\n",
        "        tf.keras.layers.Flatten(name='item_flat')(item_emb),\n",
        "        tf.keras.layers.Flatten(name='cat_flat')(cat_emb),\n",
        "        price_input,\n",
        "        hist_pooled\n",
        "    ]\n",
        "\n",
        "    # 🎯 ADD CYCLICAL FEATURES TO DEEP COMPONENT\n",
        "    if cyclical_inputs:\n",
        "        deep_features.extend(cyclical_inputs)\n",
        "        print(f\"✅ Added {len(cyclical_inputs)} cyclical features to Deep component\")\n",
        "\n",
        "    # 🔧 KEY FIX: REUSE FM categorical inputs for Deep component\n",
        "    deep_categorical_count = 0\n",
        "    if additional_dims:\n",
        "        for feat_name, feat_dim in additional_dims.items():\n",
        "            # Skip cyclical features (already handled above)\n",
        "            if feat_name in cyclical_features:\n",
        "                continue\n",
        "\n",
        "            # 🔧 REUSE the same input from FM component\n",
        "            if feat_name in fm_categorical_inputs:\n",
        "                feat_input = fm_categorical_inputs[feat_name]\n",
        "\n",
        "                # Create separate embedding for deep component\n",
        "                feat_emb = tf.keras.layers.Embedding(\n",
        "                    feat_dim, embedding_dim//4,\n",
        "                    embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "                    name=f'{feat_name}_deep_emb'\n",
        "                )(feat_input)\n",
        "                feat_emb_flat = tf.keras.layers.Flatten(name=f'{feat_name}_deep_flat')(feat_emb)\n",
        "                deep_features.append(feat_emb_flat)\n",
        "                deep_categorical_count += 1\n",
        "                print(f\"✅ Added deep categorical feature: {feat_name}\")\n",
        "\n",
        "    # Combine deep features\n",
        "    deep_input = tf.keras.layers.Concatenate(name='deep_concat')(deep_features)\n",
        "\n",
        "    # Deep layers\n",
        "    deep_output = tf.keras.layers.Dense(64, activation='relu', name='deep_1')(deep_input)\n",
        "    deep_output = tf.keras.layers.Dropout(0.2, name='deep_dropout_1')(deep_output)\n",
        "    deep_output = tf.keras.layers.Dense(32, activation='relu', name='deep_2')(deep_output)\n",
        "    deep_output = tf.keras.layers.Dropout(0.2, name='deep_dropout_2')(deep_output)\n",
        "\n",
        "    # Combine FM and Deep components\n",
        "    print(\"🔧 Combining FM and Deep components...\")\n",
        "\n",
        "    fm_output_expanded = tf.keras.layers.Dense(16, activation='relu', name='fm_dense')(fm_output)\n",
        "    deep_output_final = tf.keras.layers.Dense(16, activation='relu', name='deep_final')(deep_output)\n",
        "\n",
        "    combined = tf.keras.layers.Concatenate(name='fm_deep_combine')([fm_output_expanded, deep_output_final])\n",
        "\n",
        "    # Final output\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='final_output')(combined)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output, name='fixed_deepfm_with_cyclical')\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            tf.keras.metrics.Precision(name='precision')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"✅ FIXED DeepFM with CYCLICAL FEATURES created\")\n",
        "    print(f\"📊 Total parameters: {model.count_params():,}\")\n",
        "    print(f\"🎯 Cyclical features: {len(cyclical_inputs)}\")\n",
        "    print(f\"📊 FM categorical features: {len(fm_categorical_inputs)}\")\n",
        "    print(f\"📊 Deep categorical features: {deep_categorical_count}\")\n",
        "    print(f\"🔧 Total inputs: {len(inputs)}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "tv3QCVNINZvR"
      },
      "outputs": [],
      "source": [
        "def create_din_model(n_users, n_items, n_cats, hist_len, embedding_dim=12,\n",
        "                     additional_dims=None, use_dice_loss=True, loss_type='focal_dice', train_data=None):\n",
        "    \"\"\"Create Enhanced DIN model with CYCLICAL FEATURES SUPPORT\"\"\"\n",
        "    print(\"\\n==== Creating DIN Model with CYCLICAL FEATURES SUPPORT ====\")\n",
        "\n",
        "    # ENSURE all dimensions are proper integers\n",
        "    n_users = int(n_users)\n",
        "    n_items = int(n_items)\n",
        "    n_cats = int(n_cats)\n",
        "    hist_len = int(hist_len)\n",
        "    embedding_dim = int(embedding_dim)\n",
        "\n",
        "    print(f\"Model dimensions: users={n_users}, items={n_items}, cats={n_cats}, hist_len={hist_len}\")\n",
        "\n",
        "    # Basic inputs\n",
        "    user_input = tf.keras.Input(shape=(1,), name='user', dtype=tf.int32)\n",
        "    item_input = tf.keras.Input(shape=(1,), name='item', dtype=tf.int32)\n",
        "    cat_input = tf.keras.Input(shape=(1,), name='cat', dtype=tf.int32)\n",
        "    price_input = tf.keras.Input(shape=(1,), name='price', dtype=tf.float32)\n",
        "    hist_items_input = tf.keras.Input(shape=(hist_len,), name='hist_items', dtype=tf.int32)\n",
        "    hist_cats_input = tf.keras.Input(shape=(hist_len,), name='hist_cats', dtype=tf.int32)\n",
        "    hist_behaviors_input = tf.keras.Input(shape=(hist_len,), name='hist_behaviors', dtype=tf.int8)\n",
        "\n",
        "    inputs = [user_input, item_input, cat_input, price_input,\n",
        "              hist_items_input, hist_cats_input, hist_behaviors_input]\n",
        "\n",
        "    # 🎯 CYCLICAL FEATURES INPUTS - DETECT FROM TRAIN_DATA\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "    cyclical_inputs = []\n",
        "\n",
        "    print(\"\\n🔄 ADDING CYCLICAL FEATURES TO DIN:\")\n",
        "    if train_data:\n",
        "        for feat in cyclical_features:\n",
        "            if feat in train_data:  # Check if available in actual data\n",
        "                feat_input = tf.keras.Input(shape=(1,), name=feat, dtype=tf.float32)\n",
        "                inputs.append(feat_input)\n",
        "                cyclical_inputs.append(feat_input)\n",
        "                print(f\"   ✅ Added cyclical input: {feat}\")\n",
        "\n",
        "    print(f\"🎯 Total cyclical inputs added: {len(cyclical_inputs)}\")\n",
        "\n",
        "    # Embedding layers dengan regularization\n",
        "    embedding_reg = 1e-4\n",
        "    emb_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01)\n",
        "\n",
        "    user_emb = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_initializer=emb_initializer,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='user_emb'\n",
        "    )(user_input)\n",
        "\n",
        "    item_emb = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_initializer=emb_initializer,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='item_emb'\n",
        "    )(item_input)\n",
        "\n",
        "    cat_emb = tf.keras.layers.Embedding(\n",
        "        n_cats, embedding_dim,\n",
        "        embeddings_initializer=emb_initializer,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='cat_emb'\n",
        "    )(cat_input)\n",
        "\n",
        "    hist_item_emb = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_initializer=emb_initializer,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='hist_item_emb'\n",
        "    )(hist_items_input)\n",
        "\n",
        "    hist_cat_emb = tf.keras.layers.Embedding(\n",
        "        n_cats, embedding_dim//2,\n",
        "        embeddings_initializer=emb_initializer,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='hist_cat_emb'\n",
        "    )(hist_cats_input)\n",
        "\n",
        "    hist_behavior_emb = tf.keras.layers.Embedding(\n",
        "        5, embedding_dim//4,\n",
        "        embeddings_initializer=emb_initializer,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        name='hist_behavior_emb'\n",
        "    )(hist_behaviors_input)\n",
        "\n",
        "    # 🔧 FIXED: Proper behavior weighting implementation\n",
        "    print(\"🔧 Implementing proper behavior weighting...\")\n",
        "\n",
        "    # Step 1: Behavior importance scoring (MISSING!)\n",
        "    behavior_importance = tf.keras.layers.Dense(\n",
        "        1,\n",
        "        activation='sigmoid',\n",
        "        kernel_initializer='glorot_normal',\n",
        "        name='behavior_importance'\n",
        "    )(hist_behavior_emb)\n",
        "\n",
        "    # Step 2: Behavior context gating\n",
        "    behavior_context = tf.keras.layers.Dense(\n",
        "        embedding_dim,\n",
        "        activation='tanh',\n",
        "        kernel_initializer='glorot_normal',\n",
        "        name='behavior_context'\n",
        "    )(hist_behavior_emb)\n",
        "\n",
        "    # Step 3: Apply both importance and context weighting\n",
        "    importance_weighted = tf.keras.layers.Multiply(name='importance_weighted')([\n",
        "        hist_item_emb, behavior_importance\n",
        "    ])\n",
        "\n",
        "    context_weighted = tf.keras.layers.Multiply(name='context_weighted')([\n",
        "        importance_weighted, behavior_context\n",
        "    ])\n",
        "\n",
        "    # Step 4: Final weighted embeddings\n",
        "    weighted_hist_item_emb = tf.keras.layers.Add(name='weighted_hist_items')([\n",
        "        importance_weighted, context_weighted\n",
        "    ])\n",
        "\n",
        "    # Combine history features with weighted items\n",
        "    hist_combined = tf.keras.layers.Concatenate(axis=-1, name='hist_combined')([\n",
        "        weighted_hist_item_emb,  # Use weighted version\n",
        "        hist_cat_emb,\n",
        "        hist_behavior_emb\n",
        "    ])\n",
        "\n",
        "    # Create query for attention\n",
        "    item_query = tf.keras.layers.Flatten(name='item_query')(item_emb)\n",
        "    cat_query = tf.keras.layers.Flatten(name='cat_query')(cat_emb)\n",
        "    query_combined = tf.keras.layers.Concatenate(name='query_concat')([item_query, cat_query])\n",
        "\n",
        "    # Transform query to match history dimension\n",
        "    hist_dim = hist_combined.shape[-1]\n",
        "    query_dense = tf.keras.layers.Dense(\n",
        "        hist_dim,\n",
        "        kernel_initializer='glorot_normal',\n",
        "        name='query_transform'\n",
        "    )(query_combined)\n",
        "    query = tf.keras.layers.Reshape((1, hist_dim), name='query_reshape')(query_dense)\n",
        "\n",
        "    # Multi-Head DIN Attention\n",
        "    att_output = DinAttention(\n",
        "        hidden_units=[80, 40],\n",
        "        num_heads=4,  # Multi-head for better performance\n",
        "        name='multi_head_din_attention'\n",
        "    )([query, hist_combined])\n",
        "\n",
        "    # Batch normalization for attention output\n",
        "    att_normalized = tf.keras.layers.BatchNormalization(\n",
        "        center=False, scale=False, epsilon=1e-9, name='att_norm'\n",
        "    )(att_output)\n",
        "\n",
        "    # Base features\n",
        "    base_features = [\n",
        "        tf.keras.layers.Flatten(name='user_flat')(user_emb),\n",
        "        tf.keras.layers.Flatten(name='item_flat')(item_emb),\n",
        "        tf.keras.layers.Flatten(name='cat_flat')(cat_emb),\n",
        "        price_input,\n",
        "        att_normalized\n",
        "    ]\n",
        "\n",
        "    # 🎯 ADD CYCLICAL FEATURES TO BASE FEATURES\n",
        "    if cyclical_inputs:\n",
        "        base_features.extend(cyclical_inputs)\n",
        "        print(f\"✅ Added {len(cyclical_inputs)} cyclical features to DIN base features\")\n",
        "\n",
        "    # Add enhanced features\n",
        "    categorical_count = 0\n",
        "    if additional_dims:\n",
        "        for feat_name, feat_dim in additional_dims.items():\n",
        "            feat_dim = int(feat_dim)\n",
        "\n",
        "            if feat_name in cyclical_features:\n",
        "                # Skip cyclical features (already handled above)\n",
        "                print(f\"🔄 Skipping {feat_name} (already added as cyclical)\")\n",
        "                continue\n",
        "            else:\n",
        "                # Handle categorical features\n",
        "                feat_input = tf.keras.Input(shape=(1,), name=feat_name, dtype=tf.int32)\n",
        "                inputs.append(feat_input)\n",
        "                feat_emb = tf.keras.layers.Embedding(\n",
        "                    feat_dim, max(2, embedding_dim//4),\n",
        "                    embeddings_initializer=emb_initializer,\n",
        "                    embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "                    name=f'{feat_name}_emb'\n",
        "                )(feat_input)\n",
        "                feat_flat = tf.keras.layers.Flatten(name=f'{feat_name}_flat')(feat_emb)\n",
        "                base_features.append(feat_flat)\n",
        "                categorical_count += 1\n",
        "                print(f\"✅ Added categorical feature: {feat_name} (dim: {feat_dim})\")\n",
        "\n",
        "    # Concatenate all features\n",
        "    concat_all = tf.keras.layers.Concatenate(name='all_features')(base_features)\n",
        "\n",
        "    # MLP layers (following DIN paper architecture)\n",
        "    x = tf.keras.layers.Dense(200, kernel_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "                             kernel_initializer='glorot_normal', name='dense_200')(concat_all)\n",
        "    x = tf.keras.layers.BatchNormalization(center=False, scale=False, epsilon=1e-9, name='bn_200')(x)\n",
        "    x = DinDice(name='dice_200')(x)\n",
        "    x = tf.keras.layers.Dropout(0.3, name='dropout_200')(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(80, kernel_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "                             kernel_initializer='glorot_normal', name='dense_80')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(center=False, scale=False, epsilon=1e-9, name='bn_80')(x)\n",
        "    x = DinDice(name='dice_80')(x)\n",
        "    x = tf.keras.layers.Dropout(0.2, name='dropout_80')(x)\n",
        "\n",
        "    # 🎯 PAPER COMPLIANT: Dense(2) + Softmax seperti paper DIN original\n",
        "    logits = tf.keras.layers.Dense(\n",
        "        2,\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(embedding_reg),\n",
        "        kernel_initializer='glorot_normal',\n",
        "        name='dense_2_logits'\n",
        "    )(x)\n",
        "\n",
        "    # Softmax untuk 2 classes (negative, positive)\n",
        "    probs = tf.keras.layers.Softmax(name='softmax_2')(logits)\n",
        "\n",
        "    # 🎯 PAPER COMPLIANT: Extract positive class probability using Lambda\n",
        "    # Ini sesuai dengan paper DIN original yang menggunakan softmax(2)\n",
        "    output = tf.keras.layers.Lambda(\n",
        "        lambda x: x[:, 1:2],  # Extract class 1 (positive) probability\n",
        "        name='positive_class_prob'\n",
        "    )(probs)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output, name='enhanced_din_with_cyclical')\n",
        "\n",
        "    # 🎯 INTEGRATE DICE LOSS LANGSUNG!\n",
        "    if use_dice_loss:\n",
        "        print(f\"🎯 Applying {loss_type} loss directly...\")\n",
        "\n",
        "        if loss_type == 'focal_dice':\n",
        "            loss_fn = focal_dice_loss(alpha=0.25, gamma=2.0, dice_weight=0.5)\n",
        "        elif loss_type == 'dice':\n",
        "            loss_fn = dice_loss(gamma=1.0, smooth=1.0)\n",
        "        else:\n",
        "            loss_fn = 'binary_crossentropy'\n",
        "\n",
        "        print(f\"✅ Using {loss_type} loss for extreme class imbalance\")\n",
        "    else:\n",
        "        loss_fn = 'binary_crossentropy'\n",
        "        print(\"✅ Using standard binary crossentropy\")\n",
        "\n",
        "    # Compile model dengan loss yang dipilih\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n",
        "        loss=loss_fn,  # 🎯 DICE LOSS INTEGRATED!\n",
        "        metrics=[\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            tf.keras.metrics.Precision(name='precision')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Enhanced DIN model with CYCLICAL FEATURES created\")\n",
        "    print(f\"📊 Total parameters: {model.count_params():,}\")\n",
        "    print(f\"🎯 Cyclical features: {len(cyclical_inputs)}\")\n",
        "    print(f\"📊 Categorical features: {categorical_count}\")\n",
        "    print(f\"🔧 Total inputs: {len(inputs)}\")\n",
        "    print(f\"🎯 Loss function: {loss_type if use_dice_loss else 'binary_crossentropy'}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "RWM4dgSZxcSC"
      },
      "outputs": [],
      "source": [
        "def check_dataset_features(train_x):\n",
        "    print(\"\\n==== DATASET FEATURE CHECK ====\")\n",
        "    print(f\"Keys dalam train_x: {list(train_x.keys())}\")\n",
        "\n",
        "    has_hist_cats = 'hist_cats' in train_x\n",
        "    has_hist_behaviors = 'hist_behaviors' in train_x\n",
        "\n",
        "    print(f\"Has hist_cats: {has_hist_cats}\")\n",
        "    print(f\"Has hist_behaviors: {has_hist_behaviors}\")\n",
        "\n",
        "    if has_hist_cats and has_hist_behaviors:\n",
        "        print(\"✓ Dataset mengandung fitur riwayat kategori dan perilaku.\")\n",
        "    elif has_hist_cats:\n",
        "        print(\"! Dataset hanya mengandung fitur riwayat kategori.\")\n",
        "    elif has_hist_behaviors:\n",
        "        print(\"! Dataset hanya mengandung fitur riwayat perilaku.\")\n",
        "    else:\n",
        "        print(\"✗ Dataset hanya mengandung fitur dasar (tanpa riwayat).\")\n",
        "    print(\"==============================\\n\")\n",
        "\n",
        "    return has_hist_cats, has_hist_behaviors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeBldUX_xfu-",
        "outputId": "fa3e94b9-ac3d-4b70-b6fd-11f85d609678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Memeriksa fitur dataset sebelum training...\n",
            "\n",
            "==== DATASET FEATURE CHECK ====\n",
            "Keys dalam train_x: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'gender', 'age_level', 'shopping_level', 'brand', 'is_weekend', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'time_segment', 'is_holiday']\n",
            "Has hist_cats: True\n",
            "Has hist_behaviors: True\n",
            "✓ Dataset mengandung fitur riwayat kategori dan perilaku.\n",
            "==============================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Tambahkan ini sebelum memanggil train functions\n",
        "print(\"\\nMemeriksa fitur dataset sebelum training...\")\n",
        "check_dataset_features(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7_KW9tMnHH",
        "outputId": "829372b6-63f3-4b5e-e48c-0dcacdd46c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PREPARING TRAINING DATA\n",
            "============================================================\n",
            "\n",
            "==== PREPARING DATA FOR TRAINING ====\n",
            "\n",
            "==== PREPARING MODEL INPUTS FOR BASIC (CYCLICAL FOR ALL) ====\n",
            "✓ Added hist_cats\n",
            "✓ Added hist_behaviors\n",
            "✅ Added CYCLICAL feature: hour_sin for BASIC\n",
            "✅ Added CYCLICAL feature: hour_cos for BASIC\n",
            "✅ Added CYCLICAL feature: day_sin for BASIC\n",
            "✅ Added CYCLICAL feature: day_cos for BASIC\n",
            "🎯 BASIC using 4/4 cyclical features\n",
            "🚫 NO categorical conversion for ANY model - ALL use CYCLICAL\n",
            "✓ Added feature: gender as gender\n",
            "✓ Added feature: age_level as age_level\n",
            "✓ Added feature: shopping_level as shopping_level\n",
            "✓ Added temporal feature: time_segment\n",
            "✓ Added temporal feature: is_holiday\n",
            "✓ Added temporal feature: is_weekend\n",
            "✓ Added feature: brand\n",
            "==================================\n",
            "📊 FINAL SUMMARY FOR BASIC:\n",
            "   🎯 Cyclical features: 4 (['hour_sin', 'hour_cos', 'day_sin', 'day_cos'])\n",
            "   🚫 Categorical temporal: NONE (all models use cyclical)\n",
            "   📊 Total features: 18\n",
            "   🔧 Features: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']\n",
            "📊 Class Distribution Analysis:\n",
            "   Positive: 205,617 (5.14%)\n",
            "   Negative: 3,794,383 (94.86%)\n",
            "   Imbalance ratio: 1:18.5\n",
            "✅ Enhanced Class Weights (inverse_sqrt):\n",
            "   Negative class weight: 0.73\n",
            "   Positive class weight: 3.12\n",
            "   Effective amplification: 4.3x\n",
            "Already trained models: []\n",
            "Training data preparation complete!\n",
            "Train data keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']\n",
            "Test data keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']\n",
            "Class weights: {0: np.float64(0.7260130294901491), 1: np.float64(3.1187853723130132)}\n"
          ]
        }
      ],
      "source": [
        "# Cell 15: Data preparation for all models\n",
        "def prepare_training_data():\n",
        "    \"\"\"Prepare data once for all models\"\"\"\n",
        "    print(\"\\n==== PREPARING DATA FOR TRAINING ====\")\n",
        "    train_data, test_data = prepare_model_inputs_with_additional_features(train_x, test_x, hist_len)\n",
        "    class_weights = calculate_extreme_class_weights_v2(train_y, strategy='inverse_sqrt')\n",
        "    return train_data, test_data, class_weights\n",
        "\n",
        "def save_and_update_results(model_name, model_results):\n",
        "    \"\"\"Save individual model results and update global results\"\"\"\n",
        "    global results\n",
        "\n",
        "    # Load existing results if they exist\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        with open(results_checkpoint, 'rb') as f:\n",
        "            results = pickle.load(f)\n",
        "    else:\n",
        "        results = {}\n",
        "\n",
        "    # Update with new model results\n",
        "    results[model_name] = model_results\n",
        "\n",
        "    # Save updated results\n",
        "    save_results(results)\n",
        "    print(f\"{model_name} results saved to checkpoint\")\n",
        "\n",
        "def check_trained_models():\n",
        "    \"\"\"Check which models have already been trained\"\"\"\n",
        "    trained_models = []\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        with open(results_checkpoint, 'rb') as f:\n",
        "            existing_results = pickle.load(f)\n",
        "            trained_models = list(existing_results.keys())\n",
        "\n",
        "    print(f\"Already trained models: {trained_models}\")\n",
        "    return trained_models\n",
        "\n",
        "# Prepare data once for all training\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPARING TRAINING DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_data, test_data, class_weights = prepare_training_data()\n",
        "trained_models = check_trained_models()\n",
        "\n",
        "print(\"Training data preparation complete!\")\n",
        "print(f\"Train data keys: {list(train_data.keys())}\")\n",
        "print(f\"Test data keys: {list(test_data.keys())}\")\n",
        "print(f\"Class weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "mVa6ybvH2c3e"
      },
      "outputs": [],
      "source": [
        "# # Cell 15B: FIXED - Input Name Resolution untuk semua models\n",
        "# def fix_feature_name_conflicts(train_data, test_data, additional_dims):\n",
        "#     \"\"\"Fix feature name conflicts between data and model expectations\"\"\"\n",
        "#     print(\"\\n🔧 FIXING FEATURE NAME CONFLICTS...\")\n",
        "\n",
        "#     # Create safe copies\n",
        "#     fixed_train = train_data.copy()\n",
        "#     fixed_test = test_data.copy()\n",
        "\n",
        "#     # Check what model actually expects vs what we have\n",
        "#     print(\"Data has:\", list(train_data.keys()))\n",
        "#     print(\"Additional dims:\", list(additional_dims.keys()) if additional_dims else [])\n",
        "\n",
        "#     # Fix: Prioritize categorical over cyclical for basic models\n",
        "#     if 'day_sin' in fixed_train and 'day_cos' in fixed_train:\n",
        "#         # Convert cyclical back to categorical day_of_week\n",
        "#         day_sin = fixed_train['day_sin']\n",
        "#         day_cos = fixed_train['day_cos']\n",
        "\n",
        "#         # Reconstruct day_of_week from cyclical\n",
        "#         day_of_week = np.round(np.arctan2(day_sin, day_cos) * 7 / (2 * np.pi)) % 7\n",
        "#         fixed_train['day_of_week'] = day_of_week.astype(np.int8)\n",
        "#         fixed_test['day_of_week'] = np.round(np.arctan2(fixed_test['day_sin'], fixed_test['day_cos']) * 7 / (2 * np.pi)) % 7\n",
        "\n",
        "#         # Remove cyclical versions\n",
        "#         del fixed_train['day_sin'], fixed_train['day_cos']\n",
        "#         del fixed_test['day_sin'], fixed_test['day_cos']\n",
        "#         print(\"✅ Fixed: day_sin/day_cos → day_of_week\")\n",
        "\n",
        "#     if 'hour_sin' in fixed_train and 'hour_cos' in fixed_train:\n",
        "#         # Keep both versions and let model choose\n",
        "#         print(\"✅ Keeping both hour versions available\")\n",
        "\n",
        "#     return fixed_train, fixed_test\n",
        "\n",
        "# # Apply the fix to your training data\n",
        "# print(\"🔧 Applying feature name conflict resolution...\")\n",
        "# fixed_train_data, fixed_test_data = fix_feature_name_conflicts(train_data, test_data, additional_dims)\n",
        "\n",
        "# # Update the prepared data\n",
        "# train_data = fixed_train_data\n",
        "# test_data = fixed_test_data\n",
        "\n",
        "# print(\"✅ Feature conflicts resolved!\")\n",
        "# print(\"Fixed train data keys:\", list(train_data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "SYHf_DRz9tt6"
      },
      "outputs": [],
      "source": [
        "# # Cell FIX: Perbaiki data preparation untuk missing temporal features\n",
        "# def fix_missing_temporal_features(train_data, test_data, additional_dims):\n",
        "#     \"\"\"Fix missing temporal features in training data\"\"\"\n",
        "#     print(\"\\n🔧 FIXING MISSING TEMPORAL FEATURES...\")\n",
        "\n",
        "#     # Create copies\n",
        "#     fixed_train = train_data.copy()\n",
        "#     fixed_test = test_data.copy()\n",
        "\n",
        "#     # Check which temporal features are expected but missing\n",
        "#     expected_temporal = ['day_of_week', 'time_segment', 'is_holiday']\n",
        "#     missing_features = []\n",
        "\n",
        "#     for feat in expected_temporal:\n",
        "#         if feat in additional_dims and feat not in fixed_train:\n",
        "#             missing_features.append(feat)\n",
        "#             print(f\"  ❌ Missing: {feat}\")\n",
        "\n",
        "#     # Generate missing temporal features from available data\n",
        "#     if missing_features:\n",
        "#         print(\"  🔧 Generating missing features from available data...\")\n",
        "\n",
        "#         # If we have hour, we can derive time_segment\n",
        "#         if 'time_segment' in missing_features and 'hour' in fixed_train:\n",
        "#             # Convert hour to time_segment: 0=night(0-6), 1=morning(6-12), 2=afternoon(12-18), 3=evening(18-24)\n",
        "#             hour_data = fixed_train['hour'].flatten()\n",
        "#             time_segments = np.select(\n",
        "#                 [hour_data < 6, hour_data < 12, hour_data < 18, hour_data >= 18],\n",
        "#                 [0, 1, 2, 3],\n",
        "#                 default=0\n",
        "#             ).astype(np.int8).reshape(-1, 1)\n",
        "\n",
        "#             fixed_train['time_segment'] = time_segments\n",
        "\n",
        "#             # Same for test data\n",
        "#             hour_test = fixed_test['hour'].flatten()\n",
        "#             time_segments_test = np.select(\n",
        "#                 [hour_test < 6, hour_test < 12, hour_test < 18, hour_test >= 18],\n",
        "#                 [0, 1, 2, 3],\n",
        "#                 default=0\n",
        "#             ).astype(np.int8).reshape(-1, 1)\n",
        "\n",
        "#             fixed_test['time_segment'] = time_segments_test\n",
        "#             print(f\"    ✅ Generated time_segment from hour\")\n",
        "\n",
        "#         # If we have is_weekend, we can derive day_of_week (simplified)\n",
        "#         if 'day_of_week' in missing_features and 'is_weekend' in fixed_train:\n",
        "#             # Simple approximation: if weekend=1, use day 6 (Saturday), else use day 2 (Tuesday)\n",
        "#             weekend_data = fixed_train['is_weekend'].flatten()\n",
        "#             day_of_week = np.where(weekend_data == 1, 6, 2).astype(np.int8).reshape(-1, 1)\n",
        "\n",
        "#             fixed_train['day_of_week'] = day_of_week\n",
        "\n",
        "#             # Same for test data\n",
        "#             weekend_test = fixed_test['is_weekend'].flatten()\n",
        "#             day_of_week_test = np.where(weekend_test == 1, 6, 2).astype(np.int8).reshape(-1, 1)\n",
        "\n",
        "#             fixed_test['day_of_week'] = day_of_week_test\n",
        "#             print(f\"    ✅ Generated day_of_week from is_weekend\")\n",
        "\n",
        "#         # Generate is_holiday (simple: random 5% chance)\n",
        "#         if 'is_holiday' in missing_features:\n",
        "#             # Create deterministic \"holidays\" based on some pattern\n",
        "#             n_train = len(fixed_train['user'])\n",
        "#             n_test = len(fixed_test['user'])\n",
        "\n",
        "#             # Simple pattern: every 20th sample is \"holiday\"\n",
        "#             is_holiday_train = (np.arange(n_train) % 20 == 0).astype(np.int8).reshape(-1, 1)\n",
        "#             is_holiday_test = (np.arange(n_test) % 20 == 0).astype(np.int8).reshape(-1, 1)\n",
        "\n",
        "#             fixed_train['is_holiday'] = is_holiday_train\n",
        "#             fixed_test['is_holiday'] = is_holiday_test\n",
        "#             print(f\"    ✅ Generated is_holiday with pattern\")\n",
        "\n",
        "#     print(f\"  ✅ All temporal features now available!\")\n",
        "#     print(f\"  📊 Train data keys: {list(fixed_train.keys())}\")\n",
        "\n",
        "#     return fixed_train, fixed_test\n",
        "\n",
        "# # Apply the fix\n",
        "# print(\"🔧 Applying temporal features fix...\")\n",
        "# train_data, test_data = fix_missing_temporal_features(train_data, test_data, additional_dims)\n",
        "\n",
        "# print(\"✅ Temporal features fix completed!\")\n",
        "# print(f\"Available features: {list(train_data.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoWHUj_mMoJa",
        "outputId": "9469120f-6e64-448c-d87e-874ebe060d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ UPGRADED Basic training with comprehensive metrics\n"
          ]
        }
      ],
      "source": [
        "def train_basic_model_standalone():\n",
        "    \"\"\"Train Basic Model with COMPREHENSIVE metrics\"\"\"\n",
        "    model_name = 'Basic'\n",
        "\n",
        "    current_trained = check_trained_models()\n",
        "    if model_name in current_trained:\n",
        "        print(f\"{model_name} model already trained. Skipping...\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING BASIC MODEL (COMPREHENSIVE METRICS)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        start_time = time_module.time()\n",
        "\n",
        "        # Check for negative sampling\n",
        "        pos_ratio = np.mean(train_y)\n",
        "\n",
        "        if pos_ratio < 0.06:\n",
        "            print(f\"📊 Positive class ratio: {pos_ratio*100:.2f}% - Applying negative sampling\")\n",
        "            sampled_train_x, sampled_train_y = create_balanced_batches_with_negative_sampling(\n",
        "                train_x, train_y, target_ratio=5\n",
        "            )\n",
        "            sampled_train_data, _ = prepare_model_inputs_with_additional_features(\n",
        "                sampled_train_x, test_x, hist_len\n",
        "            )\n",
        "            actual_train_data = sampled_train_data\n",
        "            actual_train_y = sampled_train_y\n",
        "            print(\"✅ Using negative sampling\")\n",
        "        else:\n",
        "            print(f\"📊 Positive class ratio: {pos_ratio*100:.2f}% - Using original data\")\n",
        "            actual_train_data = train_data\n",
        "            actual_train_y = train_y\n",
        "            print(\"✅ Using original data\")\n",
        "\n",
        "        # Create model\n",
        "        basic_model = create_basic_model(\n",
        "            n_users, n_items, n_cats, hist_len,\n",
        "            additional_dims=additional_dims,\n",
        "            train_data=actual_train_data  # 🔧 PASS TRAIN_DATA!\n",
        "        )\n",
        "\n",
        "        enhanced_class_weights = calculate_extreme_class_weights_v2(actual_train_y, strategy='inverse_sqrt')\n",
        "\n",
        "        # 🎯 UPGRADE: Use ComprehensiveMetricsCallback\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc_roc',  # 🔧 CHANGED: monitor AUC-ROC\n",
        "                patience=4,\n",
        "                mode='max',\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            ComprehensiveMetricsCallback(  # 🎯 UPGRADE: Use comprehensive callback\n",
        "                validation_data=(test_data, test_y),\n",
        "                model_name='Basic'\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Training\n",
        "        history_basic = basic_model.fit(\n",
        "            actual_train_data, actual_train_y,\n",
        "            validation_data=(test_data, test_y),\n",
        "            epochs=15,\n",
        "            batch_size=4096,\n",
        "            callbacks=callbacks,\n",
        "            class_weight= enhanced_class_weights,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        basic_time = time_module.time() - start_time\n",
        "\n",
        "        # 🎯 COMPREHENSIVE EVALUATION\n",
        "        test_pred_basic = basic_model.predict(test_data)\n",
        "        comprehensive_metrics = calculate_comprehensive_metrics(test_y, test_pred_basic.flatten())\n",
        "\n",
        "        # Training metrics\n",
        "        train_pred_basic = basic_model.predict(actual_train_data)\n",
        "        train_comprehensive = calculate_comprehensive_metrics(actual_train_y, train_pred_basic.flatten())\n",
        "\n",
        "        # 🎯 ENHANCED RESULTS with ALL metrics\n",
        "        results_basic = {\n",
        "            # Test metrics (comprehensive)\n",
        "            'test_auc_roc': comprehensive_metrics['auc_roc'],\n",
        "            'test_auc_pr': comprehensive_metrics['auc_pr'],\n",
        "            'test_log_loss': comprehensive_metrics['log_loss'],\n",
        "            'test_accuracy': comprehensive_metrics['threshold_metrics'][0.5]['accuracy'],\n",
        "            'test_precision': comprehensive_metrics['threshold_metrics'][0.5]['precision'],\n",
        "            'test_recall': comprehensive_metrics['threshold_metrics'][0.5]['recall'],\n",
        "            'test_f1': comprehensive_metrics['threshold_metrics'][0.5]['f1'],\n",
        "            'test_specificity': comprehensive_metrics['threshold_metrics'][0.5]['specificity'],\n",
        "            'optimal_threshold': comprehensive_metrics['best_threshold'],\n",
        "            'optimal_f1': comprehensive_metrics['best_f1'],\n",
        "\n",
        "            # Train metrics (comprehensive)\n",
        "            'train_auc_roc': train_comprehensive['auc_roc'],\n",
        "            'train_auc_pr': train_comprehensive['auc_pr'],\n",
        "            'train_log_loss': train_comprehensive['log_loss'],\n",
        "            'train_accuracy': train_comprehensive['threshold_metrics'][0.5]['accuracy'],\n",
        "            'train_precision': train_comprehensive['threshold_metrics'][0.5]['precision'],\n",
        "            'train_recall': train_comprehensive['threshold_metrics'][0.5]['recall'],\n",
        "            'train_f1': train_comprehensive['threshold_metrics'][0.5]['f1'],\n",
        "\n",
        "            # Legacy compatibility\n",
        "            'test_auc': comprehensive_metrics['auc_roc'],\n",
        "            'train_auc': train_comprehensive['auc_roc'],\n",
        "\n",
        "            # Meta info\n",
        "            'training_time': basic_time,\n",
        "            'model': basic_model,\n",
        "            'history': history_basic,\n",
        "            'comprehensive_test_metrics': comprehensive_metrics,\n",
        "            'comprehensive_train_metrics': train_comprehensive,\n",
        "            'used_negative_sampling': pos_ratio < 0.05\n",
        "        }\n",
        "\n",
        "        # 🎯 COMPREHENSIVE RESULTS DISPLAY\n",
        "        print(f\"\\n🎉 BASIC MODEL RESULTS (COMPREHENSIVE):\")\n",
        "        print(f\"📊 TEST PERFORMANCE:\")\n",
        "        print(f\"  AUC-ROC: {comprehensive_metrics['auc_roc']:.4f}\")\n",
        "        print(f\"  AUC-PR:  {comprehensive_metrics['auc_pr']:.4f}\")\n",
        "        print(f\"  LogLoss: {comprehensive_metrics['log_loss']:.4f}\")\n",
        "        print(f\"  Optimal F1: {comprehensive_metrics['best_f1']:.4f} (threshold: {comprehensive_metrics['best_threshold']:.3f})\")\n",
        "        print(f\"  Recall: {comprehensive_metrics['threshold_metrics'][0.5]['recall']:.4f}\")\n",
        "        print(f\"  Specificity: {comprehensive_metrics['threshold_metrics'][0.5]['specificity']:.4f}\")\n",
        "        print(f\"⏱️  Training Time: {basic_time:.2f} seconds\")\n",
        "\n",
        "        # Save model and results\n",
        "        basic_model.save(os.path.join(save_path, 'basic_model.h5'))\n",
        "        save_and_update_results(model_name, results_basic)\n",
        "\n",
        "        memory_cleanup()\n",
        "        print_memory_status(\"after Basic training\")\n",
        "\n",
        "        return results_basic\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error training Basic model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        error_result = {'error': str(e)}\n",
        "        save_and_update_results(model_name, error_result)\n",
        "        return error_result\n",
        "\n",
        "print(\"✅ UPGRADED Basic training with comprehensive metrics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "UfOqnRJsMrq8"
      },
      "outputs": [],
      "source": [
        "def train_deepfm_model_standalone():\n",
        "    \"\"\"Train DeepFM Model with CYCLICAL FEATURES\"\"\"\n",
        "    model_name = 'DeepFM'\n",
        "\n",
        "    current_trained = check_trained_models()\n",
        "    if model_name in current_trained:\n",
        "        print(f\"{model_name} model already trained. Skipping...\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING DEEPFM MODEL WITH CYCLICAL FEATURES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        start_time = time_module.time()\n",
        "\n",
        "        # Prepare data with cyclical features\n",
        "        actual_train_data, actual_test_data = prepare_model_inputs_with_additional_features(\n",
        "            train_x, test_x, hist_len, model_type='deepfm'\n",
        "        )\n",
        "\n",
        "        # Check for negative sampling\n",
        "        pos_ratio = np.mean(train_y)\n",
        "        if pos_ratio < 0.06:\n",
        "            print(f\"📊 Applying negative sampling...\")\n",
        "            sampled_train_x, sampled_train_y = create_balanced_batches_with_negative_sampling(\n",
        "                train_x, train_y, target_ratio=5\n",
        "            )\n",
        "            actual_train_data, _ = prepare_model_inputs_with_additional_features(\n",
        "                sampled_train_x, test_x, hist_len, model_type='deepfm'\n",
        "            )\n",
        "            actual_train_y = sampled_train_y\n",
        "        else:\n",
        "            actual_train_y = train_y\n",
        "\n",
        "        # 🎯 CREATE MODEL WITH TRAIN_DATA PARAMETER\n",
        "        deepfm_model = create_deepfm_model(\n",
        "            n_users, n_items, n_cats, hist_len,\n",
        "            additional_dims=additional_dims,\n",
        "            train_data=actual_train_data  # 🔧 PASS TRAIN_DATA!\n",
        "        )\n",
        "\n",
        "        enhanced_class_weights = calculate_extreme_class_weights_v2(actual_train_y, strategy='inverse_sqrt')\n",
        "\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc_roc',\n",
        "                patience=4,\n",
        "                mode='max',\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            ComprehensiveMetricsCallback(\n",
        "                validation_data=(actual_test_data, test_y),\n",
        "                model_name='DeepFM'\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        history_deepfm = deepfm_model.fit(\n",
        "            actual_train_data, actual_train_y,\n",
        "            validation_data=(actual_test_data, test_y),\n",
        "            epochs=15,\n",
        "            batch_size=4096,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=enhanced_class_weights,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        deepfm_time = time_module.time() - start_time\n",
        "\n",
        "        # Comprehensive evaluation\n",
        "        test_pred_deepfm = deepfm_model.predict(actual_test_data)\n",
        "        comprehensive_metrics = calculate_comprehensive_metrics(test_y, test_pred_deepfm.flatten())\n",
        "\n",
        "        train_pred_deepfm = deepfm_model.predict(actual_train_data)\n",
        "        train_comprehensive = calculate_comprehensive_metrics(actual_train_y, train_pred_deepfm.flatten())\n",
        "\n",
        "        # Enhanced results\n",
        "        results_deepfm = {\n",
        "            'test_auc_roc': comprehensive_metrics['auc_roc'],\n",
        "            'test_auc_pr': comprehensive_metrics['auc_pr'],\n",
        "            'test_log_loss': comprehensive_metrics['log_loss'],\n",
        "            'test_accuracy': comprehensive_metrics['threshold_metrics'][0.5]['accuracy'],\n",
        "            'test_precision': comprehensive_metrics['threshold_metrics'][0.5]['precision'],\n",
        "            'test_recall': comprehensive_metrics['threshold_metrics'][0.5]['recall'],\n",
        "            'test_f1': comprehensive_metrics['threshold_metrics'][0.5]['f1'],\n",
        "            'test_specificity': comprehensive_metrics['threshold_metrics'][0.5]['specificity'],\n",
        "            'optimal_threshold': comprehensive_metrics['best_threshold'],\n",
        "            'optimal_f1': comprehensive_metrics['best_f1'],\n",
        "            'train_auc_roc': train_comprehensive['auc_roc'],\n",
        "            'train_auc_pr': train_comprehensive['auc_pr'],\n",
        "            'test_auc': comprehensive_metrics['auc_roc'],\n",
        "            'train_auc': train_comprehensive['auc_roc'],\n",
        "            'training_time': deepfm_time,\n",
        "            'model': deepfm_model,\n",
        "            'history': history_deepfm,\n",
        "            'comprehensive_test_metrics': comprehensive_metrics,\n",
        "            'comprehensive_train_metrics': train_comprehensive,\n",
        "            'used_negative_sampling': pos_ratio < 0.05,\n",
        "            'used_cyclical_features': True\n",
        "        }\n",
        "\n",
        "        print(f\"\\n🎉 DEEPFM MODEL RESULTS (WITH CYCLICAL FEATURES):\")\n",
        "        print(f\"📊 TEST PERFORMANCE:\")\n",
        "        print(f\"  AUC-ROC: {comprehensive_metrics['auc_roc']:.4f}\")\n",
        "        print(f\"  AUC-PR:  {comprehensive_metrics['auc_pr']:.4f}\")\n",
        "        print(f\"  LogLoss: {comprehensive_metrics['log_loss']:.4f}\")\n",
        "        print(f\"  Optimal F1: {comprehensive_metrics['best_f1']:.4f} (threshold: {comprehensive_metrics['best_threshold']:.3f})\")\n",
        "        print(f\"⏱️  Training Time: {deepfm_time:.2f} seconds\")\n",
        "\n",
        "        deepfm_model.save(os.path.join(save_path, 'deepfm_model_cyclical.h5'))\n",
        "        save_and_update_results(model_name, results_deepfm)\n",
        "\n",
        "        memory_cleanup()\n",
        "        print_memory_status(\"after DeepFM training\")\n",
        "\n",
        "        return results_deepfm\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error training DeepFM model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        error_result = {'error': str(e)}\n",
        "        save_and_update_results(model_name, error_result)\n",
        "        return error_result\n",
        "\n",
        "print(\"✅ FIXED DeepFM training with cyclical features support\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Q-aSKe5x9gzu"
      },
      "outputs": [],
      "source": [
        "def train_din_model_standalone():\n",
        "    \"\"\"Train DIN Model with CYCLICAL FEATURES\"\"\"\n",
        "    model_name = 'DIN'\n",
        "\n",
        "    current_trained = check_trained_models()\n",
        "    if model_name in current_trained:\n",
        "        print(f\"{model_name} model already trained. Skipping...\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING DIN MODEL WITH CYCLICAL FEATURES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        start_time = time_module.time()\n",
        "\n",
        "        # Prepare data with cyclical features\n",
        "        actual_train_data, actual_test_data = prepare_model_inputs_with_additional_features(\n",
        "            train_x, test_x, hist_len\n",
        "        )\n",
        "\n",
        "        # Check for negative sampling\n",
        "        pos_ratio = np.mean(train_y)\n",
        "        if pos_ratio < 0.06:\n",
        "            print(f\"📊 Applying negative sampling...\")\n",
        "            sampled_train_x, sampled_train_y = create_balanced_batches_with_negative_sampling(\n",
        "                train_x, train_y, target_ratio=5\n",
        "            )\n",
        "            actual_train_data, _ = prepare_model_inputs_with_additional_features(\n",
        "                sampled_train_x, test_x, hist_len\n",
        "            )\n",
        "            actual_train_y = sampled_train_y\n",
        "        else:\n",
        "            actual_train_y = train_y\n",
        "\n",
        "        # 🎯 CREATE MODEL WITH TRAIN_DATA PARAMETER\n",
        "        din_model = create_din_model(\n",
        "            n_users=n_users,\n",
        "            n_items=n_items,\n",
        "            n_cats=n_cats,\n",
        "            hist_len=hist_len,\n",
        "            embedding_dim=12,\n",
        "            additional_dims=additional_dims,\n",
        "            use_dice_loss=True,\n",
        "            loss_type='focal_dice',\n",
        "            train_data=actual_train_data  # 🔧 PASS TRAIN_DATA!\n",
        "        )\n",
        "\n",
        "        enhanced_class_weights = calculate_extreme_class_weights_v2(actual_train_y, strategy='inverse_sqrt')\n",
        "\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc',\n",
        "                patience=4,\n",
        "                mode='max',\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_auc',\n",
        "                factor=0.5,\n",
        "                patience=2,\n",
        "                mode='max',\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ComprehensiveMetricsCallback(\n",
        "                validation_data=(actual_test_data, test_y),\n",
        "                model_name=f'Enhanced DIN (focal_dice)'\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        history_din = din_model.fit(\n",
        "            actual_train_data, actual_train_y,\n",
        "            validation_data=(actual_test_data, test_y),\n",
        "            epochs=20,\n",
        "            batch_size=4096,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=enhanced_class_weights,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        din_time = time_module.time() - start_time\n",
        "\n",
        "        # Comprehensive evaluation\n",
        "        test_pred_din = din_model.predict(actual_test_data)\n",
        "        comprehensive_metrics = calculate_comprehensive_metrics(test_y, test_pred_din.flatten())\n",
        "\n",
        "        train_pred_din = din_model.predict(actual_train_data)\n",
        "        train_comprehensive = calculate_comprehensive_metrics(actual_train_y, train_pred_din.flatten())\n",
        "\n",
        "        # Enhanced results\n",
        "        results_din = {\n",
        "            'test_auc_roc': comprehensive_metrics['auc_roc'],\n",
        "            'test_auc_pr': comprehensive_metrics['auc_pr'],\n",
        "            'test_log_loss': comprehensive_metrics['log_loss'],\n",
        "            'test_accuracy': comprehensive_metrics['threshold_metrics'][0.5]['accuracy'],\n",
        "            'test_precision': comprehensive_metrics['threshold_metrics'][0.5]['precision'],\n",
        "            'test_recall': comprehensive_metrics['threshold_metrics'][0.5]['recall'],\n",
        "            'test_f1': comprehensive_metrics['threshold_metrics'][0.5]['f1'],\n",
        "            'test_specificity': comprehensive_metrics['threshold_metrics'][0.5]['specificity'],\n",
        "            'optimal_threshold': comprehensive_metrics['best_threshold'],\n",
        "            'optimal_f1': comprehensive_metrics['best_f1'],\n",
        "            'train_auc_roc': train_comprehensive['auc_roc'],\n",
        "            'train_auc_pr': train_comprehensive['auc_pr'],\n",
        "            'test_auc': comprehensive_metrics['auc_roc'],\n",
        "            'train_auc': train_comprehensive['auc_roc'],\n",
        "            'loss_type': 'focal_dice',\n",
        "            'used_dice_loss': True,\n",
        "            'positive_class_ratio': pos_ratio,\n",
        "            'used_negative_sampling': pos_ratio < 0.05,\n",
        "            'used_cyclical_features': True,\n",
        "            'training_time': din_time,\n",
        "            'model': din_model,\n",
        "            'history': history_din,\n",
        "            'model_type': 'Enhanced DIN with focal_dice + Cyclical Features',\n",
        "            'architecture': 'Multi-Head Attention + DICE Loss + Cyclical Features',\n",
        "            'comprehensive_test_metrics': comprehensive_metrics,\n",
        "            'comprehensive_train_metrics': train_comprehensive,\n",
        "            'behavior_weighting': 'Enhanced with importance + context gating',\n",
        "            'attention_mechanism': 'Multi-Head DIN Attention (4 heads)'\n",
        "        }\n",
        "\n",
        "        print(f\"\\n🎉 ENHANCED DIN MODEL RESULTS (WITH CYCLICAL FEATURES):\")\n",
        "        print(f\"📊 TEST PERFORMANCE:\")\n",
        "        print(f\"  AUC-ROC: {comprehensive_metrics['auc_roc']:.4f}\")\n",
        "        print(f\"  AUC-PR:  {comprehensive_metrics['auc_pr']:.4f}\")\n",
        "        print(f\"  LogLoss: {comprehensive_metrics['log_loss']:.4f}\")\n",
        "        print(f\"  Best F1: {comprehensive_metrics['best_f1']:.4f} (threshold: {comprehensive_metrics['best_threshold']:.3f})\")\n",
        "        print(f\"⏱️  Training Time: {din_time:.2f} seconds\")\n",
        "\n",
        "        model_filename = f'enhanced_din_cyclical_features.h5'\n",
        "        din_model.save(os.path.join(save_path, model_filename))\n",
        "        save_and_update_results(model_name, results_din)\n",
        "\n",
        "        memory_cleanup()\n",
        "        print_memory_status(\"after Enhanced DIN training\")\n",
        "\n",
        "        return results_din\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error training Enhanced DIN model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        error_result = {'error': str(e)}\n",
        "        save_and_update_results(model_name, error_result)\n",
        "        return error_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGWJ_g5xMvPu",
        "outputId": "be160d45-9a19-473f-fc5a-278441906c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENHANCED Quick training function ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 17: FIXED Quick training with better error handling\n",
        "def quick_train_individual(model_name):\n",
        "    \"\"\"Quick function to train specific model - ENHANCED\"\"\"\n",
        "    model_name = model_name.lower()\n",
        "\n",
        "    # Refresh trained models list\n",
        "    current_trained = check_trained_models()\n",
        "\n",
        "    print(f\"\\n🎯 Training {model_name.upper()} model...\")\n",
        "\n",
        "    try:\n",
        "        if model_name == 'basic':\n",
        "            if 'Basic' not in current_trained:\n",
        "                return train_basic_model_standalone()\n",
        "            else:\n",
        "                print(\"✅ Basic model already trained!\")\n",
        "                return None\n",
        "\n",
        "        elif model_name == 'deepfm':\n",
        "            if 'DeepFM' not in current_trained:\n",
        "                return train_deepfm_model_standalone()\n",
        "            else:\n",
        "                print(\"✅ DeepFM model already trained!\")\n",
        "                return None\n",
        "\n",
        "        elif model_name == 'din':\n",
        "            if 'DIN' not in current_trained:\n",
        "                return train_din_model_standalone()\n",
        "            else:\n",
        "                print(\"✅ DIN model already trained!\")\n",
        "                return None\n",
        "\n",
        "        else:\n",
        "            print(f\"❌ Unknown model: {model_name}\")\n",
        "            print(\"Available options: 'basic', 'deepfm', 'din'\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error training {model_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"ENHANCED Quick training function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RASZSh6-vngC",
        "outputId": "3033b8c5-d105-45ae-ce68-060671484861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Safe training wrapper ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 17B: FIXED - Training Status Functions\n",
        "def safe_model_training(model_name, train_func):\n",
        "    \"\"\"Safe wrapper for model training with enhanced error handling\"\"\"\n",
        "    print(f\"\\n🛡️ SAFE TRAINING: {model_name.upper()}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    try:\n",
        "        # Pre-training checks\n",
        "        print(\"🔍 Pre-training validation...\")\n",
        "        print_memory_status(\"before training\")\n",
        "\n",
        "        # Training\n",
        "        result = train_func()\n",
        "\n",
        "        # Post-training checks\n",
        "        print(\"✅ Training completed successfully\")\n",
        "        enhanced_memory_cleanup()\n",
        "        print_memory_status(\"after training\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ TRAINING FAILED: {e}\")\n",
        "        print(\"🔧 Attempting recovery...\")\n",
        "\n",
        "        # Enhanced error recovery\n",
        "        enhanced_memory_cleanup()\n",
        "\n",
        "        # Log detailed error\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"📝 Error details logged\")\n",
        "\n",
        "        return {'error': str(e), 'details': error_details}\n",
        "\n",
        "print(\"Safe training wrapper ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLASvk9V9gzv",
        "outputId": "69ff55f7-b101-4046-e7f6-fe9633855009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀==========================================================🚀\n",
            "                    ENHANCED QUICK START GUIDE\n",
            "🚀==========================================================🚀\n",
            "\n",
            "1️⃣  TRAIN INDIVIDUAL MODELS:\n",
            "   quick_train_individual('basic')    # Train Basic model\n",
            "   quick_train_individual('deepfm')   # Train DeepFM model\n",
            "   quick_train_individual('din')      # Train Enhanced DIN model\n",
            "\n",
            "2️⃣  TRAIN ALL REMAINING MODELS:\n",
            "   train_remaining_models()           # Train all untrained models\n",
            "\n",
            "3️⃣  CHECK STATUS & RESULTS:\n",
            "   show_training_status()             # Show current status\n",
            "   load_and_compare_results()         # Compare all results\n",
            "\n",
            "4️⃣  DEBUG & UTILITIES:\n",
            "   debug_model_inputs(model, data)    # Debug input mismatches\n",
            "   enhanced_memory_cleanup()          # Advanced memory cleanup\n",
            "\n",
            "5️⃣  DATASET INFO:\n",
            "   Training samples: 4,000,000\n",
            "   Test samples: 1,000,000\n",
            "   Features: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'gender', 'age_level', 'shopping_level', 'brand', 'is_weekend', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'time_segment', 'is_holiday']\n",
            "   Enhanced features: 7\n",
            "Already trained models: []\n",
            "\n",
            "📊 CURRENT STATUS:\n",
            "   Trained models: []\n",
            "\n",
            "🎯 ENHANCED FEATURES AVAILABLE:\n",
            "   is_weekend: Categorical (dim: 2)\n",
            "   time_segment: Categorical (dim: 4)\n",
            "   is_holiday: Categorical (dim: 1)\n",
            "   gender: Categorical (dim: 3)\n",
            "   age_level: Categorical (dim: 7)\n",
            "   shopping_level: Categorical (dim: 4)\n",
            "   brand: Categorical (dim: 5000)\n",
            "\n",
            "🎯 RECOMMENDATION: Start with train_remaining_models()\n",
            "\n",
            "🚀==========================================================🚀\n"
          ]
        }
      ],
      "source": [
        "# Cell 19: ENHANCED Quick Start Guide\n",
        "def quick_start():\n",
        "    \"\"\"Enhanced quick start guide for training models\"\"\"\n",
        "    print(\"\\n\" + \"🚀\" + \"=\"*58 + \"🚀\")\n",
        "    print(\"                    ENHANCED QUICK START GUIDE\")\n",
        "    print(\"🚀\" + \"=\"*58 + \"🚀\")\n",
        "\n",
        "    print(\"\\n1️⃣  TRAIN INDIVIDUAL MODELS:\")\n",
        "    print(\"   quick_train_individual('basic')    # Train Basic model\")\n",
        "    print(\"   quick_train_individual('deepfm')   # Train DeepFM model\")\n",
        "    print(\"   quick_train_individual('din')      # Train Enhanced DIN model\")\n",
        "\n",
        "    print(\"\\n2️⃣  TRAIN ALL REMAINING MODELS:\")\n",
        "    print(\"   train_remaining_models()           # Train all untrained models\")\n",
        "\n",
        "    print(\"\\n3️⃣  CHECK STATUS & RESULTS:\")\n",
        "    print(\"   show_training_status()             # Show current status\")\n",
        "    print(\"   load_and_compare_results()         # Compare all results\")\n",
        "\n",
        "    print(\"\\n4️⃣  DEBUG & UTILITIES:\")\n",
        "    print(\"   debug_model_inputs(model, data)    # Debug input mismatches\")\n",
        "    print(\"   enhanced_memory_cleanup()          # Advanced memory cleanup\")\n",
        "\n",
        "    print(\"\\n5️⃣  DATASET INFO:\")\n",
        "    print(f\"   Training samples: {len(train_y):,}\")\n",
        "    print(f\"   Test samples: {len(test_y):,}\")\n",
        "    print(f\"   Features: {list(train_x.keys())}\")\n",
        "    print(f\"   Enhanced features: {len(additional_dims) if additional_dims else 0}\")\n",
        "\n",
        "    # Show current model status\n",
        "    current_trained = check_trained_models()\n",
        "    print(f\"\\n📊 CURRENT STATUS:\")\n",
        "    print(f\"   Trained models: {current_trained}\")\n",
        "\n",
        "    # Show available enhanced features\n",
        "    if additional_dims:\n",
        "        print(f\"\\n🎯 ENHANCED FEATURES AVAILABLE:\")\n",
        "        cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "        for feat, dim in additional_dims.items():\n",
        "            feat_type = \"Cyclical\" if feat in cyclical_features else \"Categorical\"\n",
        "            print(f\"   {feat}: {feat_type} (dim: {dim})\")\n",
        "\n",
        "    if not current_trained:\n",
        "        print(\"\\n🎯 RECOMMENDATION: Start with train_remaining_models()\")\n",
        "    else:\n",
        "        remaining = [m for m in ['Basic', 'DeepFM', 'DIN'] if m not in current_trained]\n",
        "        if remaining:\n",
        "            print(f\"⏳ Remaining: {remaining}\")\n",
        "            next_model = remaining[0].lower()\n",
        "            print(f\"🎯 NEXT: quick_train_individual('{next_model}')\")\n",
        "        else:\n",
        "            print(\"🎉 All models trained! Run load_and_compare_results()\")\n",
        "\n",
        "    print(\"\\n\" + \"🚀\" + \"=\"*58 + \"🚀\")\n",
        "\n",
        "# Run enhanced quick start\n",
        "quick_start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QcwI5oPvngC",
        "outputId": "a646fd04-2cfb-4d85-e55c-c3f8f8aa208c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FIXED Performance diagnostics ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 20: Performance & Memory Diagnostics\n",
        "def run_performance_diagnostics():\n",
        "    \"\"\"Run comprehensive performance and memory diagnostics - FIXED\"\"\"\n",
        "    print(\"\\n\" + \"⚡\" + \"=\"*58 + \"⚡\")\n",
        "    print(\"                 PERFORMANCE DIAGNOSTICS\")\n",
        "    print(\"⚡\" + \"=\"*58 + \"⚡\")\n",
        "\n",
        "    # Memory status\n",
        "    print(\"\\n💾 MEMORY STATUS:\")\n",
        "    current_memory = print_memory_status(\"diagnostic\")\n",
        "\n",
        "    # Dataset size analysis\n",
        "    total_size = 0\n",
        "    print(\"\\n📊 DATASET SIZE ANALYSIS:\")\n",
        "\n",
        "    # Safely calculate train data size\n",
        "    try:\n",
        "        for key, arr in train_x.items():\n",
        "            if hasattr(arr, 'nbytes'):\n",
        "                size_mb = arr.nbytes / (1024 * 1024)\n",
        "                total_size += size_mb\n",
        "                print(f\"   📋 train_{key}: {size_mb:.1f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error calculating train data size: {e}\")\n",
        "\n",
        "    # Safely calculate test data size\n",
        "    try:\n",
        "        for key, arr in test_x.items():\n",
        "            if hasattr(arr, 'nbytes'):\n",
        "                size_mb = arr.nbytes / (1024 * 1024)\n",
        "                total_size += size_mb\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error calculating test data size: {e}\")\n",
        "\n",
        "    # Target arrays size\n",
        "    try:\n",
        "        if hasattr(train_y, 'nbytes'):\n",
        "            train_y_size = train_y.nbytes / (1024 * 1024)\n",
        "            total_size += train_y_size\n",
        "        if hasattr(test_y, 'nbytes'):\n",
        "            test_y_size = test_y.nbytes / (1024 * 1024)\n",
        "            total_size += test_y_size\n",
        "\n",
        "        print(f\"   📋 Target arrays: {(train_y_size + test_y_size):.1f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error calculating target size: {e}\")\n",
        "\n",
        "    print(f\"   📊 Total dataset: {total_size:.1f} MB\")\n",
        "\n",
        "    # Model complexity estimation with safe conversion\n",
        "    print(\"\\n🧮 MODEL COMPLEXITY ESTIMATION:\")\n",
        "    try:\n",
        "        n_users_int = int(n_users)\n",
        "        n_items_int = int(n_items)\n",
        "        n_cats_int = int(n_cats)\n",
        "\n",
        "        # Conservative parameter estimates\n",
        "        basic_emb_params = (n_users_int + n_items_int + n_cats_int) * 8\n",
        "        basic_dense_params = 64*32 + 32*1 + 100  # Dense layers + bias terms\n",
        "        basic_params = basic_emb_params + basic_dense_params\n",
        "\n",
        "        deepfm_params = int(basic_params * 1.5)  # FM component adds complexity\n",
        "        din_params = int(basic_params * 2.2)     # Attention mechanism adds more\n",
        "\n",
        "        print(f\"   🔧 Basic model: ~{basic_params:,} parameters\")\n",
        "        print(f\"   🔧 DeepFM model: ~{deepfm_params:,} parameters\")\n",
        "        print(f\"   🔧 Enhanced DIN: ~{din_params:,} parameters\")\n",
        "\n",
        "        # Additional features impact\n",
        "        if additional_dims:\n",
        "            additional_params = sum(additional_dims.values()) * 4  # Average embedding size\n",
        "            print(f\"   🎯 Enhanced features: +{additional_params:,} parameters\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error calculating model complexity: {e}\")\n",
        "\n",
        "    # Performance recommendations\n",
        "    print(\"\\n🎯 PERFORMANCE RECOMMENDATIONS:\")\n",
        "\n",
        "    # Memory recommendations\n",
        "    if current_memory > 8000:  # > 8GB\n",
        "        print(\"   ⚠️  High memory usage detected\")\n",
        "        print(\"   → Consider reducing batch size (current: 4096)\")\n",
        "        print(\"   → Run enhanced_memory_cleanup() between models\")\n",
        "        print(\"   → Monitor GPU memory if using GPU\")\n",
        "    else:\n",
        "        print(\"   ✅ Memory usage within acceptable range\")\n",
        "\n",
        "    # Dataset size recommendations\n",
        "    if total_size > 1000:  # > 1GB dataset\n",
        "        print(\"   📊 Large dataset detected\")\n",
        "        print(\"   → Models may take longer to train\")\n",
        "        print(\"   → Consider using callbacks for early stopping\")\n",
        "        print(\"   → Monitor training progress closely\")\n",
        "    else:\n",
        "        print(\"   ✅ Dataset size manageable\")\n",
        "\n",
        "    # Class imbalance check\n",
        "    try:\n",
        "        pos_ratio = np.mean(train_y) * 100\n",
        "        print(f\"\\n⚖️  CLASS DISTRIBUTION ANALYSIS:\")\n",
        "        print(f\"   Positive class: {pos_ratio:.2f}%\")\n",
        "\n",
        "        if pos_ratio < 5:\n",
        "            print(\"   ⚠️  Extreme class imbalance detected\")\n",
        "            print(\"   → DICE loss and negative sampling recommended\")\n",
        "            print(\"   → Focus on precision-recall metrics\")\n",
        "        elif pos_ratio < 10:\n",
        "            print(\"   ⚡ High class imbalance\")\n",
        "            print(\"   → Enhanced class weights recommended\")\n",
        "        else:\n",
        "            print(\"   ✅ Balanced enough for standard training\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error analyzing class distribution: {e}\")\n",
        "\n",
        "    # Training time estimates\n",
        "    print(f\"\\n⏱️  TRAINING TIME ESTIMATES:\")\n",
        "    try:\n",
        "        n_samples = len(train_y)\n",
        "        batch_size = 4096\n",
        "        epochs_estimate = 15\n",
        "\n",
        "        batches_per_epoch = (n_samples + batch_size - 1) // batch_size\n",
        "        total_batches = batches_per_epoch * epochs_estimate\n",
        "\n",
        "        # Rough estimates based on model complexity\n",
        "        basic_time_estimate = total_batches * 0.1  # 0.1 sec per batch\n",
        "        deepfm_time_estimate = total_batches * 0.15\n",
        "        din_time_estimate = total_batches * 0.25\n",
        "\n",
        "        print(f\"   🔧 Basic: ~{basic_time_estimate/60:.1f} minutes\")\n",
        "        print(f\"   🔧 DeepFM: ~{deepfm_time_estimate/60:.1f} minutes\")\n",
        "        print(f\"   🔧 DIN: ~{din_time_estimate/60:.1f} minutes\")\n",
        "        print(f\"   📊 Total estimated: ~{(basic_time_estimate + deepfm_time_estimate + din_time_estimate)/60:.1f} minutes\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error estimating training time: {e}\")\n",
        "\n",
        "    print(\"⚡\" + \"=\"*58 + \"⚡\")\n",
        "\n",
        "print(\"✅ FIXED Performance diagnostics ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5WxZRL8vngD",
        "outputId": "9114b087-b169-4967-8511-4df0980f56b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Master control panel ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 21: Master Control Panel\n",
        "def master_control_panel():\n",
        "    \"\"\"Master control panel for easy model management\"\"\"\n",
        "    print(\"\\n\" + \"🎛️\" + \"=\"*58 + \"🎛️\")\n",
        "    print(\"                   MASTER CONTROL PANEL\")\n",
        "    print(\"🎛️\" + \"=\"*58 + \"🎛️\")\n",
        "\n",
        "    # Current status\n",
        "    current_trained = check_trained_models()\n",
        "    all_models = ['Basic', 'DeepFM', 'DIN']\n",
        "    remaining = [m for m in all_models if m not in current_trained]\n",
        "\n",
        "    print(f\"\\n📊 CURRENT STATUS:\")\n",
        "    print(f\"   ✅ Trained: {len(current_trained)}/3 models\")\n",
        "    print(f\"   ⏳ Remaining: {len(remaining)} models\")\n",
        "\n",
        "    # Quick actions\n",
        "    print(f\"\\n🚀 QUICK ACTIONS:\")\n",
        "\n",
        "    if not current_trained:\n",
        "        print(\"   🎯 RECOMMENDED: train_remaining_models()\")\n",
        "        print(\"   📝 Alternative: Start with quick_train_individual('basic')\")\n",
        "    elif len(current_trained) == 1:\n",
        "        next_model = remaining[0].lower()\n",
        "        print(f\"   🎯 NEXT: quick_train_individual('{next_model}')\")\n",
        "        print(\"   📝 Alternative: train_remaining_models()\")\n",
        "    elif len(current_trained) == 2:\n",
        "        next_model = remaining[0].lower()\n",
        "        print(f\"   🎯 FINAL: quick_train_individual('{next_model}')\")\n",
        "        print(\"   📝 Then: load_and_compare_results()\")\n",
        "    else:\n",
        "        print(\"   🎉 ALL COMPLETE: load_and_compare_results()\")\n",
        "        print(\"   📊 View: show_model_architecture_summary()\")\n",
        "\n",
        "    # System status\n",
        "    print(f\"\\n🔧 SYSTEM STATUS:\")\n",
        "    memory_mb = print_memory_status(\"control panel\")\n",
        "\n",
        "    # Enhanced features status\n",
        "    if additional_dims:\n",
        "        enhancement_count = len(additional_dims)\n",
        "        cyclical_count = len([f for f in additional_dims.keys()\n",
        "                            if f in ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']])\n",
        "        print(f\"   🎯 Enhanced features: {enhancement_count} total\")\n",
        "        print(f\"   🔄 Cyclical features: {cyclical_count}\")\n",
        "    else:\n",
        "        print(\"   ⚠️  No enhanced features detected\")\n",
        "\n",
        "    # Quick help\n",
        "    print(f\"\\n💡 QUICK HELP:\")\n",
        "    print(\"   • show_training_status() - Detailed status\")\n",
        "    print(\"   • run_performance_diagnostics() - System analysis\")\n",
        "    print(\"   • enhanced_memory_cleanup() - Memory cleanup\")\n",
        "    print(\"   • quick_start() - Full command guide\")\n",
        "\n",
        "    print(\"🎛️\" + \"=\"*58 + \"🎛️\")\n",
        "\n",
        "print(\"Master control panel ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Av9XKJvngD",
        "outputId": "222d7033-bf3c-4844-80e4-fdd81a187bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FIXED Training summary dashboard ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 22: Training Summary Dashboard\n",
        "def training_summary_dashboard():\n",
        "    \"\"\"Comprehensive training summary dashboard - FIXED\"\"\"\n",
        "    print(\"\\n\" + \"📈\" + \"=\"*58 + \"📈\")\n",
        "    print(\"               TRAINING SUMMARY DASHBOARD\")\n",
        "    print(\"📈\" + \"=\"*58 + \"📈\")\n",
        "\n",
        "    # Load results if available\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        try:\n",
        "            with open(results_checkpoint, 'rb') as f:\n",
        "                all_results = pickle.load(f)\n",
        "\n",
        "            # 🔧 SAFE extraction\n",
        "            valid_results = {}\n",
        "            error_results = {}\n",
        "\n",
        "            for model_name, model_data in all_results.items():\n",
        "                if 'error' in model_data:\n",
        "                    error_results[model_name] = {'error': str(model_data.get('error', 'Unknown error'))}\n",
        "                else:\n",
        "                    # Extract only safe scalar values\n",
        "                    safe_metrics = {}\n",
        "                    safe_keys = [\n",
        "                        'test_auc', 'test_auc_roc', 'test_auc_pr', 'test_accuracy', 'test_precision',\n",
        "                        'test_recall', 'test_f1', 'test_specificity', 'test_log_loss',\n",
        "                        'train_auc', 'train_auc_roc', 'train_auc_pr', 'train_accuracy', 'train_precision',\n",
        "                        'train_recall', 'train_f1', 'train_log_loss',\n",
        "                        'optimal_threshold', 'optimal_f1', 'training_time', 'used_negative_sampling',\n",
        "                        'used_dice_loss', 'loss_type', 'positive_class_ratio', 'model_type',\n",
        "                        'architecture', 'behavior_weighting', 'attention_mechanism', 'relaImpr'\n",
        "                    ]\n",
        "\n",
        "                    for key in safe_keys:\n",
        "                        if key in model_data and isinstance(model_data[key], (int, float, str, bool, type(None))):\n",
        "                            safe_metrics[key] = model_data[key]\n",
        "\n",
        "                    valid_results[model_name] = safe_metrics\n",
        "\n",
        "            print(f\"\\n📊 TRAINING OVERVIEW:\")\n",
        "            print(f\"   ✅ Successfully trained: {len(valid_results)} models\")\n",
        "            print(f\"   ❌ Failed: {len(error_results)} models\")\n",
        "            print(f\"   📈 Total experiments: {len(all_results)}\")\n",
        "\n",
        "            if error_results:\n",
        "                print(f\"\\n❌ FAILED MODELS:\")\n",
        "                for model_name, error_info in error_results.items():\n",
        "                    error_msg = error_info['error'][:80] + \"...\" if len(error_info['error']) > 80 else error_info['error']\n",
        "                    print(f\"   • {model_name}: {error_msg}\")\n",
        "\n",
        "            if valid_results:\n",
        "                # 🔧 SAFE metric extraction\n",
        "                def safe_get_metric(results, metric_name, default=0.0):\n",
        "                    possible_names = [\n",
        "                        metric_name,\n",
        "                        f'test_{metric_name}',\n",
        "                        f'comprehensive_{metric_name}',\n",
        "                        f'{metric_name}_roc' if 'auc' in metric_name else metric_name\n",
        "                    ]\n",
        "\n",
        "                    for name in possible_names:\n",
        "                        if name in results and results[name] is not None:\n",
        "                            return results[name]\n",
        "\n",
        "                    return default\n",
        "\n",
        "                # Performance summary with safe extraction\n",
        "                print(f\"\\n🏆 PERFORMANCE SUMMARY:\")\n",
        "\n",
        "                # Create sorted list safely\n",
        "                model_scores = []\n",
        "                for model_name, results in valid_results.items():\n",
        "                    auc = safe_get_metric(results, 'auc')\n",
        "                    if auc == 0.0:\n",
        "                        auc = safe_get_metric(results, 'test_auc')\n",
        "                    model_scores.append((model_name, results, auc))\n",
        "\n",
        "                sorted_results = sorted(model_scores, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "                if sorted_results:\n",
        "                    best_model, best_results, best_auc = sorted_results[0]\n",
        "                    print(f\"   🥇 Best model: {best_model}\")\n",
        "                    print(f\"   🎯 Best AUC: {best_auc:.4f}\")\n",
        "\n",
        "                    training_time = best_results.get('training_time', 0)\n",
        "                    if training_time > 0:\n",
        "                        print(f\"   ⏱️  Training time: {training_time:.1f}s\")\n",
        "\n",
        "                    # Additional best model metrics\n",
        "                    best_f1 = safe_get_metric(best_results, 'test_f1')\n",
        "                    if best_f1 > 0:\n",
        "                        print(f\"   📊 Best F1: {best_f1:.4f}\")\n",
        "\n",
        "                    optimal_threshold = best_results.get('optimal_threshold', None)\n",
        "                    if optimal_threshold:\n",
        "                        print(f\"   🎯 Optimal threshold: {optimal_threshold:.3f}\")\n",
        "\n",
        "                    if len(sorted_results) > 1:\n",
        "                        # Calculate improvements safely\n",
        "                        baseline_auc = None\n",
        "                        for model_name, results, auc in sorted_results:\n",
        "                            if model_name == 'Basic':\n",
        "                                baseline_auc = auc\n",
        "                                break\n",
        "\n",
        "                        if baseline_auc and baseline_auc > 0 and best_auc > baseline_auc:\n",
        "                            improvement = ((best_auc - baseline_auc) / (1 - baseline_auc)) * 100\n",
        "                            print(f\"   📈 Relative improvement: {improvement:.2f}%\")\n",
        "\n",
        "                # Feature impact analysis\n",
        "                print(f\"\\n🎯 FEATURE IMPACT ANALYSIS:\")\n",
        "                if additional_dims:\n",
        "                    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "                    temporal_features = ['time_segment', 'is_holiday']\n",
        "                    demographic_features = ['gender', 'age_level', 'shopping_level']\n",
        "\n",
        "                    cyclical_count = len([f for f in cyclical_features if f in train_x])\n",
        "                    temporal_count = len([f for f in additional_dims.keys() if f in temporal_features])\n",
        "                    demographic_count = len([f for f in additional_dims.keys() if f in demographic_features])\n",
        "\n",
        "                    print(f\"   🔄 Cyclical temporal: {cyclical_count} features\")\n",
        "                    print(f\"   ⏰ Temporal segments: {temporal_count} features\")\n",
        "                    print(f\"   👤 Demographics: {demographic_count} features\")\n",
        "                    print(f\"   📊 Total enhanced: {len(additional_dims)} features\")\n",
        "\n",
        "                    # Show top features by dimension size\n",
        "                    sorted_features = sorted(additional_dims.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "                    print(f\"   🎯 Top features by complexity:\")\n",
        "                    for feat, dim in sorted_features:\n",
        "                        feat_type = \"🔄\" if feat in cyclical_features else \"📊\"\n",
        "                        print(f\"     {feat_type} {feat}: {dim} dimensions\")\n",
        "                else:\n",
        "                    print(\"   ⚠️  No enhanced features used\")\n",
        "\n",
        "                # Advanced techniques summary\n",
        "                print(f\"\\n🚀 ADVANCED TECHNIQUES USED:\")\n",
        "                techniques_used = set()\n",
        "                for model_name, results in valid_results.items():\n",
        "                    if results.get('used_negative_sampling', False):\n",
        "                        techniques_used.add(\"Negative Sampling\")\n",
        "                    if results.get('used_dice_loss', False):\n",
        "                        techniques_used.add(\"DICE Loss\")\n",
        "                    if 'focal' in str(results.get('loss_type', '')).lower():\n",
        "                        techniques_used.add(\"Focal Loss\")\n",
        "                    if 'attention' in str(results.get('attention_mechanism', '')).lower():\n",
        "                        techniques_used.add(\"Multi-Head Attention\")\n",
        "\n",
        "                if techniques_used:\n",
        "                    for technique in sorted(techniques_used):\n",
        "                        print(f\"   ✅ {technique}\")\n",
        "                else:\n",
        "                    print(\"   📝 Standard techniques only\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error loading training summary: {e}\")\n",
        "            print(\"💡 This might be due to serialization issues\")\n",
        "    else:\n",
        "        print(f\"\\n📝 NO TRAINING RESULTS FOUND\")\n",
        "        print(\"   → Start training with: train_remaining_models()\")\n",
        "\n",
        "    # Resource usage summary\n",
        "    print(f\"\\n💾 RESOURCE USAGE:\")\n",
        "    try:\n",
        "        current_memory = print_memory_status(\"dashboard\")\n",
        "\n",
        "        # Calculate dataset memory usage safely\n",
        "        total_dataset_mb = 0\n",
        "        for key, arr in train_x.items():\n",
        "            if hasattr(arr, 'nbytes'):\n",
        "                total_dataset_mb += arr.nbytes / (1024 * 1024)\n",
        "\n",
        "        print(f\"   📊 Dataset size: {total_dataset_mb:.1f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error calculating resource usage: {e}\")\n",
        "\n",
        "    # Dataset statistics\n",
        "    print(f\"\\n📋 DATASET STATISTICS:\")\n",
        "    try:\n",
        "        print(f\"   🎓 Training samples: {len(train_y):,}\")\n",
        "        print(f\"   🧪 Test samples: {len(test_y):,}\")\n",
        "        print(f\"   👥 Unique users: {n_users:,}\")\n",
        "        print(f\"   🛍️  Unique items: {n_items:,}\")\n",
        "        print(f\"   📂 Categories: {n_cats:,}\")\n",
        "\n",
        "        # Class distribution\n",
        "        pos_ratio = np.mean(train_y) * 100\n",
        "        print(f\"   ⚖️  Positive class: {pos_ratio:.2f}%\")\n",
        "        print(f\"   ⚖️  Negative class: {100-pos_ratio:.2f}%\")\n",
        "        print(f\"   📊 Imbalance ratio: 1:{(100-pos_ratio)/pos_ratio:.1f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Error calculating dataset statistics: {e}\")\n",
        "\n",
        "    print(\"📈\" + \"=\"*58 + \"📈\")\n",
        "\n",
        "print(\"✅ FIXED Training summary dashboard ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwpRkyNqvngD",
        "outputId": "ebebbc05-5714-48d0-b3c9-9ef4a587b126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FIXED Model architecture summary ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 23: Model Architecture Summary\n",
        "def show_model_architecture_summary():\n",
        "    \"\"\"Show detailed architecture summary for all models - FIXED\"\"\"\n",
        "    print(\"\\n\" + \"🏗️\" + \"=\"*58 + \"🏗️\")\n",
        "    print(\"              MODEL ARCHITECTURE SUMMARY\")\n",
        "    print(\"🏗️\" + \"=\"*58 + \"🏗️\")\n",
        "\n",
        "    # Enhanced architecture specifications\n",
        "    architectures = {\n",
        "        'Basic': {\n",
        "            'type': 'Enhanced Neural Network',\n",
        "            'layers': 'Embedding → Enhanced Features → Concat → Dense(64) → Dense(32) → Output',\n",
        "            'features': 'Basic + Temporal + Demographics + Cyclical Features',\n",
        "            'complexity': 'Low-Medium',\n",
        "            'parameters': '~500K-1M',\n",
        "            'special': 'Enhanced with temporal cyclical encoding'\n",
        "        },\n",
        "        'DeepFM': {\n",
        "            'type': 'Enhanced Factorization Machine + Deep',\n",
        "            'layers': 'FM Component + Deep(64→32) → Combine → Output',\n",
        "            'features': 'FM Interactions + All Enhanced Features + Regularization',\n",
        "            'complexity': 'Medium-High',\n",
        "            'parameters': '~750K-1.5M',\n",
        "            'special': 'Fixed Lambda layers, safe FM computation'\n",
        "        },\n",
        "        'DIN': {\n",
        "            'type': 'Enhanced Deep Interest Network with DICE',\n",
        "            'layers': 'Multi-Head Attention → DICE → Dense(200→80→2) → Softmax',\n",
        "            'features': 'Attention + Behavior Weighting + DICE Loss + All Enhanced',\n",
        "            'complexity': 'High',\n",
        "            'parameters': '~1M-2M',\n",
        "            'special': 'DICE Loss + Multi-Head Attention + Behavior Context Gating'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for model_name, arch in architectures.items():\n",
        "        print(f\"\\n📊 {model_name.upper()} MODEL:\")\n",
        "        print(f\"   🔧 Type: {arch['type']}\")\n",
        "        print(f\"   🏗️  Architecture: {arch['layers']}\")\n",
        "        print(f\"   🎯 Features: {arch['features']}\")\n",
        "        print(f\"   📈 Complexity: {arch['complexity']}\")\n",
        "        print(f\"   🔢 Est. Parameters: {arch['parameters']}\")\n",
        "        print(f\"   ⚡ Special: {arch['special']}\")\n",
        "\n",
        "    # Enhanced features summary with categorization\n",
        "    if additional_dims:\n",
        "        print(f\"\\n🎯 ENHANCED FEATURES UTILIZED:\")\n",
        "\n",
        "        # Categorize features\n",
        "        feature_categories = {\n",
        "            'Cyclical Temporal': ['hour_sin', 'hour_cos', 'day_sin', 'day_cos'],\n",
        "            'Categorical Temporal': ['time_segment', 'is_holiday', 'hour', 'is_weekend'],\n",
        "            'Demographics': ['gender', 'age_level', 'shopping_level'],\n",
        "            'Product': ['brand'],\n",
        "            'Other': []\n",
        "        }\n",
        "\n",
        "        # Classify each feature\n",
        "        for feat, dim in additional_dims.items():\n",
        "            categorized = False\n",
        "            for category, feature_list in feature_categories.items():\n",
        "                if feat in feature_list:\n",
        "                    categorized = True\n",
        "                    break\n",
        "\n",
        "            if not categorized:\n",
        "                feature_categories['Other'].append(feat)\n",
        "\n",
        "        # Display by category\n",
        "        for category, feature_list in feature_categories.items():\n",
        "            category_features = [(f, additional_dims[f]) for f in feature_list if f in additional_dims]\n",
        "            if category_features:\n",
        "                print(f\"\\n   📊 {category} Features:\")\n",
        "                for feat, dim in category_features:\n",
        "                    if category == 'Cyclical Temporal':\n",
        "                        print(f\"     🔄 {feat}: continuous (float32)\")\n",
        "                    else:\n",
        "                        print(f\"     📊 {feat}: {dim} categories\")\n",
        "\n",
        "        # Summary statistics\n",
        "        total_dims = sum(additional_dims.values())\n",
        "        cyclical_count = len([f for f in additional_dims.keys() if f in feature_categories['Cyclical Temporal']])\n",
        "        categorical_count = len(additional_dims) - cyclical_count\n",
        "\n",
        "        print(f\"\\n   📈 FEATURE SUMMARY:\")\n",
        "        print(f\"     Total features: {len(additional_dims)}\")\n",
        "        print(f\"     Cyclical features: {cyclical_count}\")\n",
        "        print(f\"     Categorical features: {categorical_count}\")\n",
        "        print(f\"     Total embedding dimensions: {total_dims:,}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n⚠️  NO ENHANCED FEATURES DETECTED\")\n",
        "        print(\"   Using basic features only: user, item, category, price, history\")\n",
        "\n",
        "    # Training strategies summary\n",
        "    print(f\"\\n🚀 TRAINING STRATEGIES AVAILABLE:\")\n",
        "    print(f\"   📊 Enhanced Class Weights: inverse_sqrt, log_balanced, extreme\")\n",
        "    print(f\"   🎯 Negative Sampling: 1:5 ratio for extreme imbalance\")\n",
        "    print(f\"   🔥 DICE Loss: focal_dice, dice for DIN model\")\n",
        "    print(f\"   ⚡ Multi-Head Attention: 4 heads for DIN\")\n",
        "    print(f\"   🎲 Behavior Weighting: importance + context gating for DIN\")\n",
        "\n",
        "    # Expected performance improvements\n",
        "    print(f\"\\n📈 EXPECTED PERFORMANCE IMPROVEMENTS:\")\n",
        "    print(f\"   🔧 Basic → DeepFM: +2-4% AUC (FM interactions)\")\n",
        "    print(f\"   🔧 DeepFM → DIN: +4-7% AUC (attention mechanism)\")\n",
        "    print(f\"   🎯 Enhanced Features: +5-8% AUC (temporal + demographics)\")\n",
        "    print(f\"   🔥 DICE Loss: +3-5% AUC for extreme imbalance\")\n",
        "    print(f\"   📊 Total Potential: +10-15% AUC improvement over basic\")\n",
        "\n",
        "    print(\"🏗️\" + \"=\"*58 + \"🏗️\")\n",
        "\n",
        "print(\"✅ FIXED Model architecture summary ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZPsXmdrvngD",
        "outputId": "58e550f2-16c4-4893-eb68-6476714a108d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FIXED Advanced analytics dashboard ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 24: Advanced Analytics Dashboard\n",
        "def advanced_analytics_dashboard():\n",
        "    \"\"\"Advanced analytics with feature importance and model insights - FIXED\"\"\"\n",
        "    print(\"\\n\" + \"🔬\" + \"=\"*58 + \"🔬\")\n",
        "    print(\"              ADVANCED ANALYTICS DASHBOARD\")\n",
        "    print(\"🔬\" + \"=\"*58 + \"🔬\")\n",
        "\n",
        "    # Load results for analysis\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        try:\n",
        "            with open(results_checkpoint, 'rb') as f:\n",
        "                all_results = pickle.load(f)\n",
        "\n",
        "            # 🔧 SAFE extraction of valid results\n",
        "            valid_results = {}\n",
        "            error_results = {}\n",
        "\n",
        "            for model_name, model_data in all_results.items():\n",
        "                if 'error' in model_data:\n",
        "                    error_results[model_name] = {'error': str(model_data.get('error', 'Unknown error'))}\n",
        "                else:\n",
        "                    # Extract only safe metrics\n",
        "                    safe_metrics = {}\n",
        "                    safe_keys = [\n",
        "                        'test_auc', 'test_auc_roc', 'test_auc_pr', 'test_accuracy', 'test_precision',\n",
        "                        'test_recall', 'test_f1', 'test_specificity', 'test_log_loss',\n",
        "                        'train_auc', 'train_auc_roc', 'train_auc_pr', 'train_accuracy', 'train_precision',\n",
        "                        'train_recall', 'train_f1', 'train_log_loss',\n",
        "                        'optimal_threshold', 'optimal_f1', 'training_time', 'used_negative_sampling',\n",
        "                        'used_dice_loss', 'loss_type', 'positive_class_ratio', 'model_type',\n",
        "                        'architecture', 'behavior_weighting', 'attention_mechanism', 'relaImpr'\n",
        "                    ]\n",
        "\n",
        "                    for key in safe_keys:\n",
        "                        if key in model_data and isinstance(model_data[key], (int, float, str, bool, type(None))):\n",
        "                            safe_metrics[key] = model_data[key]\n",
        "\n",
        "                    # Handle comprehensive metrics safely\n",
        "                    if 'comprehensive_test_metrics' in model_data:\n",
        "                        comp_metrics = model_data['comprehensive_test_metrics']\n",
        "                        if isinstance(comp_metrics, dict):\n",
        "                            for metric in ['auc_roc', 'auc_pr', 'log_loss', 'best_threshold', 'best_f1']:\n",
        "                                if metric in comp_metrics:\n",
        "                                    safe_metrics[f'comprehensive_{metric}'] = comp_metrics[metric]\n",
        "\n",
        "                    valid_results[model_name] = safe_metrics\n",
        "\n",
        "            if valid_results:\n",
        "                # 🔧 SAFE metric extraction function\n",
        "                def safe_get_metric(results, metric_name, default=0.0):\n",
        "                    possible_names = [\n",
        "                        metric_name,\n",
        "                        f'test_{metric_name}',\n",
        "                        f'comprehensive_{metric_name}',\n",
        "                        f'{metric_name}_roc' if 'auc' in metric_name else metric_name\n",
        "                    ]\n",
        "\n",
        "                    for name in possible_names:\n",
        "                        if name in results and results[name] is not None:\n",
        "                            return results[name]\n",
        "\n",
        "                    return default\n",
        "\n",
        "                # Performance analysis with safe extraction\n",
        "                print(f\"\\n📈 PERFORMANCE ANALYSIS:\")\n",
        "                for model_name, results in valid_results.items():\n",
        "                    test_auc = safe_get_metric(results, 'auc')\n",
        "                    if test_auc == 0.0:\n",
        "                        test_auc = safe_get_metric(results, 'test_auc')\n",
        "\n",
        "                    train_auc = safe_get_metric(results, 'train_auc')\n",
        "                    overfitting = train_auc - test_auc if train_auc > 0 and test_auc > 0 else 0\n",
        "\n",
        "                    print(f\"\\n   🎯 {model_name}:\")\n",
        "                    print(f\"     • Test AUC: {test_auc:.4f}\")\n",
        "                    print(f\"     • Train AUC: {train_auc:.4f}\")\n",
        "                    print(f\"     • Overfitting Gap: {overfitting:.4f}\")\n",
        "\n",
        "                    if overfitting > 0.05:\n",
        "                        print(f\"     ⚠️  High overfitting detected\")\n",
        "                    elif overfitting > 0.02:\n",
        "                        print(f\"     ⚡ Moderate overfitting\")\n",
        "                    else:\n",
        "                        print(f\"     ✅ Good generalization\")\n",
        "\n",
        "                    # Additional metrics if available\n",
        "                    test_f1 = safe_get_metric(results, 'test_f1')\n",
        "                    if test_f1 > 0:\n",
        "                        print(f\"     • F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "                    optimal_threshold = results.get('optimal_threshold', None)\n",
        "                    if optimal_threshold:\n",
        "                        print(f\"     • Optimal Threshold: {optimal_threshold:.3f}\")\n",
        "\n",
        "                # Feature impact estimation\n",
        "                print(f\"\\n🎯 FEATURE IMPACT ESTIMATION:\")\n",
        "                if additional_dims:\n",
        "                    feature_categories = {\n",
        "                        'Temporal': ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'time_segment', 'is_holiday'],\n",
        "                        'Demographic': ['gender', 'age_level', 'shopping_level'],\n",
        "                        'Behavioral': ['brand', 'hour', 'is_weekend']\n",
        "                    }\n",
        "\n",
        "                    for category, features in feature_categories.items():\n",
        "                        available_features = [f for f in features if f in additional_dims]\n",
        "                        if available_features:\n",
        "                            print(f\"   📊 {category} Features: {len(available_features)} active\")\n",
        "                            for feat in available_features:\n",
        "                                print(f\"     • {feat}: dimension {additional_dims[feat]}\")\n",
        "                else:\n",
        "                    print(\"   ⚠️  No enhanced features detected\")\n",
        "\n",
        "                # Advanced feature analysis\n",
        "                print(f\"\\n🔍 ADVANCED FEATURE ANALYSIS:\")\n",
        "                for model_name, results in valid_results.items():\n",
        "                    # Check for advanced features usage\n",
        "                    used_neg_sampling = results.get('used_negative_sampling', False)\n",
        "                    used_dice_loss = results.get('used_dice_loss', False)\n",
        "                    loss_type = results.get('loss_type', 'standard')\n",
        "\n",
        "                    if used_neg_sampling or used_dice_loss or loss_type != 'standard':\n",
        "                        print(f\"   🎯 {model_name} Advanced Features:\")\n",
        "                        if used_neg_sampling:\n",
        "                            print(f\"     • Negative Sampling: ✅\")\n",
        "                        if used_dice_loss:\n",
        "                            print(f\"     • DICE Loss: ✅ ({loss_type})\")\n",
        "                        if 'attention_mechanism' in results:\n",
        "                            print(f\"     • Attention: {results['attention_mechanism']}\")\n",
        "\n",
        "                # Model recommendations\n",
        "                print(f\"\\n💡 MODEL RECOMMENDATIONS:\")\n",
        "                sorted_models = sorted(valid_results.items(),\n",
        "                                     key=lambda x: safe_get_metric(x[1], 'auc') or safe_get_metric(x[1], 'test_auc'),\n",
        "                                     reverse=True)\n",
        "\n",
        "                if sorted_models:\n",
        "                    best_model, best_results = sorted_models[0]\n",
        "                    best_auc = safe_get_metric(best_results, 'auc') or safe_get_metric(best_results, 'test_auc')\n",
        "\n",
        "                    print(f\"   🥇 Best performing: {best_model} (AUC: {best_auc:.4f})\")\n",
        "\n",
        "                    if len(sorted_models) > 1:\n",
        "                        second_model, second_results = sorted_models[1]\n",
        "                        second_auc = safe_get_metric(second_results, 'auc') or safe_get_metric(second_results, 'test_auc')\n",
        "                        if second_auc > 0:\n",
        "                            improvement = (best_auc - second_auc) * 100\n",
        "                            print(f\"   📈 Performance gain: {improvement:.2f}% over {second_model}\")\n",
        "\n",
        "                    # Training efficiency analysis\n",
        "                    best_time = best_results.get('training_time', 0)\n",
        "                    if best_time > 0:\n",
        "                        efficiency = best_auc / best_time * 1000  # AUC per second * 1000\n",
        "                        print(f\"   ⚡ Training efficiency: {efficiency:.2f} AUC/second*1000\")\n",
        "\n",
        "            else:\n",
        "                print(\"\\n❌ No valid results available for analysis\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error loading results for analysis: {e}\")\n",
        "            print(\"💡 This might be due to serialization issues with complex objects\")\n",
        "    else:\n",
        "        print(\"\\n📝 No results found. Train models first!\")\n",
        "\n",
        "    print(\"🔬\" + \"=\"*58 + \"🔬\")\n",
        "\n",
        "print(\"✅ FIXED Advanced analytics dashboard ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3udslhBvngE",
        "outputId": "baf06bd0-a34e-408f-aeab-6c939f4cd30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FIXED Comprehensive report generator ready\n",
            "✅ FIXED Export to CSV ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 25: Export & Reporting System\n",
        "def generate_comprehensive_report():\n",
        "    \"\"\"Generate comprehensive training report - FIXED\"\"\"\n",
        "    print(\"\\n\" + \"📄\" + \"=\"*58 + \"📄\")\n",
        "    print(\"              COMPREHENSIVE TRAINING REPORT\")\n",
        "    print(\"📄\" + \"=\"*58 + \"📄\")\n",
        "\n",
        "    # Create report directory\n",
        "    report_dir = os.path.join(save_path, 'reports')\n",
        "    os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "    # Generate timestamp\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Report content\n",
        "    report_content = []\n",
        "    report_content.append(\"# ENHANCED TAOBAO RECOMMENDATION MODELS - TRAINING REPORT\")\n",
        "    report_content.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    report_content.append(\"=\"*60)\n",
        "\n",
        "    # Dataset information\n",
        "    report_content.append(\"\\n## DATASET INFORMATION\")\n",
        "    try:\n",
        "        report_content.append(f\"Training samples: {len(train_y):,}\")\n",
        "        report_content.append(f\"Test samples: {len(test_y):,}\")\n",
        "        report_content.append(f\"Unique users: {n_users:,}\")\n",
        "        report_content.append(f\"Unique items: {n_items:,}\")\n",
        "        report_content.append(f\"Categories: {n_cats:,}\")\n",
        "\n",
        "        # Class distribution\n",
        "        pos_ratio = np.mean(train_y) * 100\n",
        "        report_content.append(f\"Positive class ratio: {pos_ratio:.2f}%\")\n",
        "        report_content.append(f\"Imbalance ratio: 1:{(100-pos_ratio)/pos_ratio:.1f}\")\n",
        "    except Exception as e:\n",
        "        report_content.append(f\"Error calculating dataset info: {e}\")\n",
        "\n",
        "    # Enhanced features\n",
        "    if additional_dims:\n",
        "        report_content.append(\"\\n## ENHANCED FEATURES\")\n",
        "        cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "\n",
        "        # Categorize features\n",
        "        cyclical = [(f, additional_dims[f]) for f in cyclical_features if f in additional_dims]\n",
        "        categorical = [(f, additional_dims[f]) for f in additional_dims if f not in cyclical_features]\n",
        "\n",
        "        if cyclical:\n",
        "            report_content.append(\"\\n### Cyclical Temporal Features\")\n",
        "            for feat, dim in cyclical:\n",
        "                report_content.append(f\"- {feat}: Continuous (float32)\")\n",
        "\n",
        "        if categorical:\n",
        "            report_content.append(\"\\n### Categorical Features\")\n",
        "            for feat, dim in categorical:\n",
        "                report_content.append(f\"- {feat}: {dim} categories\")\n",
        "\n",
        "        total_dims = sum(additional_dims.values())\n",
        "        report_content.append(f\"\\nTotal enhanced features: {len(additional_dims)}\")\n",
        "        report_content.append(f\"Total embedding dimensions: {total_dims:,}\")\n",
        "    else:\n",
        "        report_content.append(\"\\n## ENHANCED FEATURES\")\n",
        "        report_content.append(\"No enhanced features used - basic features only\")\n",
        "\n",
        "    # Model results\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        try:\n",
        "            with open(results_checkpoint, 'rb') as f:\n",
        "                all_results = pickle.load(f)\n",
        "\n",
        "            # SAFE extraction\n",
        "            valid_results = {}\n",
        "            error_results = {}\n",
        "\n",
        "            for model_name, model_data in all_results.items():\n",
        "                if 'error' in model_data:\n",
        "                    error_results[model_name] = {'error': str(model_data.get('error', 'Unknown error'))}\n",
        "                else:\n",
        "                    safe_metrics = {}\n",
        "                    safe_keys = [\n",
        "                        'test_auc', 'test_auc_roc', 'test_auc_pr', 'test_accuracy', 'test_precision',\n",
        "                        'test_recall', 'test_f1', 'test_specificity', 'test_log_loss',\n",
        "                        'train_auc', 'training_time', 'optimal_threshold', 'optimal_f1',\n",
        "                        'used_negative_sampling', 'used_dice_loss', 'loss_type', 'relaImpr'\n",
        "                    ]\n",
        "\n",
        "                    for key in safe_keys:\n",
        "                        if key in model_data and isinstance(model_data[key], (int, float, str, bool, type(None))):\n",
        "                            safe_metrics[key] = model_data[key]\n",
        "\n",
        "                    valid_results[model_name] = safe_metrics\n",
        "\n",
        "            if valid_results or error_results:\n",
        "                report_content.append(\"\\n## MODEL PERFORMANCE RESULTS\")\n",
        "\n",
        "                # Successful models\n",
        "                if valid_results:\n",
        "                    def safe_get_metric(results, metric_name, default=0.0):\n",
        "                        possible_names = [\n",
        "                            metric_name, f'test_{metric_name}', f'comprehensive_{metric_name}',\n",
        "                            f'{metric_name}_roc' if 'auc' in metric_name else metric_name\n",
        "                        ]\n",
        "                        for name in possible_names:\n",
        "                            if name in results and results[name] is not None:\n",
        "                                return results[name]\n",
        "                        return default\n",
        "\n",
        "                    # Sort models by performance\n",
        "                    model_scores = []\n",
        "                    for model_name, results in valid_results.items():\n",
        "                        auc = safe_get_metric(results, 'auc') or safe_get_metric(results, 'test_auc')\n",
        "                        model_scores.append((model_name, results, auc))\n",
        "\n",
        "                    sorted_results = sorted(model_scores, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "                    for model_name, results, auc in sorted_results:\n",
        "                        report_content.append(f\"\\n### {model_name}\")\n",
        "                        report_content.append(f\"- Test AUC: {auc:.4f}\")\n",
        "\n",
        "                        # Additional metrics\n",
        "                        test_acc = safe_get_metric(results, 'test_accuracy')\n",
        "                        if test_acc > 0:\n",
        "                            report_content.append(f\"- Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "                        test_prec = safe_get_metric(results, 'test_precision')\n",
        "                        if test_prec > 0:\n",
        "                            report_content.append(f\"- Test Precision: {test_prec:.4f}\")\n",
        "\n",
        "                        test_f1 = safe_get_metric(results, 'test_f1')\n",
        "                        if test_f1 > 0:\n",
        "                            report_content.append(f\"- Test F1: {test_f1:.4f}\")\n",
        "\n",
        "                        training_time = results.get('training_time', 0)\n",
        "                        if training_time > 0:\n",
        "                            report_content.append(f\"- Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "                        # Special features\n",
        "                        if results.get('used_negative_sampling', False):\n",
        "                            report_content.append(\"- Used Negative Sampling: Yes\")\n",
        "\n",
        "                        if results.get('used_dice_loss', False):\n",
        "                            loss_type = results.get('loss_type', 'dice')\n",
        "                            report_content.append(f\"- Used DICE Loss: Yes ({loss_type})\")\n",
        "\n",
        "                        relaImpr = results.get('relaImpr', None)\n",
        "                        if relaImpr and relaImpr > 0:\n",
        "                            report_content.append(f\"- Relative Improvement: {relaImpr:.2f}%\")\n",
        "\n",
        "                # Failed models\n",
        "                if error_results:\n",
        "                    report_content.append(\"\\n### Failed Models\")\n",
        "                    for model_name, error_info in error_results.items():\n",
        "                        error_msg = error_info['error'][:100] + \"...\" if len(error_info['error']) > 100 else error_info['error']\n",
        "                        report_content.append(f\"- {model_name}: {error_msg}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            report_content.append(f\"\\n## MODEL PERFORMANCE RESULTS\")\n",
        "            report_content.append(f\"Error loading results: {e}\")\n",
        "    else:\n",
        "        report_content.append(\"\\n## MODEL PERFORMANCE RESULTS\")\n",
        "        report_content.append(\"No training results found\")\n",
        "\n",
        "    # Technical specifications\n",
        "    report_content.append(\"\\n## TECHNICAL SPECIFICATIONS\")\n",
        "    report_content.append(\"### Model Architectures\")\n",
        "    report_content.append(\"- Basic: Enhanced NN with temporal features\")\n",
        "    report_content.append(\"- DeepFM: FM + Deep with fixed Lambda layers\")\n",
        "    report_content.append(\"- DIN: Multi-Head Attention + DICE Loss + Behavior Weighting\")\n",
        "\n",
        "    report_content.append(\"\\n### Training Enhancements\")\n",
        "    report_content.append(\"- Enhanced class weights (inverse_sqrt strategy)\")\n",
        "    report_content.append(\"- Negative sampling for extreme imbalance (1:5 ratio)\")\n",
        "    report_content.append(\"- DICE loss for DIN model\")\n",
        "    report_content.append(\"- Cyclical temporal encoding\")\n",
        "    report_content.append(\"- Comprehensive metrics evaluation\")\n",
        "\n",
        "    # Save report\n",
        "    report_filename = f\"enhanced_training_report_{timestamp}.md\"\n",
        "    report_path = os.path.join(report_dir, report_filename)\n",
        "\n",
        "    try:\n",
        "        with open(report_path, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(report_content))\n",
        "\n",
        "        print(f\"✅ Report generated: {report_path}\")\n",
        "\n",
        "        # Also save as text for easy viewing\n",
        "        txt_report_path = report_path.replace('.md', '.txt')\n",
        "        with open(txt_report_path, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(report_content))\n",
        "\n",
        "        print(f\"✅ Text version: {txt_report_path}\")\n",
        "        print(f\"📊 Report directory: {report_dir}\")\n",
        "\n",
        "        return report_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving report: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(\"📄\" + \"=\"*58 + \"📄\")\n",
        "\n",
        "print(\"✅ FIXED Comprehensive report generator ready\")\n",
        "\n",
        "def export_results_to_csv():\n",
        "    \"\"\"Export results to CSV for further analysis - FIXED\"\"\"\n",
        "    print(\"\\n\" + \"📊\" + \"=\"*50 + \"📊\")\n",
        "    print(\"            EXPORTING RESULTS TO CSV\")\n",
        "    print(\"📊\" + \"=\"*50 + \"📊\")\n",
        "\n",
        "    if not os.path.exists(results_checkpoint):\n",
        "        print(\"❌ No results to export\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(results_checkpoint, 'rb') as f:\n",
        "            all_results = pickle.load(f)\n",
        "\n",
        "        # SAFE extraction of results\n",
        "        valid_results = {}\n",
        "        for model_name, model_data in all_results.items():\n",
        "            if 'error' not in model_data:\n",
        "                safe_metrics = {}\n",
        "                safe_keys = [\n",
        "                    'test_auc', 'test_auc_roc', 'test_auc_pr', 'test_accuracy', 'test_precision',\n",
        "                    'test_recall', 'test_f1', 'test_specificity', 'test_log_loss',\n",
        "                    'train_auc', 'train_auc_roc', 'train_auc_pr', 'train_accuracy', 'train_precision',\n",
        "                    'train_recall', 'train_f1', 'train_log_loss',\n",
        "                    'optimal_threshold', 'optimal_f1', 'training_time', 'used_negative_sampling',\n",
        "                    'used_dice_loss', 'loss_type', 'positive_class_ratio', 'relaImpr'\n",
        "                ]\n",
        "\n",
        "                for key in safe_keys:\n",
        "                    if key in model_data and isinstance(model_data[key], (int, float, str, bool, type(None))):\n",
        "                        safe_metrics[key] = model_data[key]\n",
        "\n",
        "                valid_results[model_name] = safe_metrics\n",
        "\n",
        "        if not valid_results:\n",
        "            print(\"❌ No valid results to export\")\n",
        "            return None\n",
        "\n",
        "        # SAFE metric extraction function\n",
        "        def safe_get_metric(results, metric_name, default=None):\n",
        "            possible_names = [\n",
        "                metric_name,\n",
        "                f'test_{metric_name}',\n",
        "                f'comprehensive_{metric_name}',\n",
        "                f'{metric_name}_roc' if 'auc' in metric_name else metric_name\n",
        "            ]\n",
        "\n",
        "            for name in possible_names:\n",
        "                if name in results and results[name] is not None:\n",
        "                    return results[name]\n",
        "\n",
        "            return default\n",
        "\n",
        "        # Create comprehensive DataFrame\n",
        "        export_data = []\n",
        "        for model_name, results in valid_results.items():\n",
        "            # Extract metrics safely\n",
        "            test_auc = safe_get_metric(results, 'auc') or safe_get_metric(results, 'test_auc')\n",
        "            test_auc_pr = safe_get_metric(results, 'auc_pr') or safe_get_metric(results, 'test_auc_pr')\n",
        "\n",
        "            row = {\n",
        "                'Model': model_name,\n",
        "                'Test_AUC_ROC': test_auc,\n",
        "                'Test_AUC_PR': test_auc_pr,\n",
        "                'Test_Accuracy': safe_get_metric(results, 'test_accuracy'),\n",
        "                'Test_Precision': safe_get_metric(results, 'test_precision'),\n",
        "                'Test_Recall': safe_get_metric(results, 'test_recall'),\n",
        "                'Test_F1': safe_get_metric(results, 'test_f1'),\n",
        "                'Test_Specificity': safe_get_metric(results, 'test_specificity'),\n",
        "                'Test_LogLoss': safe_get_metric(results, 'test_log_loss'),\n",
        "                'Train_AUC': safe_get_metric(results, 'train_auc'),\n",
        "                'Train_Accuracy': safe_get_metric(results, 'train_accuracy'),\n",
        "                'Train_Precision': safe_get_metric(results, 'train_precision'),\n",
        "                'Training_Time_Seconds': results.get('training_time', None),\n",
        "                'Optimal_Threshold': results.get('optimal_threshold', None),\n",
        "                'Optimal_F1': results.get('optimal_f1', None),\n",
        "                'Relative_Improvement_Percent': results.get('relaImpr', None),\n",
        "                'Used_Negative_Sampling': results.get('used_negative_sampling', False),\n",
        "                'Used_DICE_Loss': results.get('used_dice_loss', False),\n",
        "                'Loss_Type': results.get('loss_type', 'binary_crossentropy'),\n",
        "                'Positive_Class_Ratio': results.get('positive_class_ratio', None)\n",
        "            }\n",
        "            export_data.append(row)\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(export_data)\n",
        "\n",
        "        # Add summary statistics\n",
        "        summary_row = {\n",
        "            'Model': 'SUMMARY_STATS',\n",
        "            'Test_AUC_ROC': df['Test_AUC_ROC'].mean() if df['Test_AUC_ROC'].notna().any() else None,\n",
        "            'Test_Accuracy': df['Test_Accuracy'].mean() if df['Test_Accuracy'].notna().any() else None,\n",
        "            'Test_Precision': df['Test_Precision'].mean() if df['Test_Precision'].notna().any() else None,\n",
        "            'Training_Time_Seconds': df['Training_Time_Seconds'].sum() if df['Training_Time_Seconds'].notna().any() else None,\n",
        "        }\n",
        "\n",
        "        # Add summary row\n",
        "        summary_df = pd.DataFrame([summary_row])\n",
        "        df_with_summary = pd.concat([df, summary_df], ignore_index=True)\n",
        "\n",
        "        # Save main CSV\n",
        "        csv_path = os.path.join(save_path, 'enhanced_model_results.csv')\n",
        "        df_with_summary.to_csv(csv_path, index=False)\n",
        "\n",
        "        print(f\"✅ Results exported to: {csv_path}\")\n",
        "        print(f\"📊 Exported {len(df)} model results + summary\")\n",
        "\n",
        "        # Create simplified version for quick analysis\n",
        "        simple_cols = ['Model', 'Test_AUC_ROC', 'Test_F1', 'Training_Time_Seconds', 'Relative_Improvement_Percent']\n",
        "        simple_df = df[simple_cols].copy()\n",
        "\n",
        "        simple_csv_path = os.path.join(save_path, 'model_results_simple.csv')\n",
        "        simple_df.to_csv(simple_csv_path, index=False)\n",
        "\n",
        "        print(f\"✅ Simplified version: {simple_csv_path}\")\n",
        "\n",
        "        # Print summary to console\n",
        "        print(f\"\\n📊 EXPORT SUMMARY:\")\n",
        "        print(f\"   Models exported: {len(df)}\")\n",
        "        if not df.empty:\n",
        "            best_model = df.loc[df['Test_AUC_ROC'].idxmax(), 'Model'] if df['Test_AUC_ROC'].notna().any() else 'Unknown'\n",
        "            best_auc = df['Test_AUC_ROC'].max() if df['Test_AUC_ROC'].notna().any() else 0\n",
        "            print(f\"   Best model: {best_model} (AUC: {best_auc:.4f})\")\n",
        "\n",
        "            total_time = df['Training_Time_Seconds'].sum() if df['Training_Time_Seconds'].notna().any() else 0\n",
        "            print(f\"   Total training time: {total_time:.1f} seconds\")\n",
        "\n",
        "        return csv_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error exporting results: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"✅ FIXED Export to CSV ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7gStrMC9gzv",
        "outputId": "014fb953-1a58-4e65-9fd3-f1cb24f60c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ENHANCED results comparison with serialization fix ready\n"
          ]
        }
      ],
      "source": [
        "# Cell 18: ENHANCED results comparison with serialization fix\n",
        "def load_and_compare_results():\n",
        "    \"\"\"Load all trained models and compare enhanced results - WITH SERIALIZATION FIX\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LOADING AND COMPARING ALL RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.path.exists(results_checkpoint):\n",
        "        print(\"No results found. Train some models first!\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Load results with safe extraction\n",
        "        with open(results_checkpoint, 'rb') as f:\n",
        "            all_results = pickle.load(f)\n",
        "\n",
        "        # 🔧 SAFE EXTRACTION: Remove problematic objects that can't be serialized\n",
        "        clean_results = {}\n",
        "        error_results = {}\n",
        "\n",
        "        for model_name, model_data in all_results.items():\n",
        "            if 'error' in model_data:\n",
        "                error_results[model_name] = {'error': str(model_data.get('error', 'Unknown error'))}\n",
        "            else:\n",
        "                # 🎯 EXTRACT ONLY SAFE METRICS (no model objects, no functions)\n",
        "                safe_metrics = {}\n",
        "\n",
        "                # List of safe keys that contain only basic data types\n",
        "                safe_keys = [\n",
        "                    # Test metrics\n",
        "                    'test_auc', 'test_auc_roc', 'test_auc_pr', 'test_accuracy', 'test_precision',\n",
        "                    'test_recall', 'test_f1', 'test_specificity', 'test_log_loss',\n",
        "                    # Train metrics\n",
        "                    'train_auc', 'train_auc_roc', 'train_auc_pr', 'train_accuracy', 'train_precision',\n",
        "                    'train_recall', 'train_f1', 'train_log_loss',\n",
        "                    # Optimization metrics\n",
        "                    'optimal_threshold', 'optimal_f1',\n",
        "                    # Meta info\n",
        "                    'training_time', 'used_negative_sampling', 'used_dice_loss', 'loss_type',\n",
        "                    'positive_class_ratio', 'model_type', 'architecture', 'behavior_weighting',\n",
        "                    'attention_mechanism', 'relaImpr'\n",
        "                ]\n",
        "\n",
        "                # Extract only safe scalar values\n",
        "                for key in safe_keys:\n",
        "                    if key in model_data and isinstance(model_data[key], (int, float, str, bool, type(None))):\n",
        "                        safe_metrics[key] = model_data[key]\n",
        "\n",
        "                # Handle comprehensive metrics safely\n",
        "                if 'comprehensive_test_metrics' in model_data:\n",
        "                    comp_metrics = model_data['comprehensive_test_metrics']\n",
        "                    if isinstance(comp_metrics, dict):\n",
        "                        for metric in ['auc_roc', 'auc_pr', 'log_loss', 'best_threshold', 'best_f1']:\n",
        "                            if metric in comp_metrics:\n",
        "                                safe_metrics[f'comprehensive_{metric}'] = comp_metrics[metric]\n",
        "\n",
        "                clean_results[model_name] = safe_metrics\n",
        "\n",
        "        # Show error models if any\n",
        "        if error_results:\n",
        "            print(\"\\nModels with errors:\")\n",
        "            for model_name, error_info in error_results.items():\n",
        "                print(f\"  ❌ {model_name}: {error_info['error']}\")\n",
        "            print()\n",
        "\n",
        "        if not clean_results:\n",
        "            print(\"No valid results to compare!\")\n",
        "            return\n",
        "\n",
        "        # 🔧 SAFE metric extraction function\n",
        "        def safe_get_metric(results, metric_name, default=0.0):\n",
        "            \"\"\"Safely extract metric with multiple possible names\"\"\"\n",
        "            possible_names = [\n",
        "                metric_name,\n",
        "                f'test_{metric_name}',\n",
        "                f'comprehensive_{metric_name}',\n",
        "                f'{metric_name}_roc' if 'auc' in metric_name else metric_name\n",
        "            ]\n",
        "\n",
        "            for name in possible_names:\n",
        "                if name in results and results[name] is not None:\n",
        "                    return results[name]\n",
        "\n",
        "            return default\n",
        "\n",
        "        # Calculate relative improvements using safe extraction\n",
        "        if 'Basic' in clean_results:\n",
        "            baseline_auc = safe_get_metric(clean_results['Basic'], 'auc')\n",
        "            if baseline_auc == 0.0:\n",
        "                baseline_auc = safe_get_metric(clean_results['Basic'], 'test_auc')\n",
        "\n",
        "            for model_name, model_results in clean_results.items():\n",
        "                if model_name != 'Basic' and baseline_auc > 0:\n",
        "                    model_auc = safe_get_metric(model_results, 'auc')\n",
        "                    if model_auc == 0.0:\n",
        "                        model_auc = safe_get_metric(model_results, 'test_auc')\n",
        "\n",
        "                    if model_auc > 0:\n",
        "                        relaImpr = calculate_relaImpr(model_auc, baseline_auc)\n",
        "                        model_results['relaImpr'] = relaImpr\n",
        "\n",
        "        # Sort models by performance using safe extraction\n",
        "        def get_sort_key(item):\n",
        "            model_name, results = item\n",
        "            auc = safe_get_metric(results, 'auc')\n",
        "            if auc == 0.0:\n",
        "                auc = safe_get_metric(results, 'test_auc')\n",
        "            return auc\n",
        "\n",
        "        sorted_results = sorted(clean_results.items(), key=get_sort_key, reverse=True)\n",
        "\n",
        "        # 🎯 ENHANCED comprehensive results table\n",
        "        print(\"📊 COMPREHENSIVE Model Performance Summary:\")\n",
        "        print(\"-\" * 160)\n",
        "        print(f\"{'Model':<12} {'Test AUC':<12} {'AUC-PR':<10} {'Test Acc':<12} {'Test Prec':<12} \"\n",
        "              f\"{'Test F1':<10} {'Train AUC':<12} {'Time (s)':<12} {'RelaImpr (%)':<12} {'Features':<15}\")\n",
        "        print(\"-\" * 160)\n",
        "\n",
        "        for model_name, model_results in sorted_results:\n",
        "            # Safe metric extraction\n",
        "            test_auc = safe_get_metric(model_results, 'auc')\n",
        "            if test_auc == 0.0:\n",
        "                test_auc = safe_get_metric(model_results, 'test_auc')\n",
        "\n",
        "            test_auc_pr = safe_get_metric(model_results, 'auc_pr')\n",
        "            if test_auc_pr == 0.0:\n",
        "                test_auc_pr = safe_get_metric(model_results, 'test_auc_pr')\n",
        "\n",
        "            test_acc = safe_get_metric(model_results, 'test_accuracy')\n",
        "            test_prec = safe_get_metric(model_results, 'test_precision')\n",
        "            test_f1 = safe_get_metric(model_results, 'test_f1')\n",
        "            train_auc = safe_get_metric(model_results, 'train_auc')\n",
        "            training_time = model_results.get('training_time', 0.0)\n",
        "            relaImpr = model_results.get('relaImpr', 0.0)\n",
        "\n",
        "            # Special features info\n",
        "            features_info = []\n",
        "            if model_results.get('used_negative_sampling', False):\n",
        "                features_info.append(\"NegSamp\")\n",
        "            if model_results.get('used_dice_loss', False):\n",
        "                features_info.append(\"DICE\")\n",
        "            if model_results.get('loss_type') == 'focal_dice':\n",
        "                features_info.append(\"Focal+DICE\")\n",
        "            features_str = \"+\".join(features_info) if features_info else \"Standard\"\n",
        "\n",
        "            # Format values safely\n",
        "            auc_str = f\"{test_auc:.4f}\" if test_auc > 0 else \"N/A\"\n",
        "            auc_pr_str = f\"{test_auc_pr:.4f}\" if test_auc_pr > 0 else \"N/A\"\n",
        "            acc_str = f\"{test_acc:.4f}\" if test_acc > 0 else \"N/A\"\n",
        "            prec_str = f\"{test_prec:.4f}\" if test_prec > 0 else \"N/A\"\n",
        "            f1_str = f\"{test_f1:.4f}\" if test_f1 > 0 else \"N/A\"\n",
        "            train_auc_str = f\"{train_auc:.4f}\" if train_auc > 0 else \"N/A\"\n",
        "            time_str = f\"{training_time:.1f}\" if training_time > 0 else \"N/A\"\n",
        "            impr_str = f\"{relaImpr:.2f}\" if relaImpr != 0.0 else \"baseline\"\n",
        "\n",
        "            print(f\"{model_name:<12} {auc_str:<12} {auc_pr_str:<10} {acc_str:<12} {prec_str:<12} \"\n",
        "                  f\"{f1_str:<10} {train_auc_str:<12} {time_str:<12} {impr_str:<12} {features_str:<15}\")\n",
        "\n",
        "        print(\"-\" * 160)\n",
        "\n",
        "        # 🎯 BEST MODEL SUMMARY\n",
        "        if sorted_results:\n",
        "            best_model, best_results = sorted_results[0]\n",
        "            best_auc = safe_get_metric(best_results, 'auc')\n",
        "            if best_auc == 0.0:\n",
        "                best_auc = safe_get_metric(best_results, 'test_auc')\n",
        "\n",
        "            print(f\"\\n🏆 BEST PERFORMING MODEL: {best_model}\")\n",
        "            print(f\"  📊 Test AUC: {best_auc:.4f}\")\n",
        "\n",
        "            best_auc_pr = safe_get_metric(best_results, 'auc_pr')\n",
        "            if best_auc_pr > 0:\n",
        "                print(f\"  📊 AUC-PR: {best_auc_pr:.4f}\")\n",
        "\n",
        "            best_f1 = safe_get_metric(best_results, 'test_f1')\n",
        "            if best_f1 > 0:\n",
        "                optimal_threshold = best_results.get('optimal_threshold', 0.5)\n",
        "                print(f\"  📊 Best F1: {best_f1:.4f} (threshold: {optimal_threshold:.3f})\")\n",
        "\n",
        "            print(f\"  ⏱️  Training Time: {best_results.get('training_time', 0):.1f} seconds\")\n",
        "\n",
        "            # Show special features if any\n",
        "            if best_results.get('used_negative_sampling', False):\n",
        "                print(f\"  🎯 Used Negative Sampling: YES\")\n",
        "            if best_results.get('used_dice_loss', False):\n",
        "                print(f\"  🎯 Used DICE Loss: YES\")\n",
        "            if best_results.get('loss_type'):\n",
        "                print(f\"  🔧 Loss Type: {best_results['loss_type']}\")\n",
        "\n",
        "        # 🎯 ENHANCED VISUALIZATION with safe data\n",
        "        if len(clean_results) > 1:\n",
        "            try:\n",
        "                plt.figure(figsize=(20, 12))\n",
        "\n",
        "                model_names = [name for name, _ in sorted_results]\n",
        "\n",
        "                # Plot 1: AUC Comparison\n",
        "                plt.subplot(2, 4, 1)\n",
        "                test_aucs = []\n",
        "                for _, results in sorted_results:\n",
        "                    auc = safe_get_metric(results, 'auc')\n",
        "                    if auc == 0.0:\n",
        "                        auc = safe_get_metric(results, 'test_auc')\n",
        "                    test_aucs.append(auc)\n",
        "\n",
        "                colors = ['skyblue', 'lightgreen', 'coral', 'yellow', 'pink'][:len(model_names)]\n",
        "                bars1 = plt.bar(model_names, test_aucs, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('Test AUC')\n",
        "                plt.title('AUC Comparison')\n",
        "                plt.ylim(0.5, 1.0)\n",
        "\n",
        "                for bar, auc in zip(bars1, test_aucs):\n",
        "                    if auc > 0:\n",
        "                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                                f'{auc:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "                # Plot 2: AUC-PR Comparison\n",
        "                plt.subplot(2, 4, 2)\n",
        "                test_auc_prs = [safe_get_metric(results, 'auc_pr') for _, results in sorted_results]\n",
        "                bars2 = plt.bar(model_names, test_auc_prs, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('AUC-PR')\n",
        "                plt.title('AUC-PR Comparison')\n",
        "                plt.ylim(0.0, 1.0)\n",
        "\n",
        "                for bar, auc_pr in zip(bars2, test_auc_prs):\n",
        "                    if auc_pr > 0:\n",
        "                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                                f'{auc_pr:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "                # Plot 3: F1 Score Comparison\n",
        "                plt.subplot(2, 4, 3)\n",
        "                test_f1s = [safe_get_metric(results, 'test_f1') for _, results in sorted_results]\n",
        "                bars3 = plt.bar(model_names, test_f1s, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('F1 Score')\n",
        "                plt.title('F1 Score Comparison')\n",
        "                plt.ylim(0.0, 1.0)\n",
        "\n",
        "                for bar, f1 in zip(bars3, test_f1s):\n",
        "                    if f1 > 0:\n",
        "                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                                f'{f1:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "                # Plot 4: Training Time Comparison\n",
        "                plt.subplot(2, 4, 4)\n",
        "                training_times = [results.get('training_time', 0) for _, results in sorted_results]\n",
        "                plt.bar(model_names, training_times, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('Training Time (seconds)')\n",
        "                plt.title('Training Time Comparison')\n",
        "\n",
        "                # Plot 5: Relative Improvement\n",
        "                plt.subplot(2, 4, 5)\n",
        "                rel_imprs = [results.get('relaImpr', 0.0) for _, results in sorted_results]\n",
        "                bars5 = plt.bar(model_names, rel_imprs, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('Relative Improvement (%)')\n",
        "                plt.title('Relative Improvement over Basic')\n",
        "\n",
        "                for bar, rel_impr in zip(bars5, rel_imprs):\n",
        "                    if rel_impr > 0:\n",
        "                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                                f'{rel_impr:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "                # Plot 6: Model Features Comparison\n",
        "                plt.subplot(2, 4, 6)\n",
        "                feature_scores = []\n",
        "                for _, results in sorted_results:\n",
        "                    score = 0\n",
        "                    if results.get('used_negative_sampling', False):\n",
        "                        score += 1\n",
        "                    if results.get('used_dice_loss', False):\n",
        "                        score += 1\n",
        "                    if 'focal' in str(results.get('loss_type', '')).lower():\n",
        "                        score += 1\n",
        "                    feature_scores.append(score)\n",
        "\n",
        "                plt.bar(model_names, feature_scores, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('Advanced Features Count')\n",
        "                plt.title('Advanced Features Usage')\n",
        "                plt.ylim(0, 3)\n",
        "\n",
        "                # Plot 7: Performance Efficiency (AUC/Time)\n",
        "                plt.subplot(2, 4, 7)\n",
        "                efficiency_scores = []\n",
        "                for i, (_, results) in enumerate(sorted_results):\n",
        "                    auc = test_aucs[i]\n",
        "                    time = training_times[i]\n",
        "                    efficiency = auc / (time + 1) * 1000 if time > 0 else 0  # AUC per second * 1000\n",
        "                    efficiency_scores.append(efficiency)\n",
        "\n",
        "                plt.bar(model_names, efficiency_scores, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('Efficiency (AUC/Time * 1000)')\n",
        "                plt.title('Performance Efficiency')\n",
        "\n",
        "                # Plot 8: Multi-metric Score (Combined)\n",
        "                plt.subplot(2, 4, 8)\n",
        "                combined_scores = []\n",
        "                for i, (_, results) in enumerate(sorted_results):\n",
        "                    auc_score = test_aucs[i] * 100 if test_aucs[i] > 0 else 0\n",
        "                    auc_pr_score = test_auc_prs[i] * 100 if test_auc_prs[i] > 0 else 0\n",
        "                    f1_score = test_f1s[i] * 100 if test_f1s[i] > 0 else 0\n",
        "\n",
        "                    # Weighted combination\n",
        "                    combined = (auc_score * 0.4 + auc_pr_score * 0.35 + f1_score * 0.25)\n",
        "                    combined_scores.append(combined)\n",
        "\n",
        "                plt.bar(model_names, combined_scores, color=colors)\n",
        "                plt.xlabel('Model')\n",
        "                plt.ylabel('Combined Score')\n",
        "                plt.title('Multi-Metric Combined Score')\n",
        "\n",
        "                plt.tight_layout()\n",
        "\n",
        "                # Save plot\n",
        "                plot_path = os.path.join(save_path, 'enhanced_comprehensive_comparison.png')\n",
        "                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "                plt.show()\n",
        "\n",
        "                print(f\"\\n📊 Enhanced visualization saved to: {plot_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n⚠️ Visualization error (skipped): {e}\")\n",
        "\n",
        "        # 🎯 SUMMARY STATISTICS\n",
        "        if clean_results:\n",
        "            print(f\"\\n📈 SUMMARY STATISTICS:\")\n",
        "            aucs = [safe_get_metric(results, 'test_auc') for results in clean_results.values()]\n",
        "            aucs_valid = [auc for auc in aucs if auc > 0]\n",
        "\n",
        "            if aucs_valid:\n",
        "                print(f\"  Average AUC: {np.mean(aucs_valid):.4f}\")\n",
        "                print(f\"  Best AUC: {np.max(aucs_valid):.4f}\")\n",
        "                print(f\"  AUC Range: {np.max(aucs_valid) - np.min(aucs_valid):.4f}\")\n",
        "\n",
        "            times = [results.get('training_time', 0) for results in clean_results.values()]\n",
        "            times_valid = [t for t in times if t > 0]\n",
        "\n",
        "            if times_valid:\n",
        "                print(f\"  Total Training Time: {np.sum(times_valid):.1f} seconds\")\n",
        "                print(f\"  Average Training Time: {np.mean(times_valid):.1f} seconds\")\n",
        "\n",
        "            # Enhanced features impact\n",
        "            neg_sampling_models = [name for name, results in clean_results.items()\n",
        "                                  if results.get('used_negative_sampling', False)]\n",
        "            dice_models = [name for name, results in clean_results.items()\n",
        "                          if results.get('used_dice_loss', False)]\n",
        "\n",
        "            if neg_sampling_models:\n",
        "                print(f\"  Models with Negative Sampling: {neg_sampling_models}\")\n",
        "            if dice_models:\n",
        "                print(f\"  Models with DICE Loss: {dice_models}\")\n",
        "\n",
        "        return clean_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading results: {e}\")\n",
        "        print(\"💡 This might be due to serialization issues with custom loss functions\")\n",
        "        print(\"🔧 Try retraining models or use direct comparison without checkpoints\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ ENHANCED results comparison with serialization fix ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbJ_105lvngE",
        "outputId": "8ebe24db-1cf6-4612-c5ad-7b712a40e699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀==========================================================🚀\n",
            "                    ENHANCED QUICK START GUIDE\n",
            "🚀==========================================================🚀\n",
            "\n",
            "1️⃣  TRAIN INDIVIDUAL MODELS:\n",
            "   quick_train_individual('basic')    # Train Basic model\n",
            "   quick_train_individual('deepfm')   # Train DeepFM model\n",
            "   quick_train_individual('din')      # Train Enhanced DIN model\n",
            "\n",
            "2️⃣  TRAIN ALL REMAINING MODELS:\n",
            "   train_remaining_models()           # Train all untrained models\n",
            "\n",
            "3️⃣  CHECK STATUS & RESULTS:\n",
            "   show_training_status()             # Show current status\n",
            "   load_and_compare_results()         # Compare all results\n",
            "\n",
            "4️⃣  DEBUG & UTILITIES:\n",
            "   debug_model_inputs(model, data)    # Debug input mismatches\n",
            "   enhanced_memory_cleanup()          # Advanced memory cleanup\n",
            "\n",
            "5️⃣  DATASET INFO:\n",
            "   Training samples: 4,000,000\n",
            "   Test samples: 1,000,000\n",
            "   Features: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'gender', 'age_level', 'shopping_level', 'brand', 'is_weekend', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'time_segment', 'is_holiday']\n",
            "   Enhanced features: 7\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN']\n",
            "\n",
            "📊 CURRENT STATUS:\n",
            "   Trained models: ['DIN']\n",
            "\n",
            "🎯 ENHANCED FEATURES AVAILABLE:\n",
            "   is_weekend: Categorical (dim: 2)\n",
            "   time_segment: Categorical (dim: 4)\n",
            "   is_holiday: Categorical (dim: 1)\n",
            "   gender: Categorical (dim: 3)\n",
            "   age_level: Categorical (dim: 7)\n",
            "   shopping_level: Categorical (dim: 4)\n",
            "   brand: Categorical (dim: 5000)\n",
            "⏳ Remaining: ['Basic', 'DeepFM']\n",
            "🎯 NEXT: quick_train_individual('basic')\n",
            "\n",
            "🚀==========================================================🚀\n",
            "\n",
            "📊==========================================================📊\n",
            "                  TRAINING STATUS\n",
            "📊==========================================================📊\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN']\n",
            "\n",
            "✅ COMPLETED MODELS (1/3):\n",
            "   ✓ DIN\n",
            "\n",
            "⏳ REMAINING MODELS (2/3):\n",
            "   ○ Basic\n",
            "   ○ DeepFM\n",
            "\n",
            "💾 MEMORY STATUS:\n",
            "Memory usage current: 7690.9 MB\n",
            "\n",
            "📋 DATASET INFO:\n",
            "   Training samples: 4,000,000\n",
            "   Test samples: 1,000,000\n",
            "   Features available: 18\n",
            "   Additional dimensions: 7\n",
            "\n",
            "🎯 RECOMMENDATIONS:\n",
            "   → Train next: quick_train_individual('basic')\n",
            "📊==========================================================📊\n",
            "\n",
            "🎛️==========================================================🎛️\n",
            "                   MASTER CONTROL PANEL\n",
            "🎛️==========================================================🎛️\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN']\n",
            "\n",
            "📊 CURRENT STATUS:\n",
            "   ✅ Trained: 1/3 models\n",
            "   ⏳ Remaining: 2 models\n",
            "\n",
            "🚀 QUICK ACTIONS:\n",
            "   🎯 NEXT: quick_train_individual('basic')\n",
            "   📝 Alternative: train_remaining_models()\n",
            "\n",
            "🔧 SYSTEM STATUS:\n",
            "Memory usage control panel: 7729.1 MB\n",
            "   🎯 Enhanced features: 7 total\n",
            "   🔄 Cyclical features: 0\n",
            "\n",
            "💡 QUICK HELP:\n",
            "   • show_training_status() - Detailed status\n",
            "   • run_performance_diagnostics() - System analysis\n",
            "   • enhanced_memory_cleanup() - Memory cleanup\n",
            "   • quick_start() - Full command guide\n",
            "🎛️==========================================================🎛️\n"
          ]
        }
      ],
      "source": [
        "# 1. Cek status saat ini\n",
        "quick_start()                    # Lihat panduan lengkap\n",
        "show_training_status()           # Status detail training\n",
        "master_control_panel()           # Control panel utama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s_a_S_Y9gzw",
        "outputId": "3d809d17-58d3-4926-8f45-a8c026d2b59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN']\n",
            "\n",
            "🎯 Training BASIC model...\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN']\n",
            "\n",
            "==================================================\n",
            "TRAINING BASIC MODEL (COMPREHENSIVE METRICS)\n",
            "==================================================\n",
            "📊 Positive class ratio: 5.14% - Applying negative sampling\n",
            "🎯 NEGATIVE SAMPLING: Target ratio 1:5 (from 1:18)\n",
            "Original - Positive: 205,617, Negative: 3,794,383\n",
            "✅ Negative Sampling Results:\n",
            "   Final positive: 205,617\n",
            "   Final negative: 1,028,085\n",
            "   New ratio: 1:5.0\n",
            "\n",
            "==== PREPARING MODEL INPUTS FOR BASIC (CYCLICAL FOR ALL) ====\n",
            "✓ Added hist_cats\n",
            "✓ Added hist_behaviors\n",
            "✅ Added CYCLICAL feature: hour_sin for BASIC\n",
            "✅ Added CYCLICAL feature: hour_cos for BASIC\n",
            "✅ Added CYCLICAL feature: day_sin for BASIC\n",
            "✅ Added CYCLICAL feature: day_cos for BASIC\n",
            "🎯 BASIC using 4/4 cyclical features\n",
            "🚫 NO categorical conversion for ANY model - ALL use CYCLICAL\n",
            "✓ Added feature: gender as gender\n",
            "✓ Added feature: age_level as age_level\n",
            "✓ Added feature: shopping_level as shopping_level\n",
            "✓ Added temporal feature: time_segment\n",
            "✓ Added temporal feature: is_holiday\n",
            "✓ Added temporal feature: is_weekend\n",
            "✓ Added feature: brand\n",
            "==================================\n",
            "📊 FINAL SUMMARY FOR BASIC:\n",
            "   🎯 Cyclical features: 4 (['hour_sin', 'hour_cos', 'day_sin', 'day_cos'])\n",
            "   🚫 Categorical temporal: NONE (all models use cyclical)\n",
            "   📊 Total features: 18\n",
            "   🔧 Features: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']\n",
            "✅ Using negative sampling\n",
            "\n",
            "==== Creating Basic Model with CYCLICAL FEATURES SUPPORT ====\n",
            "Safe dimensions: users=1141730, items=846810, cats=12961, hist_len=40\n",
            "\n",
            "🔄 ADDING CYCLICAL FEATURES TO MODEL:\n",
            "   ✅ Added cyclical input: hour_sin\n",
            "   ✅ Added cyclical input: hour_cos\n",
            "   ✅ Added cyclical input: day_sin\n",
            "   ✅ Added cyclical input: day_cos\n",
            "🎯 Total cyclical inputs added: 4\n",
            "✅ Added 4 cyclical features to model concat\n",
            "\n",
            "📊 ADDING CATEGORICAL FEATURES:\n",
            "   ✅ Added categorical feature: is_weekend with dim 2\n",
            "   ✅ Added categorical feature: time_segment with dim 4\n",
            "   ✅ Added categorical feature: is_holiday with dim 1\n",
            "   ✅ Added categorical feature: gender with dim 3\n",
            "   ✅ Added categorical feature: age_level with dim 7\n",
            "   ✅ Added categorical feature: shopping_level with dim 4\n",
            "   ✅ Added categorical feature: brand with dim 5000\n",
            "📊 Total categorical features added: 7\n",
            "✅ FIXED Basic model with CYCLICAL FEATURES created\n",
            "📊 Total parameters: 22,906,543\n",
            "🎯 Cyclical features: 4\n",
            "📊 Categorical features: 7\n",
            "🔧 Total inputs: 18\n",
            "📊 Class Distribution Analysis:\n",
            "   Positive: 205,617 (16.67%)\n",
            "   Negative: 1,028,085 (83.33%)\n",
            "   Imbalance ratio: 1:5.0\n",
            "✅ Enhanced Class Weights (inverse_sqrt):\n",
            "   Negative class weight: 0.77\n",
            "   Positive class weight: 1.73\n",
            "   Effective amplification: 2.2x\n",
            "Epoch 1/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6370 - auc: 0.5074 - loss: 8.5362 - precision: 0.1673\n",
            "Epoch 1 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5122\n",
            "  AUC-PR:  0.0523\n",
            "  LogLoss: 0.9838\n",
            "  Best F1: 0.0984 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 395ms/step - accuracy: 0.6371 - auc: 0.5074 - loss: 8.5352 - precision: 0.1673 - val_accuracy: 0.8798 - val_auc: 0.5121 - val_loss: 5.4809 - val_precision: 0.0432 - val_auc_roc: 0.5122 - val_auc_pr: 0.0523 - val_log_loss: 0.9838 - val_best_f1: 0.0984 - val_best_threshold: 0.3000\n",
            "Epoch 2/15\n",
            "\u001b[1m298/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7520 - auc: 0.5156 - loss: 2.9632 - precision: 0.1700\n",
            "Epoch 2 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5429\n",
            "  AUC-PR:  0.0604\n",
            "  LogLoss: 0.4502\n",
            "  Best F1: 0.1001 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 333ms/step - accuracy: 0.7520 - auc: 0.5156 - loss: 2.9782 - precision: 0.1700 - val_accuracy: 0.9404 - val_auc: 0.5428 - val_loss: 0.5496 - val_precision: 0.0805 - val_auc_roc: 0.5429 - val_auc_pr: 0.0604 - val_log_loss: 0.4502 - val_best_f1: 0.1001 - val_best_threshold: 0.3000\n",
            "Epoch 3/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7190 - auc: 0.5198 - loss: 4.3695 - precision: 0.1788\n",
            "Epoch 3 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5524\n",
            "  AUC-PR:  0.0615\n",
            "  LogLoss: 0.3790\n",
            "  Best F1: 0.1018 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 338ms/step - accuracy: 0.7190 - auc: 0.5198 - loss: 4.3703 - precision: 0.1788 - val_accuracy: 0.9486 - val_auc: 0.5523 - val_loss: 0.4617 - val_precision: 0.0000e+00 - val_auc_roc: 0.5524 - val_auc_pr: 0.0615 - val_log_loss: 0.3790 - val_best_f1: 0.1018 - val_best_threshold: 0.3000\n",
            "Epoch 4/15\n",
            "\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7546 - auc: 0.5192 - loss: 4.8039 - precision: 0.1818\n",
            "Epoch 4 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5684\n",
            "  AUC-PR:  0.0641\n",
            "  LogLoss: 0.3697\n",
            "  Best F1: 0.1126 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 338ms/step - accuracy: 0.7542 - auc: 0.5191 - loss: 4.8166 - precision: 0.1818 - val_accuracy: 0.9486 - val_auc: 0.5684 - val_loss: 0.4238 - val_precision: 0.0000e+00 - val_auc_roc: 0.5684 - val_auc_pr: 0.0641 - val_log_loss: 0.3697 - val_best_f1: 0.1126 - val_best_threshold: 0.3000\n",
            "Epoch 5/15\n",
            "\u001b[1m298/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7668 - auc: 0.5295 - loss: 2.2665 - precision: 0.1844\n",
            "Epoch 5 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5719\n",
            "  AUC-PR:  0.0636\n",
            "  LogLoss: 0.4619\n",
            "  Best F1: 0.1082 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 337ms/step - accuracy: 0.7668 - auc: 0.5295 - loss: 2.2630 - precision: 0.1844 - val_accuracy: 0.9471 - val_auc: 0.5718 - val_loss: 0.9669 - val_precision: 0.0403 - val_auc_roc: 0.5719 - val_auc_pr: 0.0636 - val_log_loss: 0.4619 - val_best_f1: 0.1082 - val_best_threshold: 0.3000\n",
            "Epoch 6/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7853 - auc: 0.5444 - loss: 1.3870 - precision: 0.1855\n",
            "Epoch 6 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5790\n",
            "  AUC-PR:  0.0666\n",
            "  LogLoss: 0.4526\n",
            "  Best F1: 0.1160 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 338ms/step - accuracy: 0.7853 - auc: 0.5444 - loss: 1.3870 - precision: 0.1855 - val_accuracy: 0.9477 - val_auc: 0.5789 - val_loss: 0.4809 - val_precision: 0.0920 - val_auc_roc: 0.5790 - val_auc_pr: 0.0666 - val_log_loss: 0.4526 - val_best_f1: 0.1160 - val_best_threshold: 0.4000\n",
            "Epoch 7/15\n",
            "\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7932 - auc: 0.5798 - loss: 2.7173 - precision: 0.2378\n",
            "Epoch 7 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5830\n",
            "  AUC-PR:  0.0670\n",
            "  LogLoss: 0.4389\n",
            "  Best F1: 0.1138 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 336ms/step - accuracy: 0.7932 - auc: 0.5799 - loss: 2.7316 - precision: 0.2380 - val_accuracy: 0.9256 - val_auc: 0.5830 - val_loss: 0.4641 - val_precision: 0.0828 - val_auc_roc: 0.5830 - val_auc_pr: 0.0670 - val_log_loss: 0.4389 - val_best_f1: 0.1138 - val_best_threshold: 0.4000\n",
            "Epoch 8/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7900 - auc: 0.6561 - loss: 1.6657 - precision: 0.3003\n",
            "Epoch 8 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5600\n",
            "  AUC-PR:  0.0586\n",
            "  LogLoss: 0.7709\n",
            "  Best F1: 0.1097 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 335ms/step - accuracy: 0.7900 - auc: 0.6561 - loss: 1.6684 - precision: 0.3002 - val_accuracy: 0.8142 - val_auc: 0.5600 - val_loss: 3.9142 - val_precision: 0.0628 - val_auc_roc: 0.5600 - val_auc_pr: 0.0586 - val_log_loss: 0.7709 - val_best_f1: 0.1097 - val_best_threshold: 0.3000\n",
            "Epoch 9/15\n",
            "\u001b[1m300/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8074 - auc: 0.7309 - loss: 1.9199 - precision: 0.4065\n",
            "Epoch 9 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5789\n",
            "  AUC-PR:  0.0701\n",
            "  LogLoss: 0.4367\n",
            "  Best F1: 0.1245 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 338ms/step - accuracy: 0.8075 - auc: 0.7310 - loss: 1.9144 - precision: 0.4070 - val_accuracy: 0.8602 - val_auc: 0.5789 - val_loss: 0.4449 - val_precision: 0.0830 - val_auc_roc: 0.5789 - val_auc_pr: 0.0701 - val_log_loss: 0.4367 - val_best_f1: 0.1245 - val_best_threshold: 0.4000\n",
            "Epoch 10/15\n",
            "\u001b[1m300/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8233 - auc: 0.7985 - loss: 2.8043 - precision: 0.4744\n",
            "Epoch 10 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5673\n",
            "  AUC-PR:  0.0679\n",
            "  LogLoss: 0.3953\n",
            "  Best F1: 0.1165 (threshold: 0.3)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 334ms/step - accuracy: 0.8233 - auc: 0.7984 - loss: 2.8090 - precision: 0.4742 - val_accuracy: 0.8799 - val_auc: 0.5674 - val_loss: 0.5774 - val_precision: 0.0854 - val_auc_roc: 0.5673 - val_auc_pr: 0.0679 - val_log_loss: 0.3953 - val_best_f1: 0.1165 - val_best_threshold: 0.3000\n",
            "Epoch 11/15\n",
            "\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8260 - auc: 0.7987 - loss: 3.8295 - precision: 0.4896\n",
            "Epoch 11 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5734\n",
            "  AUC-PR:  0.0689\n",
            "  LogLoss: 0.4589\n",
            "  Best F1: 0.1230 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 338ms/step - accuracy: 0.8259 - auc: 0.7988 - loss: 3.8219 - precision: 0.4892 - val_accuracy: 0.8478 - val_auc: 0.5734 - val_loss: 0.4692 - val_precision: 0.0817 - val_auc_roc: 0.5734 - val_auc_pr: 0.0689 - val_log_loss: 0.4589 - val_best_f1: 0.1230 - val_best_threshold: 0.4000\n",
            "Epoch 12/15\n",
            "\u001b[1m298/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8627 - auc: 0.8637 - loss: 0.7425 - precision: 0.5967\n",
            "Epoch 12 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5700\n",
            "  AUC-PR:  0.0685\n",
            "  LogLoss: 0.4780\n",
            "  Best F1: 0.1216 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 335ms/step - accuracy: 0.8627 - auc: 0.8637 - loss: 0.7445 - precision: 0.5966 - val_accuracy: 0.8334 - val_auc: 0.5697 - val_loss: 0.4907 - val_precision: 0.0797 - val_auc_roc: 0.5700 - val_auc_pr: 0.0685 - val_log_loss: 0.4780 - val_best_f1: 0.1216 - val_best_threshold: 0.4000\n",
            "Epoch 13/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8684 - auc: 0.8870 - loss: 0.5983 - precision: 0.6051\n",
            "Epoch 13 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5504\n",
            "  AUC-PR:  0.0589\n",
            "  LogLoss: 0.9003\n",
            "  Best F1: 0.1094 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 335ms/step - accuracy: 0.8684 - auc: 0.8869 - loss: 0.6020 - precision: 0.6050 - val_accuracy: 0.7537 - val_auc: 0.5499 - val_loss: 2.8114 - val_precision: 0.0656 - val_auc_roc: 0.5504 - val_auc_pr: 0.0589 - val_log_loss: 0.9003 - val_best_f1: 0.1094 - val_best_threshold: 0.4000\n",
            "Epoch 14/15\n",
            "\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8542 - auc: 0.8758 - loss: 1.6248 - precision: 0.5628\n",
            "Epoch 14 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5697\n",
            "  AUC-PR:  0.0640\n",
            "  LogLoss: 0.6586\n",
            "  Best F1: 0.1169 (threshold: 0.5)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 333ms/step - accuracy: 0.8542 - auc: 0.8759 - loss: 1.6362 - precision: 0.5628 - val_accuracy: 0.7713 - val_auc: 0.5688 - val_loss: 2.8537 - val_precision: 0.0729 - val_auc_roc: 0.5697 - val_auc_pr: 0.0640 - val_log_loss: 0.6586 - val_best_f1: 0.1169 - val_best_threshold: 0.5000\n",
            "Epoch 15/15\n",
            "\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8740 - auc: 0.8734 - loss: 1.2318 - precision: 0.6320\n",
            "Epoch 15 - Basic (COMPREHENSIVE):\n",
            "  AUC-ROC: 0.5664\n",
            "  AUC-PR:  0.0650\n",
            "  LogLoss: 0.6496\n",
            "  Best F1: 0.1189 (threshold: 0.4)\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 332ms/step - accuracy: 0.8740 - auc: 0.8735 - loss: 1.2426 - precision: 0.6319 - val_accuracy: 0.8167 - val_auc: 0.5660 - val_loss: 10.2265 - val_precision: 0.0767 - val_auc_roc: 0.5664 - val_auc_pr: 0.0650 - val_log_loss: 0.6496 - val_best_f1: 0.1189 - val_best_threshold: 0.4000\n",
            "\u001b[1m31250/31250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step\n",
            "\u001b[1m38554/38554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎉 BASIC MODEL RESULTS (COMPREHENSIVE):\n",
            "📊 TEST PERFORMANCE:\n",
            "  AUC-ROC: 0.5664\n",
            "  AUC-PR:  0.0650\n",
            "  LogLoss: 0.6496\n",
            "  Optimal F1: 0.1189 (threshold: 0.400)\n",
            "  Recall: 0.2325\n",
            "  Specificity: 0.8484\n",
            "⏱️  Training Time: 1546.96 seconds\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Results saved to checkpoint\n",
            "Basic results saved to checkpoint\n",
            "🧹 Enhanced memory cleanup completed\n",
            "Memory usage after Basic training: 10041.8 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_auc_roc': np.float64(0.566441776019243),\n",
              " 'test_auc_pr': np.float64(0.0649783754230671),\n",
              " 'test_log_loss': 0.649624853210093,\n",
              " 'test_accuracy': 0.81675,\n",
              " 'test_precision': 0.07674923276448758,\n",
              " 'test_recall': 0.2325499961092522,\n",
              " 'test_f1': 0.11540949420249279,\n",
              " 'test_specificity': np.float64(0.8484075412504375),\n",
              " 'optimal_threshold': 0.4,\n",
              " 'optimal_f1': 0.11892684106803646,\n",
              " 'train_auc_roc': np.float64(0.9240711420553305),\n",
              " 'train_auc_pr': np.float64(0.6612230197557103),\n",
              " 'train_log_loss': 0.3762614339815394,\n",
              " 'train_accuracy': 0.8951051388422812,\n",
              " 'train_precision': 0.6981920128161117,\n",
              " 'train_recall': 0.6528302620892241,\n",
              " 'train_f1': 0.6747496072887214,\n",
              " 'test_auc': np.float64(0.566441776019243),\n",
              " 'train_auc': np.float64(0.9240711420553305),\n",
              " 'training_time': 1546.9642009735107,\n",
              " 'model': <Functional name=functional, built=True>,\n",
              " 'history': <keras.src.callbacks.history.History at 0x7de1c89d5650>,\n",
              " 'comprehensive_test_metrics': {'auc_roc': np.float64(0.566441776019243),\n",
              "  'auc_pr': np.float64(0.0649783754230671),\n",
              "  'log_loss': 0.649624853210093,\n",
              "  'threshold_metrics': {0.1: {'accuracy': 0.419962,\n",
              "    'precision': 0.057554402410445266,\n",
              "    'recall': 0.6688779083339818,\n",
              "    'f1': 0.10598886566667283,\n",
              "    'specificity': np.float64(0.40647335641305676)},\n",
              "   0.2: {'accuracy': 0.527529,\n",
              "    'precision': 0.06094491308926728,\n",
              "    'recall': 0.5685160687884211,\n",
              "    'f1': 0.1100883562275978,\n",
              "    'specificity': np.float64(0.5253079287705198)},\n",
              "   0.3: {'accuracy': 0.643245,\n",
              "    'precision': 0.06632808128321588,\n",
              "    'recall': 0.45426425959069333,\n",
              "    'f1': 0.1157545909477342,\n",
              "    'specificity': np.float64(0.6534857831995918)},\n",
              "   0.4: {'accuracy': 0.752318,\n",
              "    'precision': 0.07277001436593966,\n",
              "    'recall': 0.3251887012683838,\n",
              "    'f1': 0.11892684106803646,\n",
              "    'specificity': np.float64(0.775463948825422)},\n",
              "   0.5: {'accuracy': 0.81675,\n",
              "    'precision': 0.07674923276448758,\n",
              "    'recall': 0.2325499961092522,\n",
              "    'f1': 0.11540949420249279,\n",
              "    'specificity': np.float64(0.8484075412504375)},\n",
              "   0.6: {'accuracy': 0.850442,\n",
              "    'precision': 0.07938086014501448,\n",
              "    'recall': 0.18018053069800016,\n",
              "    'f1': 0.11020811270689307,\n",
              "    'specificity': np.float64(0.8867631742069332)},\n",
              "   0.7: {'accuracy': 0.876529,\n",
              "    'precision': 0.08078645803036473,\n",
              "    'recall': 0.13508676367597852,\n",
              "    'f1': 0.10110731732176267,\n",
              "    'specificity': np.float64(0.9167074286629925)},\n",
              "   0.8: {'accuracy': 0.896461,\n",
              "    'precision': 0.08186965657732223,\n",
              "    'recall': 0.0992918839000856,\n",
              "    'f1': 0.0897430261897017,\n",
              "    'specificity': np.float64(0.9396592437665772)},\n",
              "   0.9: {'accuracy': 0.913509,\n",
              "    'precision': 0.0807103080710308,\n",
              "    'recall': 0.0656952766321687,\n",
              "    'f1': 0.07243283822188858,\n",
              "    'specificity': np.float64(0.9594516527583924)}},\n",
              "  'best_threshold': 0.4,\n",
              "  'best_f1': 0.11892684106803646},\n",
              " 'comprehensive_train_metrics': {'auc_roc': np.float64(0.9240711420553305),\n",
              "  'auc_pr': np.float64(0.6612230197557103),\n",
              "  'log_loss': 0.3762614339815394,\n",
              "  'threshold_metrics': {0.1: {'accuracy': 0.6483510604667903,\n",
              "    'precision': 0.3183286551513868,\n",
              "    'recall': 0.9723904151894055,\n",
              "    'f1': 0.47963920308020774,\n",
              "    'specificity': np.float64(0.5835431895222671)},\n",
              "   0.2: {'accuracy': 0.7527068935610058,\n",
              "    'precision': 0.39863403737544406,\n",
              "    'recall': 0.9512199866742536,\n",
              "    'f1': 0.5618217332605636,\n",
              "    'specificity': np.float64(0.7130042749383563)},\n",
              "   0.3: {'accuracy': 0.8327797150365324,\n",
              "    'precision': 0.4990690434455479,\n",
              "    'recall': 0.8903543967668043,\n",
              "    'f1': 0.6396154034281083,\n",
              "    'specificity': np.float64(0.821264778690478)},\n",
              "   0.4: {'accuracy': 0.880202026097064,\n",
              "    'precision': 0.6112552046855638,\n",
              "    'recall': 0.7725139458313272,\n",
              "    'f1': 0.6824883614513222,\n",
              "    'specificity': np.float64(0.9017396421502113)},\n",
              "   0.5: {'accuracy': 0.8951051388422812,\n",
              "    'precision': 0.6981920128161117,\n",
              "    'recall': 0.6528302620892241,\n",
              "    'f1': 0.6747496072887214,\n",
              "    'specificity': np.float64(0.9435601141928927)},\n",
              "   0.6: {'accuracy': 0.8977864994950158,\n",
              "    'precision': 0.7468459742710972,\n",
              "    'recall': 0.5850197211320076,\n",
              "    'f1': 0.6561016251182908,\n",
              "    'specificity': np.float64(0.9603398551676174)},\n",
              "   0.7: {'accuracy': 0.8951707948921215,\n",
              "    'precision': 0.785007135545477,\n",
              "    'recall': 0.5109645603233196,\n",
              "    'f1': 0.6190117070354157,\n",
              "    'specificity': np.float64(0.9720120418058819)},\n",
              "   0.8: {'accuracy': 0.8876381816678582,\n",
              "    'precision': 0.8107940101315618,\n",
              "    'recall': 0.4250086325547012,\n",
              "    'f1': 0.5576852510697227,\n",
              "    'specificity': np.float64(0.9801640914904896)},\n",
              "   0.9: {'accuracy': 0.8733357001934017,\n",
              "    'precision': 0.8142214977906251,\n",
              "    'recall': 0.3109665056877593,\n",
              "    'f1': 0.4500503262407354,\n",
              "    'specificity': np.float64(0.9858095390945302)}},\n",
              "  'best_threshold': 0.4,\n",
              "  'best_f1': 0.6824883614513222},\n",
              " 'used_negative_sampling': np.False_}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "quick_train_individual('basic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "v8TMSDAz9gzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3990ee2a-4905-48e0-89f3-18465e69383d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN', 'Basic']\n",
            "\n",
            "🎯 Training DEEPFM model...\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN', 'Basic']\n",
            "\n",
            "==================================================\n",
            "TRAINING DEEPFM MODEL WITH CYCLICAL FEATURES\n",
            "==================================================\n",
            "\n",
            "==== PREPARING MODEL INPUTS FOR BASIC (CYCLICAL FOR ALL) ====\n",
            "✓ Added hist_cats\n",
            "✓ Added hist_behaviors\n",
            "✅ Added CYCLICAL feature: hour_sin for BASIC\n",
            "✅ Added CYCLICAL feature: hour_cos for BASIC\n",
            "✅ Added CYCLICAL feature: day_sin for BASIC\n",
            "✅ Added CYCLICAL feature: day_cos for BASIC\n",
            "🎯 BASIC using 4/4 cyclical features\n",
            "🚫 NO categorical conversion for ANY model - ALL use CYCLICAL\n",
            "✓ Added feature: gender as gender\n",
            "✓ Added feature: age_level as age_level\n",
            "✓ Added feature: shopping_level as shopping_level\n",
            "✓ Added temporal feature: time_segment\n",
            "✓ Added temporal feature: is_holiday\n",
            "✓ Added temporal feature: is_weekend\n",
            "✓ Added feature: brand\n",
            "==================================\n",
            "📊 FINAL SUMMARY FOR BASIC:\n",
            "   🎯 Cyclical features: 4 (['hour_sin', 'hour_cos', 'day_sin', 'day_cos'])\n",
            "   🚫 Categorical temporal: NONE (all models use cyclical)\n",
            "   📊 Total features: 18\n",
            "   🔧 Features: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']\n",
            "📊 Applying negative sampling...\n",
            "🎯 NEGATIVE SAMPLING: Target ratio 1:5 (from 1:18)\n",
            "Original - Positive: 205,617, Negative: 3,794,383\n",
            "✅ Negative Sampling Results:\n",
            "   Final positive: 205,617\n",
            "   Final negative: 1,028,085\n",
            "   New ratio: 1:5.0\n",
            "\n",
            "==== PREPARING MODEL INPUTS FOR BASIC (CYCLICAL FOR ALL) ====\n",
            "✓ Added hist_cats\n",
            "✓ Added hist_behaviors\n",
            "✅ Added CYCLICAL feature: hour_sin for BASIC\n",
            "✅ Added CYCLICAL feature: hour_cos for BASIC\n",
            "✅ Added CYCLICAL feature: day_sin for BASIC\n",
            "✅ Added CYCLICAL feature: day_cos for BASIC\n",
            "🎯 BASIC using 4/4 cyclical features\n",
            "🚫 NO categorical conversion for ANY model - ALL use CYCLICAL\n",
            "✓ Added feature: gender as gender\n",
            "✓ Added feature: age_level as age_level\n",
            "✓ Added feature: shopping_level as shopping_level\n",
            "✓ Added temporal feature: time_segment\n",
            "✓ Added temporal feature: is_holiday\n",
            "✓ Added temporal feature: is_weekend\n",
            "✓ Added feature: brand\n",
            "==================================\n",
            "📊 FINAL SUMMARY FOR BASIC:\n",
            "   🎯 Cyclical features: 4 (['hour_sin', 'hour_cos', 'day_sin', 'day_cos'])\n",
            "   🚫 Categorical temporal: NONE (all models use cyclical)\n",
            "   📊 Total features: 18\n",
            "   🔧 Features: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']\n",
            "\n",
            "==== Creating FIXED DeepFM Model with CYCLICAL FEATURES ====\n",
            "Safe dimensions: users=1141730, items=846810, cats=12961, hist_len=40\n",
            "\n",
            "🔄 ADDING CYCLICAL FEATURES TO DEEPFM:\n",
            "   ✅ Added cyclical input: hour_sin\n",
            "   ✅ Added cyclical input: hour_cos\n",
            "   ✅ Added cyclical input: day_sin\n",
            "   ✅ Added cyclical input: day_cos\n",
            "🎯 Total cyclical inputs added: 4\n",
            "🔧 Building FIXED FM component...\n",
            "✅ Added FM categorical feature: is_weekend\n",
            "✅ Added FM categorical feature: time_segment\n",
            "✅ Added FM categorical feature: is_holiday\n",
            "✅ Added FM categorical feature: gender\n",
            "✅ Added FM categorical feature: age_level\n",
            "✅ Added FM categorical feature: shopping_level\n",
            "✅ Added FM categorical feature: brand\n",
            "✅ FIXED FM component created\n",
            "🔧 Building Deep component with CYCLICAL FEATURES...\n",
            "✅ Added 4 cyclical features to Deep component\n",
            "✅ Added deep categorical feature: is_weekend\n",
            "✅ Added deep categorical feature: time_segment\n",
            "✅ Added deep categorical feature: is_holiday\n",
            "✅ Added deep categorical feature: gender\n",
            "✅ Added deep categorical feature: age_level\n",
            "✅ Added deep categorical feature: shopping_level\n",
            "✅ Added deep categorical feature: brand\n",
            "🔧 Combining FM and Deep components...\n",
            "✅ FIXED DeepFM with CYCLICAL FEATURES created\n",
            "📊 Total parameters: 22,947,351\n",
            "🎯 Cyclical features: 4\n",
            "📊 FM categorical features: 7\n",
            "📊 Deep categorical features: 7\n",
            "🔧 Total inputs: 25\n",
            "📊 Class Distribution Analysis:\n",
            "   Positive: 205,617 (16.67%)\n",
            "   Negative: 1,028,085 (83.33%)\n",
            "   Imbalance ratio: 1:5.0\n",
            "✅ Enhanced Class Weights (inverse_sqrt):\n",
            "   Negative class weight: 0.77\n",
            "   Positive class weight: 1.73\n",
            "   Effective amplification: 2.2x\n",
            "Epoch 1/15\n",
            "Error training DeepFM model: Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']. Expected the following keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend_fm', 'time_segment_fm', 'is_holiday_fm', 'gender_fm', 'age_level_fm', 'shopping_level_fm', 'brand_fm', 'is_weekend_deep', 'time_segment_deep', 'is_holiday_deep', 'gender_deep', 'age_level_deep', 'shopping_level_deep', 'brand_deep']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-83-22c833100138>\", line 58, in train_deepfm_model_standalone\n",
            "    history_deepfm = deepfm_model.fit(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\", line 149, in assert_input_compatibility\n",
            "    raise ValueError(\n",
            "ValueError: Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']. Expected the following keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend_fm', 'time_segment_fm', 'is_holiday_fm', 'gender_fm', 'age_level_fm', 'shopping_level_fm', 'brand_fm', 'is_weekend_deep', 'time_segment_deep', 'is_holiday_deep', 'gender_deep', 'age_level_deep', 'shopping_level_deep', 'brand_deep']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Results saved to checkpoint\n",
            "DeepFM results saved to checkpoint\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'error': 'Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys [\\'user\\', \\'item\\', \\'cat\\', \\'price\\', \\'hist_items\\', \\'hist_cats\\', \\'hist_behaviors\\', \\'hour_sin\\', \\'hour_cos\\', \\'day_sin\\', \\'day_cos\\', \\'gender\\', \\'age_level\\', \\'shopping_level\\', \\'time_segment\\', \\'is_holiday\\', \\'is_weekend\\', \\'brand\\']. Expected the following keys: [\\'user\\', \\'item\\', \\'cat\\', \\'price\\', \\'hist_items\\', \\'hist_cats\\', \\'hist_behaviors\\', \\'hour_sin\\', \\'hour_cos\\', \\'day_sin\\', \\'day_cos\\', \\'is_weekend_fm\\', \\'time_segment_fm\\', \\'is_holiday_fm\\', \\'gender_fm\\', \\'age_level_fm\\', \\'shopping_level_fm\\', \\'brand_fm\\', \\'is_weekend_deep\\', \\'time_segment_deep\\', \\'is_holiday_deep\\', \\'gender_deep\\', \\'age_level_deep\\', \\'shopping_level_deep\\', \\'brand_deep\\']'}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "quick_train_individual('deepfm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "ort7Voah9gzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8b07df-5b8a-42e7-ae27-55f1a1d82c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using Multi-Head Attention with 4 heads\n",
            "Already trained models: ['DIN', 'Basic', 'DeepFM']\n",
            "\n",
            "🎯 Training DIN model...\n",
            "✅ DIN model already trained!\n"
          ]
        }
      ],
      "source": [
        "quick_train_individual('din')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "B6A7I_cf9gzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e8d06ce-65d6-45c1-ae5e-c8809f350ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "LOADING AND COMPARING ALL RESULTS\n",
            "============================================================\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "\n",
            "Models with errors:\n",
            "  ❌ DeepFM: Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']. Expected the following keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend_fm', 'time_segment_fm', 'is_holiday_fm', 'gender_fm', 'age_level_fm', 'shopping_level_fm', 'brand_fm', 'is_weekend_deep', 'time_segment_deep', 'is_holiday_deep', 'gender_deep', 'age_level_deep', 'shopping_level_deep', 'brand_deep']\n",
            "\n",
            "📊 COMPREHENSIVE Model Performance Summary:\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Model        Test AUC     AUC-PR     Test Acc     Test Prec    Test F1    Train AUC    Time (s)     RelaImpr (%) Features       \n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "DIN          0.5783       0.0656     0.9486       N/A          N/A        0.9156       1424.1       2.74         DICE+Focal+DICE\n",
            "Basic        0.5664       0.0650     0.8167       0.0767       0.1154     0.9241       1547.0       baseline     Standard       \n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "🏆 BEST PERFORMING MODEL: DIN\n",
            "  📊 Test AUC: 0.5783\n",
            "  📊 AUC-PR: 0.0656\n",
            "  ⏱️  Training Time: 1424.1 seconds\n",
            "  🎯 Used DICE Loss: YES\n",
            "  🔧 Loss Type: focal_dice\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Enhanced visualization saved to: /content/drive/MyDrive/TA/TAOBAO/models/enhanced_comprehensive_comparison.png\n",
            "\n",
            "📈 SUMMARY STATISTICS:\n",
            "  Average AUC: 0.5724\n",
            "  Best AUC: 0.5783\n",
            "  AUC Range: 0.0119\n",
            "  Total Training Time: 2971.0 seconds\n",
            "  Average Training Time: 1485.5 seconds\n",
            "  Models with DICE Loss: ['DIN']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DIN': {'test_auc': np.float64(0.5783116898517753),\n",
              "  'test_auc_roc': np.float64(0.5783116898517753),\n",
              "  'test_auc_pr': np.float64(0.06559403448160535),\n",
              "  'test_accuracy': 0.948596,\n",
              "  'test_precision': 0.0,\n",
              "  'test_recall': 0.0,\n",
              "  'test_f1': 0.0,\n",
              "  'test_specificity': np.float64(1.0),\n",
              "  'test_log_loss': 0.5643111534076353,\n",
              "  'train_auc': np.float64(0.9155838760420573),\n",
              "  'train_auc_roc': np.float64(0.9155838760420573),\n",
              "  'train_auc_pr': np.float64(0.7378319629529577),\n",
              "  'optimal_threshold': 0.4,\n",
              "  'optimal_f1': 0.09778507409876856,\n",
              "  'training_time': 1424.0637872219086,\n",
              "  'used_dice_loss': True,\n",
              "  'loss_type': 'focal_dice',\n",
              "  'positive_class_ratio': np.float64(0.05140425),\n",
              "  'model_type': 'Enhanced DIN with focal_dice + Cyclical Features',\n",
              "  'architecture': 'Multi-Head Attention + DICE Loss + Cyclical Features',\n",
              "  'behavior_weighting': 'Enhanced with importance + context gating',\n",
              "  'attention_mechanism': 'Multi-Head DIN Attention (4 heads)',\n",
              "  'comprehensive_auc_roc': np.float64(0.5783116898517753),\n",
              "  'comprehensive_auc_pr': np.float64(0.06559403448160535),\n",
              "  'comprehensive_log_loss': 0.5643111534076353,\n",
              "  'comprehensive_best_threshold': 0.4,\n",
              "  'comprehensive_best_f1': 0.09778507409876856,\n",
              "  'relaImpr': np.float64(2.7377900304940734)},\n",
              " 'Basic': {'test_auc': np.float64(0.566441776019243),\n",
              "  'test_auc_roc': np.float64(0.566441776019243),\n",
              "  'test_auc_pr': np.float64(0.0649783754230671),\n",
              "  'test_accuracy': 0.81675,\n",
              "  'test_precision': 0.07674923276448758,\n",
              "  'test_recall': 0.2325499961092522,\n",
              "  'test_f1': 0.11540949420249279,\n",
              "  'test_specificity': np.float64(0.8484075412504375),\n",
              "  'test_log_loss': 0.649624853210093,\n",
              "  'train_auc': np.float64(0.9240711420553305),\n",
              "  'train_auc_roc': np.float64(0.9240711420553305),\n",
              "  'train_auc_pr': np.float64(0.6612230197557103),\n",
              "  'train_accuracy': 0.8951051388422812,\n",
              "  'train_precision': 0.6981920128161117,\n",
              "  'train_recall': 0.6528302620892241,\n",
              "  'train_f1': 0.6747496072887214,\n",
              "  'train_log_loss': 0.3762614339815394,\n",
              "  'optimal_threshold': 0.4,\n",
              "  'optimal_f1': 0.11892684106803646,\n",
              "  'training_time': 1546.9642009735107,\n",
              "  'comprehensive_auc_roc': np.float64(0.566441776019243),\n",
              "  'comprehensive_auc_pr': np.float64(0.0649783754230671),\n",
              "  'comprehensive_log_loss': 0.649624853210093,\n",
              "  'comprehensive_best_threshold': 0.4,\n",
              "  'comprehensive_best_f1': 0.11892684106803646}}"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "# 1. Load dan compare semua hasil\n",
        "load_and_compare_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "DO2rM8EBvngM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "186e9c8c-73e8-4fa2-aed5-748e33b32860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔬==========================================================🔬\n",
            "              ADVANCED ANALYTICS DASHBOARD\n",
            "🔬==========================================================🔬\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "\n",
            "📈 PERFORMANCE ANALYSIS:\n",
            "\n",
            "   🎯 DIN:\n",
            "     • Test AUC: 0.5783\n",
            "     • Train AUC: 0.9156\n",
            "     • Overfitting Gap: 0.3373\n",
            "     ⚠️  High overfitting detected\n",
            "     • Optimal Threshold: 0.400\n",
            "\n",
            "   🎯 Basic:\n",
            "     • Test AUC: 0.5664\n",
            "     • Train AUC: 0.9241\n",
            "     • Overfitting Gap: 0.3576\n",
            "     ⚠️  High overfitting detected\n",
            "     • F1 Score: 0.1154\n",
            "     • Optimal Threshold: 0.400\n",
            "\n",
            "🎯 FEATURE IMPACT ESTIMATION:\n",
            "   📊 Temporal Features: 2 active\n",
            "     • time_segment: dimension 4\n",
            "     • is_holiday: dimension 1\n",
            "   📊 Demographic Features: 3 active\n",
            "     • gender: dimension 3\n",
            "     • age_level: dimension 7\n",
            "     • shopping_level: dimension 4\n",
            "   📊 Behavioral Features: 2 active\n",
            "     • brand: dimension 5000\n",
            "     • is_weekend: dimension 2\n",
            "\n",
            "🔍 ADVANCED FEATURE ANALYSIS:\n",
            "   🎯 DIN Advanced Features:\n",
            "     • DICE Loss: ✅ (focal_dice)\n",
            "     • Attention: Multi-Head DIN Attention (4 heads)\n",
            "\n",
            "💡 MODEL RECOMMENDATIONS:\n",
            "   🥇 Best performing: DIN (AUC: 0.5783)\n",
            "   📈 Performance gain: 1.19% over Basic\n",
            "   ⚡ Training efficiency: 0.41 AUC/second*1000\n",
            "🔬==========================================================🔬\n",
            "\n",
            "⚡==========================================================⚡\n",
            "                 PERFORMANCE DIAGNOSTICS\n",
            "⚡==========================================================⚡\n",
            "\n",
            "💾 MEMORY STATUS:\n",
            "Memory usage diagnostic: 8334.7 MB\n",
            "\n",
            "📊 DATASET SIZE ANALYSIS:\n",
            "   📋 train_user: 15.3 MB\n",
            "   📋 train_item: 15.3 MB\n",
            "   📋 train_cat: 15.3 MB\n",
            "   📋 train_price: 15.3 MB\n",
            "   📋 train_hist_items: 610.4 MB\n",
            "   📋 train_hist_cats: 610.4 MB\n",
            "   📋 train_hist_behaviors: 152.6 MB\n",
            "   📋 train_gender: 3.8 MB\n",
            "   📋 train_age_level: 3.8 MB\n",
            "   📋 train_shopping_level: 3.8 MB\n",
            "   📋 train_brand: 30.5 MB\n",
            "   📋 train_is_weekend: 3.8 MB\n",
            "   📋 train_hour_sin: 15.3 MB\n",
            "   📋 train_hour_cos: 15.3 MB\n",
            "   📋 train_day_sin: 15.3 MB\n",
            "   📋 train_day_cos: 15.3 MB\n",
            "   📋 train_time_segment: 3.8 MB\n",
            "   📋 train_is_holiday: 3.8 MB\n",
            "   📋 Target arrays: 4.8 MB\n",
            "   📊 Total dataset: 1940.7 MB\n",
            "\n",
            "🧮 MODEL COMPLEXITY ESTIMATION:\n",
            "   🔧 Basic model: ~16,014,188 parameters\n",
            "   🔧 DeepFM model: ~24,021,282 parameters\n",
            "   🔧 Enhanced DIN: ~35,231,213 parameters\n",
            "   🎯 Enhanced features: +20,084 parameters\n",
            "\n",
            "🎯 PERFORMANCE RECOMMENDATIONS:\n",
            "   ⚠️  High memory usage detected\n",
            "   → Consider reducing batch size (current: 4096)\n",
            "   → Run enhanced_memory_cleanup() between models\n",
            "   → Monitor GPU memory if using GPU\n",
            "   📊 Large dataset detected\n",
            "   → Models may take longer to train\n",
            "   → Consider using callbacks for early stopping\n",
            "   → Monitor training progress closely\n",
            "\n",
            "⚖️  CLASS DISTRIBUTION ANALYSIS:\n",
            "   Positive class: 5.14%\n",
            "   ⚡ High class imbalance\n",
            "   → Enhanced class weights recommended\n",
            "\n",
            "⏱️  TRAINING TIME ESTIMATES:\n",
            "   🔧 Basic: ~24.4 minutes\n",
            "   🔧 DeepFM: ~36.6 minutes\n",
            "   🔧 DIN: ~61.1 minutes\n",
            "   📊 Total estimated: ~122.1 minutes\n",
            "⚡==========================================================⚡\n",
            "\n",
            "📈==========================================================📈\n",
            "               TRAINING SUMMARY DASHBOARD\n",
            "📈==========================================================📈\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "\n",
            "📊 TRAINING OVERVIEW:\n",
            "   ✅ Successfully trained: 2 models\n",
            "   ❌ Failed: 1 models\n",
            "   📈 Total experiments: 3\n",
            "\n",
            "❌ FAILED MODELS:\n",
            "   • DeepFM: Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys [...\n",
            "\n",
            "🏆 PERFORMANCE SUMMARY:\n",
            "   🥇 Best model: DIN\n",
            "   🎯 Best AUC: 0.5783\n",
            "   ⏱️  Training time: 1424.1s\n",
            "   🎯 Optimal threshold: 0.400\n",
            "   📈 Relative improvement: 2.74%\n",
            "\n",
            "🎯 FEATURE IMPACT ANALYSIS:\n",
            "   🔄 Cyclical temporal: 4 features\n",
            "   ⏰ Temporal segments: 2 features\n",
            "   👤 Demographics: 3 features\n",
            "   📊 Total enhanced: 7 features\n",
            "   🎯 Top features by complexity:\n",
            "     📊 brand: 5000 dimensions\n",
            "     📊 age_level: 7 dimensions\n",
            "     📊 time_segment: 4 dimensions\n",
            "     📊 shopping_level: 4 dimensions\n",
            "     📊 gender: 3 dimensions\n",
            "\n",
            "🚀 ADVANCED TECHNIQUES USED:\n",
            "   ✅ DICE Loss\n",
            "   ✅ Focal Loss\n",
            "   ✅ Multi-Head Attention\n",
            "\n",
            "💾 RESOURCE USAGE:\n",
            "Memory usage dashboard: 8256.4 MB\n",
            "   📊 Dataset size: 1548.8 MB\n",
            "\n",
            "📋 DATASET STATISTICS:\n",
            "   🎓 Training samples: 4,000,000\n",
            "   🧪 Test samples: 1,000,000\n",
            "   👥 Unique users: 1,141,730\n",
            "   🛍️  Unique items: 846,810\n",
            "   📂 Categories: 12,961\n",
            "   ⚖️  Positive class: 5.14%\n",
            "   ⚖️  Negative class: 94.86%\n",
            "   📊 Imbalance ratio: 1:18.5\n",
            "📈==========================================================📈\n",
            "\n",
            "🏗️==========================================================🏗️\n",
            "              MODEL ARCHITECTURE SUMMARY\n",
            "🏗️==========================================================🏗️\n",
            "\n",
            "📊 BASIC MODEL:\n",
            "   🔧 Type: Enhanced Neural Network\n",
            "   🏗️  Architecture: Embedding → Enhanced Features → Concat → Dense(64) → Dense(32) → Output\n",
            "   🎯 Features: Basic + Temporal + Demographics + Cyclical Features\n",
            "   📈 Complexity: Low-Medium\n",
            "   🔢 Est. Parameters: ~500K-1M\n",
            "   ⚡ Special: Enhanced with temporal cyclical encoding\n",
            "\n",
            "📊 DEEPFM MODEL:\n",
            "   🔧 Type: Enhanced Factorization Machine + Deep\n",
            "   🏗️  Architecture: FM Component + Deep(64→32) → Combine → Output\n",
            "   🎯 Features: FM Interactions + All Enhanced Features + Regularization\n",
            "   📈 Complexity: Medium-High\n",
            "   🔢 Est. Parameters: ~750K-1.5M\n",
            "   ⚡ Special: Fixed Lambda layers, safe FM computation\n",
            "\n",
            "📊 DIN MODEL:\n",
            "   🔧 Type: Enhanced Deep Interest Network with DICE\n",
            "   🏗️  Architecture: Multi-Head Attention → DICE → Dense(200→80→2) → Softmax\n",
            "   🎯 Features: Attention + Behavior Weighting + DICE Loss + All Enhanced\n",
            "   📈 Complexity: High\n",
            "   🔢 Est. Parameters: ~1M-2M\n",
            "   ⚡ Special: DICE Loss + Multi-Head Attention + Behavior Context Gating\n",
            "\n",
            "🎯 ENHANCED FEATURES UTILIZED:\n",
            "\n",
            "   📊 Categorical Temporal Features:\n",
            "     📊 time_segment: 4 categories\n",
            "     📊 is_holiday: 1 categories\n",
            "     📊 is_weekend: 2 categories\n",
            "\n",
            "   📊 Demographics Features:\n",
            "     📊 gender: 3 categories\n",
            "     📊 age_level: 7 categories\n",
            "     📊 shopping_level: 4 categories\n",
            "\n",
            "   📊 Product Features:\n",
            "     📊 brand: 5000 categories\n",
            "\n",
            "   📈 FEATURE SUMMARY:\n",
            "     Total features: 7\n",
            "     Cyclical features: 0\n",
            "     Categorical features: 7\n",
            "     Total embedding dimensions: 5,021\n",
            "\n",
            "🚀 TRAINING STRATEGIES AVAILABLE:\n",
            "   📊 Enhanced Class Weights: inverse_sqrt, log_balanced, extreme\n",
            "   🎯 Negative Sampling: 1:5 ratio for extreme imbalance\n",
            "   🔥 DICE Loss: focal_dice, dice for DIN model\n",
            "   ⚡ Multi-Head Attention: 4 heads for DIN\n",
            "   🎲 Behavior Weighting: importance + context gating for DIN\n",
            "\n",
            "📈 EXPECTED PERFORMANCE IMPROVEMENTS:\n",
            "   🔧 Basic → DeepFM: +2-4% AUC (FM interactions)\n",
            "   🔧 DeepFM → DIN: +4-7% AUC (attention mechanism)\n",
            "   🎯 Enhanced Features: +5-8% AUC (temporal + demographics)\n",
            "   🔥 DICE Loss: +3-5% AUC for extreme imbalance\n",
            "   📊 Total Potential: +10-15% AUC improvement over basic\n",
            "🏗️==========================================================🏗️\n",
            "\n",
            "📄==========================================================📄\n",
            "              COMPREHENSIVE TRAINING REPORT\n",
            "📄==========================================================📄\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "✅ Report generated: /content/drive/MyDrive/TA/TAOBAO/models/reports/enhanced_training_report_20250605_144526.md\n",
            "✅ Text version: /content/drive/MyDrive/TA/TAOBAO/models/reports/enhanced_training_report_20250605_144526.txt\n",
            "📊 Report directory: /content/drive/MyDrive/TA/TAOBAO/models/reports\n",
            "\n",
            "📊==================================================📊\n",
            "            EXPORTING RESULTS TO CSV\n",
            "📊==================================================📊\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "✅ Results exported to: /content/drive/MyDrive/TA/TAOBAO/models/enhanced_model_results.csv\n",
            "📊 Exported 2 model results + summary\n",
            "✅ Simplified version: /content/drive/MyDrive/TA/TAOBAO/models/model_results_simple.csv\n",
            "\n",
            "📊 EXPORT SUMMARY:\n",
            "   Models exported: 2\n",
            "   Best model: DIN (AUC: 0.5783)\n",
            "   Total training time: 2971.0 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/TA/TAOBAO/models/enhanced_model_results.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "# 1. Advanced Analysis\n",
        "advanced_analytics_dashboard()\n",
        "\n",
        "# 2. System Performance Check\n",
        "run_performance_diagnostics()\n",
        "\n",
        "# 3. Complete Summary\n",
        "training_summary_dashboard()\n",
        "\n",
        "# 4. Architecture Review\n",
        "show_model_architecture_summary()\n",
        "\n",
        "# 5. Generate Final Report\n",
        "generate_comprehensive_report()\n",
        "\n",
        "# 6. Export for Further Analysis\n",
        "export_results_to_csv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "TPkkeEL6vLpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbedbf6-0a75-41b5-e3b5-2fd07f990b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    3794383\n",
            "1     205617\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(pd.Series(train_y).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check detailed training status\n",
        "def check_detailed_training_status():\n",
        "    \"\"\"Check detailed status of all models\"\"\"\n",
        "    print(\"\\n🔍 DETAILED TRAINING STATUS CHECK:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        with open(results_checkpoint, 'rb') as f:\n",
        "            all_results = pickle.load(f)\n",
        "\n",
        "        print(f\"📊 Models in checkpoint: {list(all_results.keys())}\")\n",
        "\n",
        "        for model_name, results in all_results.items():\n",
        "            print(f\"\\n🎯 {model_name}:\")\n",
        "            if 'error' in results:\n",
        "                print(f\"   ❌ Error: {results['error']}\")\n",
        "            else:\n",
        "                test_auc = results.get('test_auc', results.get('test_auc_roc', 'N/A'))\n",
        "                training_time = results.get('training_time', 'N/A')\n",
        "                print(f\"   ✅ Test AUC: {test_auc}\")\n",
        "                print(f\"   ⏱️  Time: {training_time}\")\n",
        "\n",
        "                # Check for cyclical features\n",
        "                if 'used_cyclical_features' in results:\n",
        "                    print(f\"   🔄 Used cyclical: {results['used_cyclical_features']}\")\n",
        "    else:\n",
        "        print(\"❌ No checkpoint found!\")\n",
        "\n",
        "check_detailed_training_status()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiElLtOhVzkz",
        "outputId": "cc7277ff-c7ab-4cd5-cc05-3e89c521efab"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 DETAILED TRAINING STATUS CHECK:\n",
            "==================================================\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "📊 Models in checkpoint: ['DIN', 'Basic', 'DeepFM']\n",
            "\n",
            "🎯 DIN:\n",
            "   ✅ Test AUC: 0.5783116898517753\n",
            "   ⏱️  Time: 1424.0637872219086\n",
            "   🔄 Used cyclical: True\n",
            "\n",
            "🎯 Basic:\n",
            "   ✅ Test AUC: 0.566441776019243\n",
            "   ⏱️  Time: 1546.9642009735107\n",
            "\n",
            "🎯 DeepFM:\n",
            "   ❌ Error: Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']. Expected the following keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend_fm', 'time_segment_fm', 'is_holiday_fm', 'gender_fm', 'age_level_fm', 'shopping_level_fm', 'brand_fm', 'is_weekend_deep', 'time_segment_deep', 'is_holiday_deep', 'gender_deep', 'age_level_deep', 'shopping_level_deep', 'brand_deep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "6knCgS2TCp1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b479d2-b040-4b2a-f10c-72eedaf5f592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 VERIFYING CYCLICAL FEATURES:\n",
            "========================================\n",
            "📊 Available features in train_x:\n",
            "   • user: (4000000,)\n",
            "   • item: (4000000,)\n",
            "   • cat: (4000000,)\n",
            "   • price: (4000000,)\n",
            "   • hist_items: (4000000, 40)\n",
            "   • hist_cats: (4000000, 40)\n",
            "   • hist_behaviors: (4000000, 40)\n",
            "   • gender: (4000000,)\n",
            "   • age_level: (4000000,)\n",
            "   • shopping_level: (4000000,)\n",
            "   • brand: (4000000, 1)\n",
            "   • is_weekend: (4000000,)\n",
            "   • hour_sin: (4000000,)\n",
            "   • hour_cos: (4000000,)\n",
            "   • day_sin: (4000000,)\n",
            "   • day_cos: (4000000,)\n",
            "   • time_segment: (4000000,)\n",
            "   • is_holiday: (4000000,)\n",
            "\n",
            "🔄 Cyclical Features Check:\n",
            "   ✅ hour_sin: FOUND\n",
            "      Sample values: [ 0.9659258   0.70710677  0.          0.25881904 -0.25881904]\n",
            "   ✅ hour_cos: FOUND\n",
            "      Sample values: [-0.25881904  0.70710677  1.         -0.9659258  -0.9659258 ]\n",
            "   ✅ day_sin: FOUND\n",
            "      Sample values: [ 0.43388373 -0.9749279  -0.9749279   0.43388373  0.43388373]\n",
            "   ✅ day_cos: FOUND\n",
            "      Sample values: [-0.90096885 -0.22252093 -0.22252093 -0.90096885 -0.90096885]\n",
            "\n",
            "📈 Total cyclical features found: 4/4\n",
            "\n",
            "📊 Additional dimensions:\n",
            "   • is_weekend: 2 (Categorical)\n",
            "   • time_segment: 4 (Categorical)\n",
            "   • is_holiday: 1 (Categorical)\n",
            "   • gender: 3 (Categorical)\n",
            "   • age_level: 7 (Categorical)\n",
            "   • shopping_level: 4 (Categorical)\n",
            "   • brand: 5000 (Categorical)\n"
          ]
        }
      ],
      "source": [
        "# 2. Check if cyclical features exist in data\n",
        "def verify_cyclical_features():\n",
        "    \"\"\"Verify cyclical features in training data\"\"\"\n",
        "    print(\"\\n🔍 VERIFYING CYCLICAL FEATURES:\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    print(f\"📊 Available features in train_x:\")\n",
        "    for key in train_x.keys():\n",
        "        print(f\"   • {key}: {train_x[key].shape}\")\n",
        "\n",
        "    # Check for cyclical features specifically\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "    print(f\"\\n🔄 Cyclical Features Check:\")\n",
        "\n",
        "    cyclical_count = 0\n",
        "    for feat in cyclical_features:\n",
        "        if feat in train_x:\n",
        "            print(f\"   ✅ {feat}: FOUND\")\n",
        "            # Show sample values\n",
        "            sample_vals = train_x[feat][:5].flatten()\n",
        "            print(f\"      Sample values: {sample_vals}\")\n",
        "            cyclical_count += 1\n",
        "        else:\n",
        "            print(f\"   ❌ {feat}: MISSING\")\n",
        "\n",
        "    print(f\"\\n📈 Total cyclical features found: {cyclical_count}/4\")\n",
        "\n",
        "    # Check additional_dims\n",
        "    if additional_dims:\n",
        "        print(f\"\\n📊 Additional dimensions:\")\n",
        "        for feat, dim in additional_dims.items():\n",
        "            feat_type = \"Cyclical\" if feat in cyclical_features else \"Categorical\"\n",
        "            print(f\"   • {feat}: {dim} ({feat_type})\")\n",
        "\n",
        "    return cyclical_count\n",
        "\n",
        "cyclical_count = verify_cyclical_features()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check status checkpoint dengan detail\n",
        "def diagnose_checkpoint_issue():\n",
        "    \"\"\"Diagnose checkpoint detection issue\"\"\"\n",
        "    print(\"\\n🔍 DIAGNOSING CHECKPOINT DETECTION ISSUE:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check if results checkpoint exists\n",
        "    print(f\"📁 Results checkpoint exists: {os.path.exists(results_checkpoint)}\")\n",
        "    print(f\"📁 Checkpoint path: {results_checkpoint}\")\n",
        "\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        try:\n",
        "            with open(results_checkpoint, 'rb') as f:\n",
        "                results = pickle.load(f)\n",
        "\n",
        "            print(f\"✅ Checkpoint loaded successfully\")\n",
        "            print(f\"📊 Models in checkpoint: {list(results.keys())}\")\n",
        "\n",
        "            for model_name, model_data in results.items():\n",
        "                if 'error' in model_data:\n",
        "                    print(f\"   ❌ {model_name}: ERROR - {model_data['error']}\")\n",
        "                else:\n",
        "                    # Try to get AUC safely\n",
        "                    test_auc = model_data.get('test_auc_roc',\n",
        "                              model_data.get('test_auc', 'Unknown'))\n",
        "                    training_time = model_data.get('training_time', 'Unknown')\n",
        "                    print(f\"   ✅ {model_name}: AUC = {test_auc}, Time = {training_time}s\")\n",
        "\n",
        "                    # Check for specific keys\n",
        "                    key_count = len([k for k in model_data.keys()\n",
        "                                   if isinstance(model_data[k], (int, float, str, bool))])\n",
        "                    print(f\"      📊 Safe keys: {key_count}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading checkpoint: {e}\")\n",
        "            print(\"💡 Checkpoint might be corrupted\")\n",
        "    else:\n",
        "        print(\"❌ Results checkpoint does not exist!\")\n",
        "        print(\"💡 Training might not have saved properly\")\n",
        "\n",
        "    # Check individual model files\n",
        "    print(f\"\\n📁 MODEL FILES CHECK:\")\n",
        "    model_files = ['basic_model.h5', 'deepfm_model_cyclical.h5', 'enhanced_din_cyclical_features.h5']\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(save_path, model_file)\n",
        "        exists = os.path.exists(model_path)\n",
        "        if exists:\n",
        "            size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
        "            print(f\"   ✅ {model_file}: {size_mb:.1f} MB\")\n",
        "        else:\n",
        "            print(f\"   ❌ {model_file}: Not found\")\n",
        "\n",
        "# Run diagnosis\n",
        "diagnose_checkpoint_issue()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImJjtWKcVs84",
        "outputId": "4db8c6f4-8776-48b8-dd7e-cfc35a6bcec2"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 DIAGNOSING CHECKPOINT DETECTION ISSUE:\n",
            "==================================================\n",
            "📁 Results checkpoint exists: True\n",
            "📁 Checkpoint path: /content/drive/MyDrive/TA/TAOBAO/checkpoints/results.pkl\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "✅ Checkpoint loaded successfully\n",
            "📊 Models in checkpoint: ['DIN', 'Basic', 'DeepFM']\n",
            "   ✅ DIN: AUC = 0.5783116898517753, Time = 1424.0637872219086s\n",
            "      📊 Safe keys: 23\n",
            "   ✅ Basic: AUC = 0.566441776019243, Time = 1546.9642009735107s\n",
            "      📊 Safe keys: 20\n",
            "   ❌ DeepFM: ERROR - Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']. Expected the following keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend_fm', 'time_segment_fm', 'is_holiday_fm', 'gender_fm', 'age_level_fm', 'shopping_level_fm', 'brand_fm', 'is_weekend_deep', 'time_segment_deep', 'is_holiday_deep', 'gender_deep', 'age_level_deep', 'shopping_level_deep', 'brand_deep']\n",
            "\n",
            "📁 MODEL FILES CHECK:\n",
            "   ✅ basic_model.h5: 262.3 MB\n",
            "   ❌ deepfm_model_cyclical.h5: Not found\n",
            "   ✅ enhanced_din_cyclical_features.h5: 393.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. DEBUG: Cek status sebenarnya dari semua model\n",
        "def debug_all_model_status():\n",
        "    \"\"\"Debug status semua model secara detail\"\"\"\n",
        "    print(\"🔍 DEBUGGING ALL MODEL STATUS:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check checkpoint file\n",
        "    if os.path.exists(results_checkpoint):\n",
        "        with open(results_checkpoint, 'rb') as f:\n",
        "            results = pickle.load(f)\n",
        "\n",
        "        print(f\"📊 Models in checkpoint: {list(results.keys())}\")\n",
        "\n",
        "        for model_name, model_data in results.items():\n",
        "            print(f\"\\n🎯 {model_name}:\")\n",
        "            if 'error' in model_data:\n",
        "                print(f\"   ❌ ERROR: {model_data['error']}\")\n",
        "            else:\n",
        "                # Check basic metrics\n",
        "                test_auc = model_data.get('test_auc_roc',\n",
        "                          model_data.get('test_auc', 'N/A'))\n",
        "                training_time = model_data.get('training_time', 'N/A')\n",
        "\n",
        "                print(f\"   ✅ Test AUC: {test_auc}\")\n",
        "                print(f\"   ⏱️  Training Time: {training_time}\")\n",
        "\n",
        "                # Check cyclical features specifically\n",
        "                used_cyclical = model_data.get('used_cyclical_features', 'Not found')\n",
        "                print(f\"   🔄 Used cyclical: {used_cyclical}\")\n",
        "    else:\n",
        "        print(\"❌ No checkpoint found!\")\n",
        "\n",
        "    # Check model files\n",
        "    print(f\"\\n📁 MODEL FILES:\")\n",
        "    model_files = {\n",
        "        'Basic': 'basic_model.h5',\n",
        "        'DeepFM': 'deepfm_model_cyclical.h5',\n",
        "        'DIN': 'enhanced_din_cyclical_features.h5'\n",
        "    }\n",
        "\n",
        "    for model_name, filename in model_files.items():\n",
        "        filepath = os.path.join(save_path, filename)\n",
        "        if os.path.exists(filepath):\n",
        "            size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
        "            print(f\"   ✅ {model_name}: {filename} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   ❌ {model_name}: {filename} - NOT FOUND\")\n",
        "\n",
        "# Run debug\n",
        "debug_all_model_status()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xQU0owYWLuH",
        "outputId": "eaeff577-f662-4da8-dcda-4f256cc5d3af"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 DEBUGGING ALL MODEL STATUS:\n",
            "==================================================\n",
            "✅ Using Multi-Head Attention with 4 heads\n",
            "📊 Models in checkpoint: ['DIN', 'Basic', 'DeepFM']\n",
            "\n",
            "🎯 DIN:\n",
            "   ✅ Test AUC: 0.5783116898517753\n",
            "   ⏱️  Training Time: 1424.0637872219086\n",
            "   🔄 Used cyclical: True\n",
            "\n",
            "🎯 Basic:\n",
            "   ✅ Test AUC: 0.566441776019243\n",
            "   ⏱️  Training Time: 1546.9642009735107\n",
            "   🔄 Used cyclical: Not found\n",
            "\n",
            "🎯 DeepFM:\n",
            "   ❌ ERROR: Missing data for input \"is_weekend_fm\". You passed a data dictionary with keys ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gender', 'age_level', 'shopping_level', 'time_segment', 'is_holiday', 'is_weekend', 'brand']. Expected the following keys: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend_fm', 'time_segment_fm', 'is_holiday_fm', 'gender_fm', 'age_level_fm', 'shopping_level_fm', 'brand_fm', 'is_weekend_deep', 'time_segment_deep', 'is_holiday_deep', 'gender_deep', 'age_level_deep', 'shopping_level_deep', 'brand_deep']\n",
            "\n",
            "📁 MODEL FILES:\n",
            "   ✅ Basic: basic_model.h5 (262.3 MB)\n",
            "   ❌ DeepFM: deepfm_model_cyclical.h5 - NOT FOUND\n",
            "   ✅ DIN: enhanced_din_cyclical_features.h5 (393.5 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DEBUG: Cek cyclical features di data aktual\n",
        "def debug_cyclical_features_in_data():\n",
        "    \"\"\"Debug cyclical features di training data\"\"\"\n",
        "    print(\"\\n🔍 DEBUGGING CYCLICAL FEATURES IN DATA:\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "\n",
        "    print(f\"📊 All features in train_x: {list(train_x.keys())}\")\n",
        "\n",
        "    cyclical_count = 0\n",
        "    for feat in cyclical_features:\n",
        "        if feat in train_x:\n",
        "            print(f\"   ✅ {feat}: FOUND\")\n",
        "            # Show sample values\n",
        "            sample_vals = train_x[feat][:5].flatten()\n",
        "            print(f\"      Sample: {sample_vals}\")\n",
        "            cyclical_count += 1\n",
        "        else:\n",
        "            print(f\"   ❌ {feat}: MISSING\")\n",
        "\n",
        "    print(f\"\\n📈 Total cyclical features: {cyclical_count}/4\")\n",
        "\n",
        "    # Check additional_dims\n",
        "    if additional_dims:\n",
        "        print(f\"\\n📊 Additional dimensions:\")\n",
        "        for feat, dim in additional_dims.items():\n",
        "            feat_type = \"🔄 Cyclical\" if feat in cyclical_features else \"📊 Categorical\"\n",
        "            print(f\"   {feat_type} {feat}: {dim}\")\n",
        "\n",
        "    return cyclical_count\n",
        "\n",
        "cyclical_found = debug_cyclical_features_in_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXKpYYF_YTOf",
        "outputId": "1e7f5968-4eb6-449b-caad-4f17509a604f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 DEBUGGING CYCLICAL FEATURES IN DATA:\n",
            "========================================\n",
            "📊 All features in train_x: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'gender', 'age_level', 'shopping_level', 'brand', 'is_weekend', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'time_segment', 'is_holiday']\n",
            "   ✅ hour_sin: FOUND\n",
            "      Sample: [ 0.9659258   0.70710677  0.          0.25881904 -0.25881904]\n",
            "   ✅ hour_cos: FOUND\n",
            "      Sample: [-0.25881904  0.70710677  1.         -0.9659258  -0.9659258 ]\n",
            "   ✅ day_sin: FOUND\n",
            "      Sample: [ 0.43388373 -0.9749279  -0.9749279   0.43388373  0.43388373]\n",
            "   ✅ day_cos: FOUND\n",
            "      Sample: [-0.90096885 -0.22252093 -0.22252093 -0.90096885 -0.90096885]\n",
            "\n",
            "📈 Total cyclical features: 4/4\n",
            "\n",
            "📊 Additional dimensions:\n",
            "   📊 Categorical is_weekend: 2\n",
            "   📊 Categorical time_segment: 4\n",
            "   📊 Categorical is_holiday: 1\n",
            "   📊 Categorical gender: 3\n",
            "   📊 Categorical age_level: 7\n",
            "   📊 Categorical shopping_level: 4\n",
            "   📊 Categorical brand: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Keys in train_x: {list(train_x.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmIZ8J5wYUvG",
        "outputId": "dc4f47c2-5395-4738-a61a-f5fcdcc4022e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in train_x: ['user', 'item', 'cat', 'price', 'hist_items', 'hist_cats', 'hist_behaviors', 'gender', 'age_level', 'shopping_level', 'brand', 'is_weekend', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'time_segment', 'is_holiday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_cyclical_features(train_x):\n",
        "    cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "    missing_features = [feat for feat in cyclical_features if feat not in train_x]\n",
        "    if missing_features:\n",
        "        print(f\"❌ Missing cyclical features: {missing_features}\")\n",
        "    else:\n",
        "        print(\"✅ All cyclical features are present\")\n",
        "\n",
        "validate_cyclical_features(train_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cEQJ8Yhbvuu",
        "outputId": "30eedbf0-5323-44c3-f10a-0d862ce21c14"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All cyclical features are present\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7xhR7kNb4do"
      },
      "execution_count": 127,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}